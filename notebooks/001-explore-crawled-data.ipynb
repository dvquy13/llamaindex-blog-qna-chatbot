{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a424d031-221e-443a-9705-86592aedea8f",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4f23c48-7807-452e-a9fa-0a53167cdbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbba9d1-4103-4efd-b0d6-25ba32c74f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0438668-7d1d-46cd-968b-3a3774e109b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb3d4f-6de7-462c-bc3b-b536b0a1580e",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "860f66ff-51a8-42ac-ac6a-5a0261a5c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING = False\n",
    "DEBUG = True\n",
    "LOG_TO_MLFLOW = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3aeff7f-d3a6-4d94-9ce5-50853ca91714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "if DEBUG:\n",
    "    logging.getLogger('llama_index').addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "    logging.getLogger('llama_index').setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "984eedcf-127a-4eda-8df4-163c94bfc7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_TO_MLFLOW:\n",
    "    RUN_NAME = \"exp_001_qdrant_togetherai_llama3\"\n",
    "    RUN_DESCRIPTION = \"\"\"\n",
    "# Qdrant with TogetherAI Llama3 model\n",
    "\"\"\"\n",
    "    mlflow.set_experiment(\"Chain Frost - LlamaIndex Blog QnA Chatbot\")\n",
    "    mlflow.start_run(run_name=RUN_NAME, description=RUN_DESCRIPTION)\n",
    "    mlflow.log_param(\"TESTING\", TESTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fafc26a2-7df5-4963-855d-92ec99c958d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_CACHE_DP = f'data/001/{RUN_NAME}'\n",
    "os.makedirs(NOTEBOOK_CACHE_DP, exist_ok=True)\n",
    "\n",
    "if LOG_TO_MLFLOW:\n",
    "    mlflow.log_param(\"NOTEBOOK_CACHE_DP\", NOTEBOOK_CACHE_DP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c298c-20ea-45df-9b05-9d98d9c29a48",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e4b4a7e-90d7-4f3c-87a3-0daf60c30e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FP = '../crawl_llamaindex_blog/data/blogs.json'\n",
    "with open(DATA_FP, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a373ee9-9979-423f-9b08-0084fc496855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d84dba2-443a-4ff0-8611-7703b8a6829b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Automate online tasks with MultiOn and LlamaIndex',\n",
       "  'content': 'Introduction MultiOn is an AI agents platform designed to facilitate the autonomous completion of tasks in any web environment. It empowers developers to build AI agents that can manage online activities from start to finish, handling everything from simple data retrieval to complex interactions. LlamaIndex complements this by providing an orchestration framework that bridges the gap between private and public data essential for building applications with Large Language Models. It facilitates data ingestion, indexing, and querying, making it indispensable for developers looking to leverage generative AI. In this article, we\\'ll demonstrate how MultiOn\\'s capabilities can be seamlessly integrated within the LlamaIndex framework, showcasing a practical application that leverages both technologies to automate and streamline web interactions. Technical walkthrough: Integrating MultiOn with LlamaIndex Let’s explore a practical example where MultiOn and LlamaIndex work in tandem to manage email interactions and web browsing. Step 1: Setting Up the Environment  We begin by setting up our AI agent with the necessary configurations and API keys: import  openai\\n from  llama_index.agent.openai  import  OpenAIAgent\\nopenai.api_key =  \"sk-your-key\" \\n\\n from  llama_index.tools.multion  import  MultionToolSpec\\nmultion_tool = MultionToolSpec(api_key= \"your-multion-key\" ) Step 2: Integrating Gmail Search Tool  Next, we integrate a Gmail search tool to help our agent fetch and analyze emails, providing the necessary context for further actions: from  llama_index.tools.google  import  GmailToolSpec\\n from  llama_index.core.tools.ondemand_loader_tool  import  OnDemandLoaderTool\\n\\ngmail_tool = GmailToolSpec()\\ngmail_loader_tool = OnDemandLoaderTool.from_tool(\\n    gmail_tool.to_tool_list()[ 1 ],\\n    name= \"gmail_search\" ,\\n    description= \"\"\"\\n         This tool allows you to search the users gmail inbox and give directions for how to summarize or process the emails\\n\\n        You must always provide a query to filter the emails, as well as a query_str to process the retrieved emails.\\n        All parameters are required\\n        \\n        If you need to reply to an email, ask this tool to build the reply directly\\n        Examples:\\n            query=\\'from:adam subject:dinner\\', max_results=5, query_str=\\'Where are adams favourite places to eat\\'\\n            query=\\'dentist appointment\\', max_results=1, query_str=\\'When is the next dentist appointment\\'\\n            query=\\'to:jerry\\', max_results=1, query_str=\\'summarize and then create a response email to jerrys latest email\\'\\n            query=\\'is:inbox\\', max_results=5, query_str=\\'Summarize these emails\\'\\n    \"\"\" \\n) Step 3: Initialize agent Initialise the agent with tools and a system prompt agent = OpenAIAgent.from_tools(\\n    [*multion_tool.to_tool_list(), gmail_loader_tool],\\n    system_prompt= \"\"\"\\n\\t    You are an AI agent that assists the user in crafting email responses based on previous conversations.\\n\\t    \\n\\t    The gmail_search tool connects directly to an API to search and retrieve emails, and answer questions based on the content.\\n\\t    The browse tool allows you to control a web browser with natural language to complete arbitrary actions on the web.\\n\\t    \\n\\t    Use these two tools together to gain context on past emails and respond to conversations for the user.\\n    \"\"\" \\n) Step 4: Agent Execution Flow  With our tools integrated, the agent is now equipped to perform a series of tasks: 1. Search and Summarize Emails : The agent uses LlamaIndex\\'s Gmail tool to fetch relevant emails and summarize the content, providing a basis for drafting a response. print (agent.chat( \"browse to the latest email from Julian and open the email\" )) Added user message to memory: browse to the latest email from Julian and open the email\\n=== Calling Function ===\\nCalling function: gmail_search with args: {\"query\":\"from:Julian\",\"max_results\":1,\"query_str\":\"Browse to the latest email from Julian and open the email\"}\\nPlease visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=1054044249014.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.compose+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly&state=JSdsfdsi990sddsd&access_type=offline\\nGot output: Open the email from Julian to view the latest communication.\\n========================\\n \\nI have opened the latest email from Julian for you to view. If you need any specific information or action to be taken, please let me know. 2. Generate Response : Based on the summarized information, the agent crafts an appropriate response to the email chain. print (agent.chat(\\n\\t \"Summarize the email chain with julian and create a response to the last email that confirms all the details\" \\n)) Added user message to memory: Summarize the email chain with julian and create a response to the last email that confirms all the details\\n=== Calling Function ===\\nCalling function: gmail_search with args: {\"query\":\"from:Julian\",\"max_results\":1,\"query_str\":\"Summarize the email chain with Julian and create a response to the last email confirming all the details\"}\\nGot output: The email chain with Julian involved a change in an event scheduled for Friday, August 6, 2021, from 15:30 to 16:00 United Kingdom Time on Google Meet. The instructions for joining were provided in the description. The email also included contact information for joining the meeting. Julian and Nassar were listed as attendees, with Julian being the organizer. The email was authenticated and passed SPF and DKIM checks.\\n\\nIn response to the last email, I would confirm all the details of the event change, reiterating the date, time, platform (Google Meet), and any specific instructions provided. I would express gratitude for the update and confirm attendance at the revised event timing.\\n========================\\n\\nBased on the email chain with Julian, here is a summary:\\n- The event scheduled for Friday, August 6, 2021, has been changed from 15:30 to 16:00 United Kingdom Time on Google Meet.\\n- Instructions for joining the meeting were provided in the email.\\n- Attendees included Julian and Nassar, with Julian as the organizer.\\n- The email passed SPF and DKIM checks.\\n\\nTo respond and confirm all the details, you can mention the revised event date and time, the platform (Google Meet), and express gratitude for the update. Confirm your attendance at the new timing. Let me know if you would like me to draft the response email for you. 3. Send Email through MultiOn : Finally, the generated response is passed to the MultiOn agent, which manages the action of sending the email through the web browser. print (agent.chat(\\n\\t \"pass the entire generated email to the browser and have it send the email as a reply to the chain\" \\n)) Added user message to memory: pass the entire generated email to the browser and have it send the email as a reply to the chain\\n=== Calling Function ===\\nCalling function: browse with args: {\"cmd\": \"Compose a reply email to Julian confirming the event change to Fri 6 Aug 2021 from 15:30 to 16:00 UK Time on Google Meet. Express readiness to attend and thank Julian for the details.\"}\\nGot output: Email response sent to Julian\\n======================== Next Steps MultiOn is an officially supported tool on LlamaHub, the central page for all LlamaIndex integrations (from tools to LLMs to vector stores). Check out the  LlamaHub page  here. If you’re interested in running through this tutorial on building a browser + Gmail-powered agent yourself, check out our  notebook . The integration of MultiOn and LlamaIndex offers a powerful toolkit for developers aiming to automate and streamline online tasks. As these technologies evolve, they will continue to unlock new potentials in AI application, significantly impacting how developers interact with digital environments and manage data.',\n",
       "  'author': 'MultiOn',\n",
       "  'date': 'May 23, 2024',\n",
       "  'tags': ['automation', 'Agents']},\n",
       " {'title': 'Simplify your RAG application architecture with LlamaIndex + PostgresML',\n",
       "  'content': 'We’re happy to announce the recent integration of LlamaIndex with PostgresML — a comprehensive machine learning platform built on PostgreSQL. The PostgresML Managed Index allows LlamaIndex users to seamlessly manage document storage, splitting, embedding, and retrieval. By using PostgresML as the backend, users benefit from a streamlined and optimized process for Retrieval-Augmented Generation (RAG). This integration unifies embedding, vector search, and text generation into a single network call, resulting in faster, more reliable, and easier-to-manage RAG workflows. The problem with typical RAG workflows Typical Retrieval-Augmented Generation (RAG) workflows come with significant drawbacks, particularly for users. Poor performance is a major issue, as these workflows involve multiple network calls to different services for embedding, vector storage, and text generation, leading to increased latency. Additionally, there are privacy concerns when sensitive data is sent to various LLM providers. These user-centric issues are compounded by other challenges: Increased dev time to master new technologies Complicated maintenance and scalability issues due to multiple points of failure Costly vendors required for multiple services The diagram above illustrates the complexity, showing how each component interacts across different services — exacerbating these problems. Solution The PostgresML Managed Index offers a comprehensive solution to the challenges of typical RAG workflows. By managing document storage, splitting, embedding generation, and retrieval all within a single system, PostgresML significantly reduces dev time, scaling costs, and overall spend when you eliminate the need for multiple point solutions. Most importantly, it enhances the user experience by consolidating embedding, vector search, and text generation into a single network call — resulting in improved performance and reduced latency. Additionally, the use of open-source models ensures transparency and flexibility, while operating within the database addresses privacy concerns and provides users with a secure and efficient RAG workflow. About PostgresML PostgresML [ github  ||  website  ||  docs ] allows users to take advantage of the fundamental relationship between data and models, by moving the models to your database rather than constantly moving data to the models. This in-database approach to AI architecture results in more scalable, reliable and efficient applications. On the PostgresML cloud, you can perform vector operations, create embeddings, and generate real-time outputs in one process, directly where your data resides. Key highlights: Model Serving - GPU accelerated inference engine for interactive applications, with no additional networking latency or reliability costs Model Store - Access to open-source models including state of the art LLMs from Hugging Face, and track changes in performance between versions Model Training - Train models with your application data using more than 50 algorithms for regression, classification or clustering tasks; fine tune pre-trained models like Llama and BERT to improve performance Feature Store - Scalable access to model inputs, including vector, text, categorical, and numeric data: vector database, text search, knowledge graph and application data all in one low-latency system Python and JavaScript SDKs - SDK clients can perform advanced ML/AI tasks in a single SQL request without having to transfer additional data, models, hardware or dependencies to your application Serverless deployments - Enjoy instant autoscaling, so your applications can handle peak loads without overprovisioning PostgresML has a range of capabilities. In the following sections, we’ll guide you through just one use case – RAG – and how to use the PostgresML Managed Index on LlamaIndex to build a better RAG app. How it works in LlamaIndex Let’s look at a simple question-answering example using the PostgresML Managed Index. For this example, we will be using Paul Graham’s essays. Step 1: Get Your Database Connection String If you haven’t already,  create your PostgresML account . You’ll get $100 in free credits when you complete your profile. Set the PGML_DATABASE_URL environment variable: export  PGML_DATABASE_URL= \"{YOUR_CONNCECTION_STRING}\" Alternatively, you can pass the pgml_database_url argument when creating the index. Step 2: Create the PostgresML Managed Index First install Llama_index and the PostgresML Managed Index component: pip install llama_index llama-index-indices-managed-postgresml Then load in the data: mkdir  data\\ncurl -o data/paul_graham_essay.txt https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt Finally create the PostgresML Managed Index: from  llama_index.core.readers  import  SimpleDirectoryReader\\n from  llama_index.indices.managed.postgresml  import  PostgresMLIndex\\n\\n\\ndocuments = SimpleDirectoryReader( \"data\" ).load_data()\\nindex = PostgresMLIndex.from_documents(\\n    documents, collection_name= \"llama-index-example\" \\n) Note the collection_name is used to uniquely identify the index you are working with. Here we are using the SimpleDirectoryReader to load in the documents and then we construct the PostgresMLIndex from those documents. This workflow does not require document preprocessing. Instead, the documents are sent directly to PostgresML where they are stored, split, and embedded per the pipeline specification. For more information on pipelines see:  https://postgresml.org/docs/api/client-sdk/pipelines  Custom Pipelines can be passed into the PostgresML index at creation, but by default documents are split using the recursive_character splitter and embedded with intfloat/e5-small-v2 . Step 3: Querying Now that we have created our index we can use it for retrieval and querying: retriever = index.as_retriever()\\ndocs = retriever.retrieve( \"Was the author puzzled by the IBM 1401?\" )\\n for  doc  in  docs:\\n     print (doc) PostgreML does embedding and retrieval in a single network call. Compare this query against other common LlamaIndex embedding and vector storage configurations and you will notice a significant speed up. Using the PostgresML Index as a query_engine is just as easy: response = index.as_query_engine().query( \"Was the author puzzled by the IBM 1401?\" )\\n print (response) Once again, notice how fast the response was! The PostgresML Managed Index is doing embedding, retrieval, and augmented generation in one network call. The speed up becomes even more apparent when streaming: query_engine = index.as_query_engine(streaming= True )\\nresults = query_engine.query( \"Was the author puzzled by the IBM 1401?\" )\\n for  text  in  results.response_gen:\\n     print (text, end= \"\" , flush= True ) Note that by default the query_engine uses meta-llama/Meta-Llama-3-8B-Instruct but this is completely configurable. Key takeaways The PostgresML Managed Index uniquely unifies embedding, vector search, and text generation into a single network call. LlamaIndex users can expect faster, more reliable, and easier-to-manage RAG workflows by using PostgresML as the backend. To get started with PostgresML and LlamaIndex, you can follow the PostgresML intro  guide  to setup your account, and the examples above with your own data.',\n",
       "  'author': 'PostgresML',\n",
       "  'date': 'May 28, 2024',\n",
       "  'tags': ['Managed Indexes']},\n",
       " {'title': 'LlamaIndex Newsletter 2024-06-04',\n",
       "  'content': \"Hello, LlamaIndex Family! 🦙 We're thrilled to connect with you again and bring you the latest and greatest from the world of LlamaIndex. This week, we're excited to present an array of updates and a diverse lineup of content designed to enhance your LlamaIndex experience, particularly when working with Knowledge Graphs. From integrations and guides to demos and tutorials, we've got you covered with all the tools and insights you need. 🤩\\xa0 The highlights: Elevating Knowledge Graphs:  The Property Graph Index, introduced in LlamaIndex, transforms how knowledge graphs (KGs) are built and queried. This powerful toolkit enhances graph searches with vector capabilities.  Docs ,  Tweet . Spreadsheet Insights with LlamaParse:  LlamaParse now supports spreadsheet parsing, turning complex Excel files into LLM-friendly tables for improved performance and data handling.  Notebook ,  Tweet . Code Generation with Codestral:  Codestral, a cutting-edge model from MistralAI, is now integrated into LlamaIndex. This code-generating tool supports over 80 programming languages.  Docs ,  Tweet . ✨ Feature Releases and Enhancements: We have introduced the Property Graph Index, a major feature that establishes LlamaIndex as the premier framework for building knowledge graphs (KGs) with LLMs. This sophisticated toolkit enables the construction and querying of KGs, allowing for joint vector and graph searches even in graph stores that lack native vector support.  Docs ,  Tweet . We have launched support for parsing spreadsheets in LlamaParse, allowing you to convert complex Excel files and other spreadsheet formats into clean, LLM-friendly tables for improved RAG pipeline performance.  Notebook ,  Tweet . We have integrated Codestral from MistralAI into LlamaIndex, providing day 0 support for this cutting-edge code-generating model trained on over 80 programming languages.  Docs ,  Tweet . We have integrated PostgresML into LlamaIndex, perfect for those who love Postgres and want to build AI applications. It serves open-source models locally, handles embeddings, and allows you to train or fine-tune models directly in Python and JavaScript.  Blogpost ,  Tweet . We have integrated with Milvus Lite to provide an easy start to vector search, offering day-1 support with LlamaIndex.  Docs ,  Tweet . 🗺️ Guides: Guide  to Building a Custom Graph Retriever to create a custom graph retriever for your specific needs by combining vector search and graph search with reranking for improved results. Guide  to Building GenAI Applications in minutes with NVIDIA's NIM inference microservices, offering an easy and fast way to deploy GenAI applications. This step-by-step guide teaches you how to run models, generate embeddings, and re-rank data for optimal results. Guide  to Constructing Knowledge Graphs with LLMs**,** build knowledge graphs using local models and Neo4j, starting with defining entities and relationships, using SchemaLLMPathExtractor to create structured graphs, and querying to uncover insights. 🖥️\\xa0Demos: Omakase RAG Orchestrator , a project developed by  Amir Mehr , is a web app template designed to help you build scalable RAG applications using Django, LlamaIndex, and Google Drive. It features a full-featured RAG API, data source management, user access control, and an admin panel. gmail-extractor , a project by Laurie project that trains a Python script with an LLM to extract structured data from Gmail. By iteratively improving the script based on email data, the LLM can effectively modify and enhance it to extract information with precision. ✍️ Tutorials: Sherlock Xu’s  tutorial  from BentoML on Serving A LlamaIndex RAG App as REST APIs. 📑\\xa0Papers: FinTextQA, a new benchmark dataset for long-form financial question answering, has been introduced by Jian Chen and their team. This benchmark was evaluated using LlamaIndex's Auto-Merging and Sentence Window Retrievers, along with various embeddings, rerankers, and LLMs, offering a comprehensive question-answering system for financial text. 📹\\xa0Webinar: Webinar  with authors of memary - Julian Saks, Kevin Li, Seyeong Han. Memary is a fully open-source reference implementation for long-term memory in autonomous agents 📅\\xa0 Events: Join  Pierre from LlamaIndex along with speakers from Weaviate, and Weights & Biases on June 12th at the London NLP meetup, focusing on the challenges and solutions for using LLMs with financial services data in production settings.\",\n",
       "  'author': 'LlamaIndex',\n",
       "  'date': 'Jun 4, 2024',\n",
       "  'tags': []},\n",
       " {'title': 'Batch inference with MyMagic AI and LlamaIndex',\n",
       "  'content': 'This is a guest post from MyMagic AI. MyMagic AI  allows processing and analyzing large datasets with AI. MyMagic AI offers a powerful API for  batch  inference (also known as  offline  or  delayed  inference) that brings various open-source Large Language Models (LLMs) such as Llama 70B, Mistral 7B, Mixtral 8x7B, CodeLlama70b, and advanced Embedding models to its users. Our framework is designed to perform data extraction, summarization, categorization, sentiment analysis, training data generation, and embedding, to name a few. And now it\\'s integrated directly into LlamaIndex! Part 1: batch inference How It Works: 1. Setup : Organize Your Data in an AWS S3 or GCS Bucket: Create a folder using your user ID assigned to you upon registration. Inside that folder, create another folder (called a \"session\") to store all the files you need for your tasks. Purpose of the \\'Session\\' Folder: This \"Session\" folder keeps your files separate from others, making sure that your tasks run on the right set of files. You can name your session subfolder anything you like. Granting Access to MyMagic AI: To allow MyMagic AI to securely access your files in the cloud, follow the setup instructions provided in the  MyMagic AI documentation . 2. Install : Install both MyMagic AI’s API integration and LlamaIndex library: pip install llama-index\\npip install llama-index-llms-mymagic 3. API Request:  The llamaIndex library is a wrapper around MyMagic AI’s API. What it does under the hood is simple: it sends a POST request to the MyMagic AI API while specifying the model, storage provider, bucket name, session name, and other necessary details. import  asyncio\\n from  llama_index.llms.mymagic  import  MyMagicAI\\n\\nllm = MyMagicAI(\\n    api_key= \"user_...\" ,  # provided by MyMagic AI upon sign-up \\n    storage_provider= \"s3\" ,\\n    bucket_name= \"batch-bucket\" ,  # you may name anything \\n    session= \"my-session\" ,\\n    role_arn= \"arn:aws:iam::<your account id>:role/mymagic-role\" ,\\n    system_prompt= \"You are an AI assistant that helps to summarize the documents without essential loss of information\" ,  # default prompt at https://docs.mymagic.ai/api-reference/endpoint/create \\n    region= \"eu-west-2\" ,\\n) We have designed the integration to allow the user to set up the bucket and data together with the system prompt when instantiating the llm object. Other inputs, e.g. question (i.e. your prompt), model and max_tokens are dynamic requirements when submitting complete and acomplete requests. resp = llm.complete(\\n    question= \"Summarise this in one sentence.\" ,\\n    model= \"mixtral8x7\" , \\n    max_tokens= 20 ,   # default is 10 \\n)\\n print (resp)\\n async   def   main ():\\n    aresp =  await  llm.acomplete(\\n        question= \"Summarize this in one sentence.\" ,\\n        model= \"llama7b\" ,\\n        max_tokens= 20 ,\\n    )\\n     print (aresp)\\n\\nasyncio.run(main()) This dynamic entry allows developers to experiment with different prompts and models in their workflow while also controlling for model output to cap their spending limit. MyMagic AI’s backend supports both synchronous requests (complete) and asynchronous requests (acomplete). It is advisable, however, to use our async endpoints as much as possible as batch jobs are inherently asynchronous with potentially long processing times (depending on the size of your data). Currently, we do not support chat or achat methods as our API is not designed for real-time interactive experience. However, we are planning to add those methods in the future that will function in a “batch way”. The user queries will be aggregated and appended as one prompt (to give the chat context) and sent to all files at once. Use Cases While there are myriads of use cases, here we provide a few to help motivate our users. Feel free to embed our API in your workflows that are good fit for batch processing. 1. Extraction Imagine needing to extract specific information from millions of files stored in a bucket. Information from all files will be extracted with one API call instead of a million sequential ones. 2. Classification For businesses looking to classify customer reviews such as positive, neutral, and negative. With one request you can start processing the requests over the weekend and get them ready by Monday morning. 3. Embedding Embedding text files for further machine learning applications is another powerful use case of MyMagic AI\\'s API. You will be ready for your vector db in a matter of days not weeks. 4. Training (Fine-tuning) Data Generation Imagine generating thousands of synthetic data for your fine-tuning tasks. With MyMagic AI’s API, you can reduce the generation time by a factor of 5-10x compared to GPT-3.5. 5. Transcription MyMagic AI’s API supports different types of files, so it is also easy to batch transcribe many mp3 or mp4 files in your bucket. Part 2: Integration with LlamaIndex’s RAG Pipeline The output from batch inference processes, often voluminous, can seamlessly integrate into LlamaIndex\\'s RAG pipeline for effective data storage and retrieval. This section demonstrates how to use the Llama3 model from the Ollama library coupled with BGE embedding to manage information storage and execute queries. Please ensure the following prerequisites are installed and Llama3 model is pulled: pip install llama-index-embeddings-huggingface\\ncurl -fsSL https://ollama.com/install.sh | sh\\nollama pull llama3 For this demo, we have run a batch summarization job on 5 Amazon reviews (but this might be millions in some real scenarios) and saved the results as reviews_1_5.json: {\\n  \"id_review1\": {\\n    \"query\": \"Summarize the document!\",\\n    \"output\": \"The document describes a family with a young boy who believes there is a zombie in his closet, while his parents are constantly fighting. The movie is criticized for its inconsistent genre, described as a slow-paced drama with occasional thriller elements. The review praises the well-playing parents and the decent dialogs but criticizes the lack of a boogeyman-like horror element. The overall rating is 3 out of 10.\"\\n  },\\n  \"id_review2\": {\\n    \"query\": \"Summarize the document!\",\\n    \"output\": \"The document is a positive review of a light-hearted Woody Allen comedy. The reviewer praises the witty dialogue, likable characters, and Woody Allen\\'s control over his signature style. The film is noted for making the reviewer laugh more than any recent Woody Allen comedy and praises Scarlett Johansson\\'s performance. It concludes by calling the film a great comedy to watch with friends.\"\\n  },\\n  \"id_review3\": {\\n    \"query\": \"Summarize the document!\",\\n    \"output\": \"The document describes a well-made film about one of the great masters of comedy, filmed in an old-time BBC fashion that adds realism. The actors, including Michael Sheen, are well-chosen and convincing. The production is masterful, showcasing realistic details like the fantasy of the guard and the meticulously crafted sets of Orton and Halliwell\\'s flat. Overall, it is a terrific and well-written piece.\"\\n  },\\n  \"id_review4\": {\\n    \"query\": \"Summarize the document!\",\\n    \"output\": \"Petter Mattei\\'s \\'Love in the Time of Money\\' is a visually appealing film set in New York, exploring human relations in the context of money, power, and success. The characters, played by a talented cast including Steve Buscemi and Rosario Dawson, are connected in various ways but often unaware of their shared links. The film showcases the different stages of loneliness experienced by individuals in a big city. Mattei successfully portrays the world of these characters, creating a luxurious and sophisticated look. The film is a modern adaptation of Arthur Schnitzler\\'s play on the same theme. Mattei\\'s work is appreciated, and viewers look forward to his future projects.\"\\n  },\\n  \"id_review5\": {\\n    \"query\": \"Summarize the document!\",\\n    \"output\": \"The document describes the TV show \\'Oz\\', set in the Oswald Maximum Security State Penitentiary. Known for its brutality, violence, and lack of privacy, it features an experimental section of the prison called Em City, where all the cells have glass fronts and face inwards. The show goes where others wouldn\\'t dare, featuring graphic violence, injustice, and the harsh realities of prison life. The viewer may become comfortable with uncomfortable viewing if they can embrace their darker side.\"\\n  },\\n  \"token_count\": 3391\\n}\\n Now let’s embed and store this document and ask questions using LlamaIndex’s query engine. Bring in our dependencies: import  os\\n\\n from  llama_index.embeddings.huggingface  import  HuggingFaceEmbedding\\n from  llama_index.core.indices.vector_store  import  VectorStoreIndex\\n from  llama_index.core.settings  import  Settings\\n from  llama_index.core.readers  import  SimpleDirectoryReader\\n from  llama_index.llms.ollama  import  Ollama Configure the embedding model and Llama3 model embed_model = HuggingFaceEmbedding(model_name= \"BAAI/bge-base-en-v1.5\" )\\nllm = Ollama(model= \"llama3\" , request_timeout= 300.0 ) Update settings for the indexing pipeline: Settings.llm = llm\\nSettings.embed_model = embed_model\\nSettings.chunk_size =  512   # This parameter defines the size of text chunks for embedding \\n\\ndocuments = SimpleDirectoryReader( \"reviews_1_5.json\" ).load_data()  #Modify path for your case Now create our index, our query engine and run a query: index = VectorStoreIndex.from_documents(documents, show_progress= True )\\n\\nquery_engine = index.as_query_engine(similarity_top_k= 3 )\\n\\nresponse = query_engine.query( \"What is the least favourite movie?\" )\\n print (response) Output: Based on query results, the least favourite movie is: review 1 with a rating of 3 out of 10. Now we know that the review 1 is the least favorite movie among these reviews. Next Steps This shows how batch inference combined with real-time inference can be a powerful tool for analyzing, storing and retrieving information from massive amounts of data.  Get started with MyMagic AI’s API  today!',\n",
       "  'author': 'MyMagic AI',\n",
       "  'date': 'May 22, 2024',\n",
       "  'tags': ['MyMagic AI', 'Batch inference']},\n",
       " {'title': 'LlamaIndex Newsletter 2024-05-28',\n",
       "  'content': \"Greetings, LlamaIndex Family! 🦙 Welcome to your latest weekly update from LlamaIndex! We're excited to present a variety of outstanding integration updates, detailed guides, demos, educational tutorials, and informative webinars this week. 🤩\\xa0 The highlights: Secure Code Execution with AzureCodeInterpreterTool:  Securely run LLM-generated code with Azure Container Apps, integrated with LlamaIndex for safe code execution. Build Automated Email Agents:  Create email agents with MultiOn and LlamaIndex that autonomously read, index, and respond to emails. LlamaFS for Organized Files:  Alex Reibman's team developed LlamaFS to automatically structure messy file directories, enhanced by Llama 3 and Groq Inc.'s API. RAGApp's No-Code Chatbots:  Deploy RAG chatbots easily with RAGApp's no-code interface, fully open-source and cloud-compatible. ✨ Feature Releases and Enhancements: We have launched Azure Container Apps dynamic sessions to securely run LLM-generated code in a sandbox. Integrated into LlamaIndex, this feature ensures safe execution of complex code tasks by your agents. Set up a session pool on Azure, add the AzureCodeInterpreterTool to your agent, and you’re ready to go.  Blogpost ,  Tweet . We have integrated with the open source Nomic embed, now fully operable locally. This integration allows for completely local embeddings and introduces a dynamic inference mode that optimizes embedding latency. The system automatically selects between local and remote embeddings based on speed, ensuring optimal performance.  Docs ,  Tweet . We have integrated the Vespa vector store, supporting hybrid search with BM25.  Docs ,  Tweet . We have integrated with MyMagic AI to facilitate batch data processing for GenAI applications. This setup allows you to pre-process large datasets with an LLM, enabling advanced analysis and querying capabilities.  Docs ,  Tweet . 🗺️ Guides: Guide  to building an automated Email Agent with MultiOn and LlamaIndex that can autonomously read and index emails for easy retrieval and draft responses using advanced browsing capabilities. Guide  to building Full-Stack Job Search Assistant by Rishi Raj Jain using Gokoyeb, MongoDB, and LlamaIndex. This guide takes you through setting up MongoDB Atlas, crafting a Next.js application, developing UI components, and deploying your app on Koyeb, complete with real-time response streaming and continuous job updates. 🖥️\\xa0Demos: LlamaFS, a project developed by  Alex Reibman  and his team, automatically organizes messy file directories into neatly structured folders with interpretable names. Enhanced by Llama 3 and supported by Groq Inc.'s API, Ollama's fully local mode and LlamaIndex, this tool significantly improves file management efficiency.  Code ,  Tweet . RAGApp, a project developed by  Marcus Schiesser , offers a no-code interface for configuring RAG chatbots as simply as GPTs by OpenAI. This fully open-source docker container can be deployed on any cloud platform, allowing users to set up the LLM, define system prompts, upload knowledge bases, and launch chatbots via UI or API.  Code ,  Tweet . ✍️ Tutorials: Phil Chirchir’s   tutorial  on DSPy RAG with LlamaIndex. It demonstrates how to integrate DSPy bootstrapping models with a LlamaIndex RAG pipeline powered by LlamaParse. Pavan Kumar’s   tutorial  on advanced image indexing for RAG demonstrates how to combine image embeddings with structured annotations using multimodal models. It details how to enhance image search with LlamaIndex and Qdrant Engine’s capabilities. Jayita Bhattacharyya’s  tutorial  on Building a RAG Chatbot using Llamaindex, Groq with Llama3 & Chainlit. 📹\\xa0Webinar: Webinar  with OpenDevin team to learn how to build an Open-Source Coding Assistant using OpenDevin.\",\n",
       "  'author': 'LlamaIndex',\n",
       "  'date': 'May 28, 2024',\n",
       "  'tags': []}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aabb844-bd47-4762-8dbc-4b55488e8d10",
   "metadata": {},
   "source": [
    "# Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17f5cbfd-43d1-4eda-9c76-05d219e94729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Introduction MultiOn is an AI agents platform designed to facilitate the autonomous completion of tasks in any web environment. It empowers developers to build AI agents that can manage online activities from start to finish, handling everything from simple data retrieval to complex interactions. LlamaIndex complements this by providing an orchestration framework that bridges the gap between private and public data essential for building applications with Large Language Models. It facilitates data ingestion, indexing, and querying, making it indispensable for developers looking to leverage generative AI. In this article, we\\'ll demonstrate how MultiOn\\'s capabilities can be seamlessly integrated within the LlamaIndex framework, showcasing a practical application that leverages both technologies to automate and streamline web interactions. Technical walkthrough: Integrating MultiOn with LlamaIndex Let’s explore a practical example where MultiOn and LlamaIndex work in tandem to manage email interactions and web browsing. Step 1: Setting Up the Environment  We begin by setting up our AI agent with the necessary configurations and API keys: import  openai\\n from  llama_index.agent.openai  import  OpenAIAgent\\nopenai.api_key =  \"sk-your-key\" \\n\\n from  llama_index.tools.multion  import  MultionToolSpec\\nmultion_tool = MultionToolSpec(api_key= \"your-multion-key\" ) Step 2: Integrating Gmail Search Tool  Next, we integrate a Gmail search tool to help our agent fetch and analyze emails, providing the necessary context for further actions: from  llama_index.tools.google  import  GmailToolSpec\\n from  llama_index.core.tools.ondemand_loader_tool  import  OnDemandLoaderTool\\n\\ngmail_tool = GmailToolSpec()\\ngmail_loader_tool = OnDemandLoaderTool.from_tool(\\n    gmail_tool.to_tool_list()[ 1 ],\\n    name= \"gmail_search\" ,\\n    description= \"\"\"\\n         This tool allows you to search the users gmail inbox and give directions for how to summarize or process the emails\\n\\n        You must always provide a query to filter the emails, as well as a query_str to process the retrieved emails.\\n        All parameters are required\\n        \\n        If you need to reply to an email, ask this tool to build the reply directly\\n        Examples:\\n            query=\\'from:adam subject:dinner\\', max_results=5, query_str=\\'Where are adams favourite places to eat\\'\\n            query=\\'dentist appointment\\', max_results=1, query_str=\\'When is the next dentist appointment\\'\\n            query=\\'to:jerry\\', max_results=1, query_str=\\'summarize and then create a response email to jerrys latest email\\'\\n            query=\\'is:inbox\\', max_results=5, query_str=\\'Summarize these emails\\'\\n    \"\"\" \\n) Step 3: Initialize agent Initialise the agent with tools and a system prompt agent = OpenAIAgent.from_tools(\\n    [*multion_tool.to_tool_list(), gmail_loader_tool],\\n    system_prompt= \"\"\"\\n\\t    You are an AI agent that assists the user in crafting email responses based on previous conversations.\\n\\t    \\n\\t    The gmail_search tool connects directly to an API to search and retrieve emails, and answer questions based on the content.\\n\\t    The browse tool allows you to control a web browser with natural language to complete arbitrary actions on the web.\\n\\t    \\n\\t    Use these two tools together to gain context on past emails and respond to conversations for the user.\\n    \"\"\" \\n) Step 4: Agent Execution Flow  With our tools integrated, the agent is now equipped to perform a series of tasks: 1. Search and Summarize Emails : The agent uses LlamaIndex\\'s Gmail tool to fetch relevant emails and summarize the content, providing a basis for drafting a response. print (agent.chat( \"browse to the latest email from Julian and open the email\" )) Added user message to memory: browse to the latest email from Julian and open the email\\n=== Calling Function ===\\nCalling function: gmail_search with args: {\"query\":\"from:Julian\",\"max_results\":1,\"query_str\":\"Browse to the latest email from Julian and open the email\"}\\nPlease visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=1054044249014.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.compose+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly&state=JSdsfdsi990sddsd&access_type=offline\\nGot output: Open the email from Julian to view the latest communication.\\n========================\\n \\nI have opened the latest email from Julian for you to view. If you need any specific information or action to be taken, please let me know. 2. Generate Response : Based on the summarized information, the agent crafts an appropriate response to the email chain. print (agent.chat(\\n\\t \"Summarize the email chain with julian and create a response to the last email that confirms all the details\" \\n)) Added user message to memory: Summarize the email chain with julian and create a response to the last email that confirms all the details\\n=== Calling Function ===\\nCalling function: gmail_search with args: {\"query\":\"from:Julian\",\"max_results\":1,\"query_str\":\"Summarize the email chain with Julian and create a response to the last email confirming all the details\"}\\nGot output: The email chain with Julian involved a change in an event scheduled for Friday, August 6, 2021, from 15:30 to 16:00 United Kingdom Time on Google Meet. The instructions for joining were provided in the description. The email also included contact information for joining the meeting. Julian and Nassar were listed as attendees, with Julian being the organizer. The email was authenticated and passed SPF and DKIM checks.\\n\\nIn response to the last email, I would confirm all the details of the event change, reiterating the date, time, platform (Google Meet), and any specific instructions provided. I would express gratitude for the update and confirm attendance at the revised event timing.\\n========================\\n\\nBased on the email chain with Julian, here is a summary:\\n- The event scheduled for Friday, August 6, 2021, has been changed from 15:30 to 16:00 United Kingdom Time on Google Meet.\\n- Instructions for joining the meeting were provided in the email.\\n- Attendees included Julian and Nassar, with Julian as the organizer.\\n- The email passed SPF and DKIM checks.\\n\\nTo respond and confirm all the details, you can mention the revised event date and time, the platform (Google Meet), and express gratitude for the update. Confirm your attendance at the new timing. Let me know if you would like me to draft the response email for you. 3. Send Email through MultiOn : Finally, the generated response is passed to the MultiOn agent, which manages the action of sending the email through the web browser. print (agent.chat(\\n\\t \"pass the entire generated email to the browser and have it send the email as a reply to the chain\" \\n)) Added user message to memory: pass the entire generated email to the browser and have it send the email as a reply to the chain\\n=== Calling Function ===\\nCalling function: browse with args: {\"cmd\": \"Compose a reply email to Julian confirming the event change to Fri 6 Aug 2021 from 15:30 to 16:00 UK Time on Google Meet. Express readiness to attend and thank Julian for the details.\"}\\nGot output: Email response sent to Julian\\n======================== Next Steps MultiOn is an officially supported tool on LlamaHub, the central page for all LlamaIndex integrations (from tools to LLMs to vector stores). Check out the  LlamaHub page  here. If you’re interested in running through this tutorial on building a browser + Gmail-powered agent yourself, check out our  notebook . The integration of MultiOn and LlamaIndex offers a powerful toolkit for developers aiming to automate and streamline online tasks. As these technologies evolve, they will continue to unlock new potentials in AI application, significantly impacting how developers interact with digital environments and manage data.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e65a39-1308-4459-97fb-d88fe3d74c81",
   "metadata": {},
   "source": [
    "# Prepare documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc404403-96d2-4ad2-9b71-aa4370c953f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 13:29:54.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mlen(input_data)=159\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input_data = data\n",
    "if TESTING:\n",
    "    input_data = data[:2]\n",
    "logger.info(f\"{len(input_data)=}\")\n",
    "if LOG_TO_MLFLOW:\n",
    "    mlflow.log_param(\"len_input_data\", len(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b61465bc-bc54-4845-89c5-bfe28b93ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "documents = []\n",
    "for record in input_data:\n",
    "    title = record['title']\n",
    "    metadata = {\n",
    "        'title': title,\n",
    "        'author': record['author'],\n",
    "        'date': record['date'],\n",
    "        'tags': ', '.join(record['tags'])\n",
    "    }\n",
    "    text = f\"{title}\\n{record['content']}\"\n",
    "    doc = Document(text=text, metadata=metadata)\n",
    "    documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "984356cd-5af4-4b94-8417-1d8743c830d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='0509b067-43b1-47e0-8a92-457d9f25b80b', embedding=None, metadata={'title': 'Automate online tasks with MultiOn and LlamaIndex', 'author': 'MultiOn', 'date': 'May 23, 2024', 'tags': 'automation, Agents'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Automate online tasks with MultiOn and LlamaIndex\\nIntroduction MultiOn is an AI agents platform designed to facilitate the autonomous completion of tasks in any web environment. It empowers developers to build AI agents that can manage online activities from start to finish, handling everything from simple data retrieval to complex interactions. LlamaIndex complements this by providing an orchestration framework that bridges the gap between private and public data essential for building applications with Large Language Models. It facilitates data ingestion, indexing, and querying, making it indispensable for developers looking to leverage generative AI. In this article, we\\'ll demonstrate how MultiOn\\'s capabilities can be seamlessly integrated within the LlamaIndex framework, showcasing a practical application that leverages both technologies to automate and streamline web interactions. Technical walkthrough: Integrating MultiOn with LlamaIndex Let’s explore a practical example where MultiOn and LlamaIndex work in tandem to manage email interactions and web browsing. Step 1: Setting Up the Environment  We begin by setting up our AI agent with the necessary configurations and API keys: import  openai\\n from  llama_index.agent.openai  import  OpenAIAgent\\nopenai.api_key =  \"sk-your-key\" \\n\\n from  llama_index.tools.multion  import  MultionToolSpec\\nmultion_tool = MultionToolSpec(api_key= \"your-multion-key\" ) Step 2: Integrating Gmail Search Tool  Next, we integrate a Gmail search tool to help our agent fetch and analyze emails, providing the necessary context for further actions: from  llama_index.tools.google  import  GmailToolSpec\\n from  llama_index.core.tools.ondemand_loader_tool  import  OnDemandLoaderTool\\n\\ngmail_tool = GmailToolSpec()\\ngmail_loader_tool = OnDemandLoaderTool.from_tool(\\n    gmail_tool.to_tool_list()[ 1 ],\\n    name= \"gmail_search\" ,\\n    description= \"\"\"\\n         This tool allows you to search the users gmail inbox and give directions for how to summarize or process the emails\\n\\n        You must always provide a query to filter the emails, as well as a query_str to process the retrieved emails.\\n        All parameters are required\\n        \\n        If you need to reply to an email, ask this tool to build the reply directly\\n        Examples:\\n            query=\\'from:adam subject:dinner\\', max_results=5, query_str=\\'Where are adams favourite places to eat\\'\\n            query=\\'dentist appointment\\', max_results=1, query_str=\\'When is the next dentist appointment\\'\\n            query=\\'to:jerry\\', max_results=1, query_str=\\'summarize and then create a response email to jerrys latest email\\'\\n            query=\\'is:inbox\\', max_results=5, query_str=\\'Summarize these emails\\'\\n    \"\"\" \\n) Step 3: Initialize agent Initialise the agent with tools and a system prompt agent = OpenAIAgent.from_tools(\\n    [*multion_tool.to_tool_list(), gmail_loader_tool],\\n    system_prompt= \"\"\"\\n\\t    You are an AI agent that assists the user in crafting email responses based on previous conversations.\\n\\t    \\n\\t    The gmail_search tool connects directly to an API to search and retrieve emails, and answer questions based on the content.\\n\\t    The browse tool allows you to control a web browser with natural language to complete arbitrary actions on the web.\\n\\t    \\n\\t    Use these two tools together to gain context on past emails and respond to conversations for the user.\\n    \"\"\" \\n) Step 4: Agent Execution Flow  With our tools integrated, the agent is now equipped to perform a series of tasks: 1. Search and Summarize Emails : The agent uses LlamaIndex\\'s Gmail tool to fetch relevant emails and summarize the content, providing a basis for drafting a response. print (agent.chat( \"browse to the latest email from Julian and open the email\" )) Added user message to memory: browse to the latest email from Julian and open the email\\n=== Calling Function ===\\nCalling function: gmail_search with args: {\"query\":\"from:Julian\",\"max_results\":1,\"query_str\":\"Browse to the latest email from Julian and open the email\"}\\nPlease visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=1054044249014.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.compose+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly&state=JSdsfdsi990sddsd&access_type=offline\\nGot output: Open the email from Julian to view the latest communication.\\n========================\\n \\nI have opened the latest email from Julian for you to view. If you need any specific information or action to be taken, please let me know. 2. Generate Response : Based on the summarized information, the agent crafts an appropriate response to the email chain. print (agent.chat(\\n\\t \"Summarize the email chain with julian and create a response to the last email that confirms all the details\" \\n)) Added user message to memory: Summarize the email chain with julian and create a response to the last email that confirms all the details\\n=== Calling Function ===\\nCalling function: gmail_search with args: {\"query\":\"from:Julian\",\"max_results\":1,\"query_str\":\"Summarize the email chain with Julian and create a response to the last email confirming all the details\"}\\nGot output: The email chain with Julian involved a change in an event scheduled for Friday, August 6, 2021, from 15:30 to 16:00 United Kingdom Time on Google Meet. The instructions for joining were provided in the description. The email also included contact information for joining the meeting. Julian and Nassar were listed as attendees, with Julian being the organizer. The email was authenticated and passed SPF and DKIM checks.\\n\\nIn response to the last email, I would confirm all the details of the event change, reiterating the date, time, platform (Google Meet), and any specific instructions provided. I would express gratitude for the update and confirm attendance at the revised event timing.\\n========================\\n\\nBased on the email chain with Julian, here is a summary:\\n- The event scheduled for Friday, August 6, 2021, has been changed from 15:30 to 16:00 United Kingdom Time on Google Meet.\\n- Instructions for joining the meeting were provided in the email.\\n- Attendees included Julian and Nassar, with Julian as the organizer.\\n- The email passed SPF and DKIM checks.\\n\\nTo respond and confirm all the details, you can mention the revised event date and time, the platform (Google Meet), and express gratitude for the update. Confirm your attendance at the new timing. Let me know if you would like me to draft the response email for you. 3. Send Email through MultiOn : Finally, the generated response is passed to the MultiOn agent, which manages the action of sending the email through the web browser. print (agent.chat(\\n\\t \"pass the entire generated email to the browser and have it send the email as a reply to the chain\" \\n)) Added user message to memory: pass the entire generated email to the browser and have it send the email as a reply to the chain\\n=== Calling Function ===\\nCalling function: browse with args: {\"cmd\": \"Compose a reply email to Julian confirming the event change to Fri 6 Aug 2021 from 15:30 to 16:00 UK Time on Google Meet. Express readiness to attend and thank Julian for the details.\"}\\nGot output: Email response sent to Julian\\n======================== Next Steps MultiOn is an officially supported tool on LlamaHub, the central page for all LlamaIndex integrations (from tools to LLMs to vector stores). Check out the  LlamaHub page  here. If you’re interested in running through this tutorial on building a browser + Gmail-powered agent yourself, check out our  notebook . The integration of MultiOn and LlamaIndex offers a powerful toolkit for developers aiming to automate and streamline online tasks. As these technologies evolve, they will continue to unlock new potentials in AI application, significantly impacting how developers interact with digital environments and manage data.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbc54b70-1676-496d-b429-6bfaace26683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Simplify your RAG application architecture with LlamaIndex + PostgresML',\n",
       " 'author': 'PostgresML',\n",
       " 'date': 'May 28, 2024',\n",
       " 'tags': 'Managed Indexes'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23ee5bd7-3f29-4b0e-b2e3-19d69ed7adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_TO_MLFLOW:\n",
    "    mlflow.log_param(\"len_documents\", len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055cfe0f-e8cf-44da-9bd6-b602bf98f1ec",
   "metadata": {},
   "source": [
    "## Setting LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce58b389-ddb6-4c14-816f-29376e0b91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings, ServiceContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c47872e1-ac65-476d-993f-d39e530ad32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM_OPTION = 'openai'\n",
    "# LLM_OPTION = 'ollama'\n",
    "LLM_OPTION = 'togetherai'\n",
    "\n",
    "# LLM_MODEL_NAME = 'llama3'\n",
    "# LLM_MODEL_NAME = 'gpt-3.5-turbo'\n",
    "LLM_MODEL_NAME = 'meta-llama/Meta-Llama-3-8B-Instruct-Lite'\n",
    "\n",
    "# EMBED_OPTION = 'openai'\n",
    "# EMBED_OPTION = 'togetherai'\n",
    "# EMBED_OPTION = 'ollama'\n",
    "EMBED_OPTION = 'huggingface'\n",
    "\n",
    "# EMBED_MODEL_NAME = 'llama3'\n",
    "# EMBED_MODEL_NAME = 'togethercomputer/m2-bert-80M-2k-retrieval'\n",
    "EMBED_MODEL_NAME = \"BAAI/bge-small-en-v1.5\"\n",
    "\n",
    "if LOG_TO_MLFLOW:\n",
    "    mlflow.log_param(\"LLM_OPTION\", LLM_OPTION)\n",
    "    mlflow.log_param(\"LLM_MODEL_NAME\", LLM_MODEL_NAME)\n",
    "    mlflow.log_param(\"EMBED_OPTION\", EMBED_OPTION)\n",
    "    mlflow.log_param(\"EMBED_MODEL_NAME\", EMBED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "831156c6-08f7-4ed6-9063-6c7d7f00b312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 13:30:32.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mLLM:\n",
      "TogetherLLM(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x793a452ab550>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x793afa355080>, completion_to_prompt=<function default_completion_to_prompt at 0x793afa3c3420>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model='meta-llama/Meta-Llama-3-8B-Instruct-Lite', temperature=0.1, max_tokens=None, logprobs=None, top_logprobs=0, additional_kwargs={}, max_retries=3, timeout=60.0, default_headers=None, reuse_client=True, api_key='3cf613093b6eb9b479c341126dc8d3761c67f9340d0a4a8e1fdc62ed41b58126', api_base='https://api.together.xyz/v1', api_version='', context_window=3900, is_chat_model=True, is_function_calling_model=False, tokenizer=None)\u001b[0m\n",
      "\u001b[32m2024-07-23 13:30:32.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mEmbed model:\n",
      "HuggingFaceEmbedding(model_name='BAAI/bge-small-en-v1.5', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x793a4679bf50>, num_workers=None, max_length=512, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# LLM options\n",
    "if LLM_OPTION == 'ollama':\n",
    "    LLM_SERVER_HOST = '192.168.100.14'\n",
    "    LLM_SERVER_PORT = 11434\n",
    "    base_url = f'http://{LLM_SERVER_HOST}:{LLM_SERVER_PORT}'\n",
    "    llm = Ollama(base_url=base_url, model=LLM_MODEL_NAME, request_timeout=60.0)\n",
    "    !ping -c 1 $LLM_SERVER_HOST\n",
    "elif LLM_OPTION == 'openai':\n",
    "    from llama_index.llms.openai import OpenAI\n",
    "    llm = OpenAI(model=LLM_MODEL_NAME)\n",
    "elif LLM_OPTION == 'togetherai':\n",
    "    from llama_index.llms.together import TogetherLLM\n",
    "    llm = TogetherLLM(model=LLM_MODEL_NAME)\n",
    "\n",
    "# Embed options\n",
    "if EMBED_OPTION == 'huggingface':\n",
    "    from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "    embed_model = HuggingFaceEmbedding(\n",
    "        model_name=EMBED_MODEL_NAME\n",
    "    )\n",
    "elif EMBED_OPTION == 'openai':\n",
    "    from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "    embed_model = OpenAIEmbedding()\n",
    "elif EMBED_OPTION == 'togetherai':\n",
    "    from llama_index.embeddings.together import TogetherEmbedding\n",
    "    embed_model = TogetherEmbedding(EMBED_MODEL_NAME)\n",
    "elif EMBED_OPTION == 'ollama':\n",
    "    from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "    embed_model = OllamaEmbedding(\n",
    "        model_name=EMBED_MODEL_NAME,\n",
    "        base_url=base_url,\n",
    "        ollama_additional_kwargs={\"mirostat\": 0},\n",
    "    )\n",
    "\n",
    "logger.info(f\"LLM:\\n{repr(llm)}\")\n",
    "logger.info(f\"Embed model:\\n{repr(embed_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0db5ed88-2448-4308-97e0-73bc9451c2bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embed_model_dim = len(embed_model.get_text_embedding('sample text to find embedding dimensions'))\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm\n",
    "\n",
    "if LOG_TO_MLFLOW:\n",
    "    mlflow.log_param(\"embedding_model_dim\", embed_model_dim)\n",
    "    mlflow.log_param(\"LLM_MODEL\", repr(llm))\n",
    "    mlflow.log_param(\"EMBEDDING_MODEL\", repr(embed_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc548f-6c02-4755-b851-eec692090115",
   "metadata": {},
   "source": [
    "# Index embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a05d2-4b9e-4295-9dc5-e1b3bdf22be0",
   "metadata": {},
   "source": [
    "## Qdrant as VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0be2dff6-23da-448b-866b-d791bb54812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qdrant_client\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08b83e18-6391-408c-93d9-dcf225813302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 13:30:40.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1msubstitute_punctuation(collection_raw_name)='huggingface__BAAI_bge_small_en_v1_5'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def substitute_punctuation(text):\n",
    "    # Create a translation table that maps each punctuation character to an underscore\n",
    "    translator = str.maketrans(string.punctuation, '_' * len(string.punctuation))\n",
    "    # Translate the text using the translation table\n",
    "    return text.translate(translator)\n",
    "\n",
    "collection_raw_name = f\"{EMBED_OPTION}__{EMBED_MODEL_NAME}\"\n",
    "logger.info(f\"{substitute_punctuation(collection_raw_name)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da75b19f-ef70-4ca7-9564-0bf663466dd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RECREATE_INDEX = True\n",
    "\n",
    "COLLECTION = substitute_punctuation(collection_raw_name)\n",
    "NODES_PERSIST_FP = f'{NOTEBOOK_CACHE_DP}/nodes.pkl'\n",
    "\n",
    "if LOG_TO_MLFLOW:\n",
    "    mlflow.log_param(f\"COLLECTION\", COLLECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ec5d7b9-7ad3-427f-a423-0fee1f7f49aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 13:30:58.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mCreating new Qdrant collection...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both client and aclient are provided. If using `:memory:` mode, the data between clients is not synced.\n"
     ]
    }
   ],
   "source": [
    "qdrantdb = qdrant_client.QdrantClient(\n",
    "    # you can use :memory: mode for fast and light-weight experiments,\n",
    "    # it does not require to have Qdrant deployed anywhere\n",
    "    # but requires qdrant-client >= 1.1.1\n",
    "    # location=\":memory:\"\n",
    "    # otherwise set Qdrant instance address with:\n",
    "    # url=\"http://<host>:<port>\"\n",
    "    # otherwise set Qdrant instance with host and port:\n",
    "    host=\"localhost\",\n",
    "    port=6333\n",
    "    # set API KEY for Qdrant Cloud\n",
    "    # api_key=\"<qdrant-api-key>\",\n",
    ")\n",
    "aqdrantdb = qdrant_client.AsyncQdrantClient(\n",
    "    # you can use :memory: mode for fast and light-weight experiments,\n",
    "    # it does not require to have Qdrant deployed anywhere\n",
    "    # but requires qdrant-client >= 1.1.1\n",
    "    # location=\":memory:\"\n",
    "    # otherwise set Qdrant instance address with:\n",
    "    # url=\"http://<host>:<port>\"\n",
    "    # otherwise set Qdrant instance with host and port:\n",
    "    host=\"localhost\",\n",
    "    port=6333\n",
    "    # set API KEY for Qdrant Cloud\n",
    "    # api_key=\"<qdrant-api-key>\",\n",
    ")\n",
    "collection_exists = qdrantdb.collection_exists(COLLECTION)\n",
    "if RECREATE_INDEX or not collection_exists:\n",
    "    if collection_exists:\n",
    "        logger.info(f\"Deleting existing Qdrant collection...\")\n",
    "        qdrantdb.delete_collection(COLLECTION)\n",
    "    if os.path.exists(NODES_PERSIST_FP):\n",
    "        logger.info(f\"Deleting persisted nodes object at {NODES_PERSIST_FP}...\")\n",
    "        os.remove(NODES_PERSIST_FP)\n",
    "    logger.info(f\"Creating new Qdrant collection...\")\n",
    "    qdrantdb.create_collection(\n",
    "        COLLECTION,\n",
    "        vectors_config=VectorParams(size=embed_model_dim, distance=Distance.COSINE),\n",
    "    )\n",
    "else:\n",
    "    logger.info(f\"Use existing Qdrant collection\")\n",
    "db_collection = qdrantdb.get_collection(COLLECTION)\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=qdrantdb,\n",
    "    collection_name=COLLECTION,\n",
    "    aclient=aqdrantdb,\n",
    "    prefer_grpc=True\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6e0c6f0-92a6-430b-a509-682e5884b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKER = \"SentenceSplitter\"\n",
    "CHUNKER_CONFIG = {\n",
    "    \"chunk_size\": 512,\n",
    "    \"chunk_overlap\": 10\n",
    "}\n",
    "if LOG_TO_MLFLOW:\n",
    "    mlflow.log_param(\"CHUNKER\", CHUNKER)\n",
    "    for k, v in CHUNKER_CONFIG.items():\n",
    "        mlflow.log_param(f\"CHUNKER__{k}\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e60fed4-7ea5-463c-bd19-d5b6da2cb04f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 13:32:17.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mCreating new DB index...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Adding chunk: Automate online tasks with MultiOn and LlamaInd...\n",
      "> Adding chunk: All parameters are required\n",
      "        \n",
      "        If...\n",
      "> Adding chunk: print (agent.chat( \"browse to the latest email ...\n",
      "> Adding chunk: The email was authenticated and passed SPF and ...\n",
      "> Adding chunk: As these technologies evolve, they will continu...\n",
      "> Adding chunk: Simplify your RAG application architecture with...\n",
      "> Adding chunk: On the PostgresML cloud, you can perform vector...\n",
      "> Adding chunk: Step 2: Create the PostgresML Managed Index Fir...\n",
      "> Adding chunk: The PostgresML Managed Index is doing embedding...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-06-04\n",
      "Hello, LlamaIn...\n",
      "> Adding chunk: Blogpost ,  Tweet . We have integrated with Mil...\n",
      "> Adding chunk: Memary is a fully open-source reference impleme...\n",
      "> Adding chunk: Batch inference with MyMagic AI and LlamaIndex\n",
      "...\n",
      "> Adding chunk: import  asyncio\n",
      " from  llama_index.llms.mymagic...\n",
      "> Adding chunk: The user queries will be aggregated and appende...\n",
      "> Adding chunk: \",\n",
      "    \"output\": \"The document describes a fami...\n",
      "> Adding chunk: },\n",
      "  \"id_review5\": {\n",
      "    \"query\": \"Summarize th...\n",
      "> Adding chunk: Next Steps This shows how batch inference combi...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-05-28\n",
      "Greetings, Lla...\n",
      "> Adding chunk: Guide  to building Full-Stack Job Search Assist...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-06-18\n",
      "Hey Llama Foll...\n",
      "> Adding chunk: LlamaPack ,  Tweet . PingCap  has integrated th...\n",
      "> Adding chunk: Kingzzm ’s  tutorial  on Advanced RAG Patterns ...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-06-11\n",
      "Hello Llama Fa...\n",
      "> Adding chunk: Notebook . 🗺️ Guides: Guide  to Integrating Lla...\n",
      "> Adding chunk: Pavan Mantha 's  tutorial  on securing RAG apps...\n",
      "> Adding chunk: Introducing llama-agents: A Powerful Framework ...\n",
      "> Adding chunk: First we’ll bring in our dependencies and set u...\n",
      "> Adding chunk: )\n",
      " print (result) Deploying Your Multi-Agent Sy...\n",
      "> Adding chunk: ,\n",
      "    service_name= \"dumb_fact_agent\" ,\n",
      "    hos...\n",
      "> Adding chunk: import  dotenv\n",
      "dotenv.load_dotenv()  # our .env...\n",
      "> Adding chunk: input ,\n",
      "    )\n",
      "    query_engine = RetrieverQuery...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-07-02\n",
      "Hello, Llama e...\n",
      "> Adding chunk: Codebase . 🗺️ Guides: Guide  to Building an Age...\n",
      "> Adding chunk: LlamaCloud - Built for Enterprise LLM App Build...\n",
      "> Adding chunk: The Rise of Centralized Knowledge Management We...\n",
      "> Adding chunk: Want to discuss unlimited commercial use?  Cont...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-07-09\n",
      "Hello, Llama L...\n",
      "> Adding chunk: Notebook ,  Tweet . [ Yi-01.AI ]( http://Yi-01....\n",
      "> Adding chunk: Ross A.’s  tutorial  on retrieval evaluations f...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: NO — Response and Source Nodes (Context) are no...\n",
      "> Adding chunk: This mode of evaluation will look at each sourc...\n",
      "> Adding chunk: A New Document Summary Index for LLM-powered QA...\n",
      "> Adding chunk: It also allows for a more flexible form of retr...\n",
      "> Adding chunk: The rest of this guide showcases the relevant c...\n",
      "> Adding chunk: Note that the LLM returns relevance scores in a...\n",
      "> Adding chunk: Testing Anthropic Claude’s 100k-token window on...\n",
      "> Adding chunk: Where Anthropic’s 100k model doesn’t do well: C...\n",
      "> Adding chunk: from  llama_index  import  download_loader\n",
      " fro...\n",
      "> Adding chunk: from  llama_index  import  PromptHelper, LLMPre...\n",
      "> Adding chunk: # NOTE: the default create/refine approach does...\n",
      "> Adding chunk: • Reliance on Drivers and Restaurants. Uber' s ...\n",
      "> Adding chunk: • Macroeconomic conditions. Ube r's business wa...\n",
      "> Adding chunk: Increased competition could make it difficult  ...\n",
      "> Adding chunk: Analyzing Multiple Documents A popular example ...\n",
      "> Adding chunk: 2019   10 -K: \n",
      "- Further expanded AV risks to i...\n",
      "> Adding chunk: In summary, Uber ' s risk factors changed over ...\n",
      "> Adding chunk: Using LLM’s for Retrieval and Reranking\n",
      "Summary...\n",
      "> Adding chunk: The first stage uses embedding-based retrieval ...\n",
      "> Adding chunk: There are two ways of feeding in the text to th...\n",
      "> Adding chunk: You use the LLM instead of embedding-based look...\n",
      "> Adding chunk: We also showcase some results of pure LLM-based...\n",
      "> Adding chunk: With embedding-based retrieval we set k=3. With...\n",
      "> Adding chunk: The independent company initiatives include “ex...\n",
      "> Adding chunk: Secure code execution in LlamaIndex with Azure ...\n",
      "> Adding chunk: Doing this will give you a pool management endp...\n",
      "> Adding chunk: PDT is UTC-7, and PST is UTC-8. I can use the c...\n",
      "> Adding chunk: Action: code_interpreter\n",
      "Action Input: {'python...\n",
      "> Adding chunk: Action: code_interpreter\n",
      "Action Input: {'python...\n",
      "> Adding chunk: Modifying files would not be useful if you coul...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-05-21\n",
      "Hello LlamaInd...\n",
      "> Adding chunk: Now, you can easily process complex documents l...\n",
      "> Adding chunk: Introducing the Property Graph Index: A Powerfu...\n",
      "> Adding chunk: from  llama_index.indices.property_graph  impor...\n",
      "> Adding chunk: 1. Keyword/Synonym-Based Retrieval : Expand you...\n",
      "> Adding chunk: from  llama_index.indices.property_graph  impor...\n",
      "> Adding chunk: Learn More Property Graph Index Overview Basic ...\n",
      "> Adding chunk: Dumber LLM Agents Need More Constraints and Bet...\n",
      "> Adding chunk: It repeats these steps in an iterative loop unt...\n",
      "> Adding chunk: These Tools can vary in complexity. For instanc...\n",
      "> Adding chunk: Smarter agents require fewer constraints.  We d...\n",
      "> Adding chunk: graph = ComposableGraph.from_indices(\n",
      "    GPTLi...\n",
      "> Adding chunk: GPT-3/GPT-4 ReAct Agent Setup # initializing ze...\n",
      "> Adding chunk: \",\n",
      ")\n",
      "\n",
      "# our \"router\" query engine is effectivel...\n",
      "> Adding chunk: Query 2 agent_chain.run(input=\"Analyze changes ...\n",
      "> Adding chunk: Query 1: agent_chain_gpt4.run(input=\"Analyze Ub...\n",
      "> Adding chunk: To provide a more comprehensive analysis, addit...\n",
      "> Adding chunk: COVID -19  pandemic: The ongoing pandemic remai...\n",
      "> Adding chunk: 7.  Integration  and  performance of acquired b...\n",
      "> Adding chunk: > Current query: Analyze Uber revenue growth an...\n",
      "> Adding chunk: We did not test out other agent interaction pat...\n",
      "> Adding chunk: Vellum <> LlamaIndex Integration\n",
      "Co-Authors: Ak...\n",
      "> Adding chunk: While doing that, however, it’s best practice t...\n",
      "> Adding chunk: If you would like additional reasoning or expla...\n",
      "> Adding chunk: For example, if you generate a first draft of e...\n",
      "> Adding chunk: Customizing property graph index in LlamaIndex\n",
      "...\n",
      "> Adding chunk: Environment setup In this blog post, we will us...\n",
      "> Adding chunk: entities =  Literal [ \"PERSON\" ,  \"LOCATION\" , ...\n",
      "> Adding chunk: from  llama_index.core  import  PropertyGraphIn...\n",
      "> Adding chunk: graph_store.structured_query( \"\"\"\n",
      "CREATE VECTOR...\n",
      "> Adding chunk: similarity_threshold =  0.9 \n",
      "word_edit_distance...\n",
      "> Adding chunk: You can tune  similarity_threshold  and  word_d...\n",
      "> Adding chunk: class   Entities ( BaseModel ):\n",
      "     \"\"\"List of...\n",
      "> Adding chunk: entities = self.entity_extraction(text=query_st...\n",
      "> Adding chunk: )\n",
      " print ( str (response))\n",
      " # Detected entities...\n",
      "> Adding chunk: LlamaIndex and Weaviate\n",
      "Co-authors: Jerry Liu (...\n",
      "> Adding chunk: Data Indexing Once the data is loaded, LlamaInd...\n",
      "> Adding chunk: from  llama_index.node_parser  import  SimpleNo...\n",
      "> Adding chunk: LLMs can be used to prompt the language model t...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-06-25\n",
      "Hello to All L...\n",
      "> Adding chunk: Guide  to Building an Agent in LlamaIndex: Our ...\n",
      "> Adding chunk: Llama Index & Prem AI Join Forces\n",
      "Co-authors:  ...\n",
      "> Adding chunk: Start Building Your App In this quick tutorial ...\n",
      "> Adding chunk: Prem's got you covered.\n",
      "\n",
      "Rapid Iterations, Inst...\n",
      "> Adding chunk: )\n",
      " print (response) The benefits of using Prem ...\n",
      "> Adding chunk: LlamaIndex Update — 06/26/2023\n",
      "Greetings, Llama...\n",
      "> Adding chunk: Docs ,  Tweet We now incorporate the FLARE tech...\n",
      "> Adding chunk: The router can pick up to a maximum number of c...\n",
      "> Adding chunk: Notebook ,  Blogpost Prem App has successfully ...\n",
      "> Adding chunk: We hope you found this information useful and a...\n",
      "> Adding chunk: Build and Scale a Powerful Query Engine with Ll...\n",
      "> Adding chunk: More specifically, we showcase a very relevant ...\n",
      "> Adding chunk: if  file.suffix.lower() ==  \".html\" :\n",
      "        l...\n",
      "> Adding chunk: This will split the documents into chunks. \n",
      " fr...\n",
      "> Adding chunk: encode_kwargs={ \"device\" :  \"cuda\" ,  \"batch_si...\n",
      "> Adding chunk: In this example, we use a simple in-memory vect...\n",
      "> Adding chunk: Given an existing question, it can decide to br...\n",
      "> Adding chunk: To do this, you just need to do the following s...\n",
      "> Adding chunk: Q: \"Compare and contrast how the Ray docs and t...\n",
      "> Adding chunk: This allows you to effortlessly ask questions a...\n",
      "> Adding chunk: Build and Evaluate LLM Apps with LlamaIndex and...\n",
      "> Adding chunk: Wrap A LlamaIndex App with TruLens With TruLens...\n",
      "> Adding chunk: f_lang_match = Feedback(hugs.language_match).on...\n",
      "> Adding chunk: min )\n",
      "\n",
      "\n",
      "feedbacks = [f_lang_match, f_qa_relevan...\n",
      "> Adding chunk: Enriching LlamaIndex Models with GraphQL and Gr...\n",
      "> Adding chunk: !pip install llama-index==0.6.19 python-dotenv ...\n",
      "> Adding chunk: Initializing CSV Loader and GPTVectorStoreIndex...\n",
      "> Adding chunk: As you can see in the response below it doesn’t...\n",
      "> Adding chunk: 7877589022795918)], extra_info={'3decbee1-98cc-...\n",
      "> Adding chunk: Then I added the code for  __init__  to take in...\n",
      "> Adding chunk: if  parameters  is   None :\n",
      "            paramet...\n",
      "> Adding chunk: GraphDBCypherReader = download_loader('GraphDBC...\n",
      "> Adding chunk: extra_info=None), Document(text='names:\\n- Yimo...\n",
      "> Adding chunk: embedding=None, doc_hash='4d493a9f33eb7a1c07175...\n",
      "> Adding chunk: GraphQL  is not a database query language, but ...\n",
      "> Adding chunk: phone :  String !\n",
      "     phones : [ String !]!\n",
      "  ...\n",
      "> Adding chunk: Answer:\n",
      "\"\"\")\n",
      "\n",
      "response.response I was surprised...\n",
      "> Adding chunk: LlamaIndex on TWIML AI: A Distilled Summary (us...\n",
      "> Adding chunk: It also provides an outer abstraction layer tha...\n",
      "> Adding chunk: What is the origin story of LlamaIndex? The ori...\n",
      "> Adding chunk: Jerry’s response is that there are probably a f...\n",
      "> Adding chunk: Additionally, we can use LlamaIndex to structur...\n",
      "> Adding chunk: Special Feature: Berkeley Hackathon Projects (L...\n",
      "> Adding chunk: Key Features and Technology Stack Context-Aware...\n",
      "> Adding chunk: With a solid foundation in place, Helmet AI hop...\n",
      "> Adding chunk: However, with a lot of dedication and troublesh...\n",
      "> Adding chunk: The Prosperity Engine: How Prosper AI Works Pro...\n",
      "> Adding chunk: However, as we progressed and aimed for higher ...\n",
      "> Adding chunk: The Road Ahead for Prosper AI As we set our sig...\n",
      "> Adding chunk: LlamaIndex Update — 07/11/2023\n",
      "Greetings once a...\n",
      "> Adding chunk: Primarily effective for simple charts, such as ...\n",
      "> Adding chunk: It includes native LLM abstractions for platfor...\n",
      "> Adding chunk: Michael Hunger tutorial  on   Load in data from...\n",
      "> Adding chunk: Build a ChatGPT with your Private Data using Ll...\n",
      "> Adding chunk: There are 2 main paradigms currently for extend...\n",
      "> Adding chunk: Or you can get started directly  here . Use of ...\n",
      "> Adding chunk: Query “How does GPT4 do on the bar exam?” Respo...\n",
      "> Adding chunk: Building Better Tools for LLM Agents\n",
      "Over the p...\n",
      "> Adding chunk: Example inputs:\n",
      "              \"(7 * 12 ^ 10) / ...\n",
      "> Adding chunk: In fact, the above tool definition is only 9 li...\n",
      "> Adding chunk: Techniques for building better tools Below are ...\n",
      "> Adding chunk: Print the returned draft's message and id.\n",
      "    ...\n",
      "> Adding chunk: We could simply pass along the null value and r...\n",
      "> Adding chunk: All of the above actions cause friction and fru...\n",
      "> Adding chunk: Currently, LLMs tend to have context windows fr...\n",
      "> Adding chunk: #    2.   `create_event` :  This  tool allows m...\n",
      "> Adding chunk: Data Agents\n",
      "Today we’re incredibly excited to a...\n",
      "> Adding chunk: As a result some of our existing query capabili...\n",
      "> Adding chunk: You can use them as the following: from  llama_...\n",
      "> Adding chunk: The ReAct agent uses an input prompt inspired b...\n",
      "> Adding chunk: The  __call__  function can take in any series ...\n",
      "> Adding chunk: )\n",
      "    ),\n",
      " ...\n",
      "] Tool Specs A  tool spec  is a P...\n",
      "> Adding chunk: The primary reason is to preserve the generalit...\n",
      "> Adding chunk: Finally, let’s send the email! This is a good s...\n",
      "> Adding chunk: As a tool spec, it implements  to_tool_list  , ...\n",
      "> Adding chunk: The agent then reasons that it needs to call th...\n",
      "> Adding chunk: We provide some additional tool abstractions to...\n",
      "> Adding chunk: Building the data framework for LLMs\n",
      "Today is a...\n",
      "> Adding chunk: In just six months, the project garnered an imp...\n",
      "> Adding chunk: We also offer an extensive array of integration...\n",
      "> Adding chunk: They must choose in accordance to a variety of ...\n",
      "> Adding chunk: Find our project on  Github  and check out our ...\n",
      "> Adding chunk: Combining Text-to-SQL with Semantic Search for ...\n",
      "> Adding chunk: Each of these stacks solves particular use case...\n",
      "> Adding chunk: Example queries suited for Retrieval Augmented ...\n",
      "> Adding chunk: A Query Engine to Combine Structured Analytics ...\n",
      "> Adding chunk: For instance if the original question is “Tell ...\n",
      "> Adding chunk: Setup Our experiment setup is very simple. We h...\n",
      "> Adding chunk: Query 1 query_engine.query(\n",
      "  'Tell me about th...\n",
      "> Adding chunk: The early 20th century saw Berlin as a hub for ...\n",
      "> Adding chunk: Introducing LlamaIndex.TS\n",
      "We are beyond excited...\n",
      "> Adding chunk: https://github.com/run-llama/ts-playground Main...\n",
      "> Adding chunk: LlamaIndex and Transformers Agents\n",
      "Summary Agen...\n",
      "> Adding chunk: from  datasets  import  load_dataset\n",
      " from  lla...\n",
      "> Adding chunk: query ( \"Draw me a picture of a happy dog\" ) Sn...\n",
      "> Adding chunk: )\n",
      "        service_context = ServiceContext.from...\n",
      "> Adding chunk: When asked to draw a picture of a mountain, thi...\n",
      "> Adding chunk: LlamaIndex + Metaphor: Towards Automating Knowl...\n",
      "> Adding chunk: Given a query, the agent will execute its reaso...\n",
      "> Adding chunk: Search:  The entrypoint to Metaphor — allows an...\n",
      "> Adding chunk: Example input: metaphor_tool.search('machine le...\n",
      "> Adding chunk: ===  Calling   Function  ===\n",
      " Calling   functio...\n",
      "> Adding chunk: lephenixto.com/', 'id': 'spCTcFr0GHlFUTzyngfRVw...\n",
      "> Adding chunk: Note that we can ask a followup question as wel...\n",
      "> Adding chunk: Our  LoadAndSearchToolSpec  wraps any given too...\n",
      "> Adding chunk: ===  Calling   Function  ===\n",
      " Calling   functio...\n",
      "> Adding chunk: Conclusion As shown above, the integration betw...\n",
      "> Adding chunk: Easily Finetune Llama 2 for Your Text-to-SQL Ap...\n",
      "> Adding chunk: This is exactly where fine-tuning comes in — gi...\n",
      "> Adding chunk: Make sure to check it out! As mentioned above, ...\n",
      "> Adding chunk: modal run src.load_data_sql --data-dir \"data_sq...\n",
      "> Adding chunk: The input prompt is then tokenized, and the lab...\n",
      "> Adding chunk: ,  'context' :  'CREATE TABLE table_name_12 (re...\n",
      "> Adding chunk: We create a toy  city_stats  table that contain...\n",
      "> Adding chunk: Jupyter notebook guide . Stack: [b-mc2/sql-crea...\n",
      "> Adding chunk: LlamaIndex: Harnessing the Power of Text2SQL an...\n",
      "> Adding chunk: \"},\n",
      "\n",
      "    # SamsungTV Reviews\n",
      "    {\"category\": \"...\n",
      "> Adding chunk: The breathable material ensures no discomfort e...\n",
      "> Adding chunk: Let’s start doing it step by step. Decomposing ...\n",
      "> Adding chunk: Provide the culture of countries\n",
      "  '''\n",
      "\n",
      "  messa...\n",
      "> Adding chunk: sql_response_list = ast.literal_eval(sql_respon...\n",
      "> Adding chunk: The ambient mode, gaming mode, and HDR content ...\n",
      "> Adding chunk: Fine-Tuning Embeddings for RAG with Synthetic D...\n",
      "> Adding chunk: (Of course RAG can be much more advanced than t...\n",
      "> Adding chunk: These (question, chunk) pairs are then used as ...\n",
      "> Adding chunk: \"\" \"\n",
      "\n",
      "# for a given node, extract questions (do...\n",
      "> Adding chunk: # define model \n",
      "model_id =  \"BAAI/bge-small-en\"...\n",
      "> Adding chunk: Resources (copied from intro) Repo:  https://gi...\n",
      "> Adding chunk: LlamaIndex: Automatic Knowledge Transfer (KT) G...\n",
      "> Adding chunk: However, using entire code bases for\n",
      "  explanat...\n",
      "> Adding chunk: However, a challenge arises. While\n",
      "   accumulat...\n",
      "> Adding chunk: To see this in action, let’s take a look at a s...\n",
      "> Adding chunk: Introducing Airbyte sources within LlamaIndex\n",
      "A...\n",
      "> Adding chunk: With this release, it’s easier than ever to run...\n",
      "> Adding chunk: This allows you to load only documents that cha...\n",
      "> Adding chunk: source  import  MyCustomSource  # plug in your ...\n",
      "> Adding chunk: LlamaIndex 0.7.0: Better Enabling Bottoms-Up LL...\n",
      "> Adding chunk: Slightly cleaner dev UX. Before, if you wanted ...\n",
      "> Adding chunk: Here’s on how you can use the LLM abstractions ...\n",
      "> Adding chunk: Here’s some resources to show both the LLM abst...\n",
      "> Adding chunk: Accumulate  - Query an LLM with the same prompt...\n",
      "> Adding chunk: Defining Metadata Fields document = Document(\n",
      " ...\n",
      "> Adding chunk: In addition to this, node post processors are n...\n",
      "> Adding chunk: Old from  llama_index  import  (\n",
      "    VectorStor...\n",
      "> Adding chunk: Now, the LLM Predictor class is mostly a lightw...\n",
      "> Adding chunk: LlamaIndex Update — 08/01/2023\n",
      "Greetings once a...\n",
      "> Adding chunk: This feature, compatible with all ReAct and Ope...\n",
      "> Adding chunk: Users can define custom retrievers within Llama...\n",
      "> Adding chunk: Anil Chandra Naidu ’s tutorial on  Retrievers  ...\n",
      "> Adding chunk: Data Agents + Zapier NLA\n",
      "Joint blog by LlamaInd...\n",
      "> Adding chunk: Zep and LlamaIndex: A Vector Store Walkthrough\n",
      "...\n",
      "> Adding chunk: from  llama_index.vector_stores  import  ZepVec...\n",
      "> Adding chunk: print ( str (response)) But one of the most sig...\n",
      "> Adding chunk: retriever = index.as_retriever(filters=filters)...\n",
      "> Adding chunk: Timescale Vector x LlamaIndex: Making PostgreSQ...\n",
      "> Adding chunk: Efficient similarity search with time-based fil...\n",
      "> Adding chunk: Try Timescale Vector for free today . Faster Ve...\n",
      "> Adding chunk: We can also specify the exact parameters for in...\n",
      "> Adding chunk: We can take advantage of this time metadata in ...\n",
      "> Adding chunk: from  llama_index.schema  import  TextNode, Nod...\n",
      "> Adding chunk: from  timescale_vector  import  client\n",
      " # Funct...\n",
      "> Adding chunk: # Create embeddings for nodes \n",
      " from  llama_ind...\n",
      "> Adding chunk: similarity_top_k= 5 )\n",
      "\n",
      "# Time filter variables ...\n",
      "> Adding chunk: -----------------------------------------------...\n",
      "> Adding chunk: 11.1 release… Success! Notice how only vectors ...\n",
      "> Adding chunk: When creating the query engine, we use Timescal...\n",
      "> Adding chunk: Take the next step in your learning journey by ...\n",
      "> Adding chunk: ChatGPT’s Knowledge is Two Years Old: What to d...\n",
      "> Adding chunk: We have integrated with over 20 open source vec...\n",
      "> Adding chunk: LlamaIndex update 2023–10–10\n",
      "Here’s our weekly ...\n",
      "> Adding chunk: NewsGPT by Kang-Chi Ho:  https://buff.ly/46jkut...\n",
      "> Adding chunk: This method fosters enhanced utilization of con...\n",
      "> Adding chunk: Docs ,  Tweet . TimescaleDB : We integrated wit...\n",
      "> Adding chunk: Evaluating the Ideal Chunk Size for a RAG Syste...\n",
      "> Adding chunk: For a practical evaluation in choosing the righ...\n",
      "> Adding chunk: # We will use GPT-4 for evaluating the response...\n",
      "> Adding chunk: total_response_time =  0 \n",
      "    total_faithfulnes...\n",
      "> Adding chunk: chunk_sizes = [ 128 ,  256 ,  512 ,  1024 ,  20...\n",
      "> Adding chunk: from_defaults(llm=gpt4)\n",
      "\n",
      " # Define Faithfulness...\n",
      "> Adding chunk: for  chunk_size  in  [ 128 ,  256 ,  512 ,  102...\n",
      "> Adding chunk: Fine-Tuning a Linear Adapter for Any Embedding ...\n",
      "> Adding chunk: The linear adapter can be used on top of any ex...\n",
      "> Adding chunk: The full guide is here:  https://gpt-index.read...\n",
      "> Adding chunk: from  llama_index.finetuning  import  Embedding...\n",
      "> Adding chunk: The reciprocal rank is defined as 1/rank. Of co...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–10–17\n",
      "Hello Llama En...\n",
      "> Adding chunk: Slides . Simon  conducted a workshop on Buildin...\n",
      "> Adding chunk: ✨ Feature Releases and Enhancements: Text to pg...\n",
      "> Adding chunk: Webinar  with Omar Khattab and Thomas Joshi on ...\n",
      "> Adding chunk: LlamaIndex + Vectara\n",
      "(co-authored by Ofer Mende...\n",
      "> Adding chunk: We never train on your data, so you can be sure...\n",
      "> Adding chunk: Then setup your Vectara customer_id, corpus_id ...\n",
      "> Adding chunk: The school district’s 1401 happened to be in th...\n",
      "> Adding chunk: \").response “Yes, learning Lisp was helpful for...\n",
      "> Adding chunk: Improving RAG effectiveness with Retrieval-Augm...\n",
      "> Adding chunk: Language Model Fine-tuning With our fine-tuning...\n",
      "> Adding chunk: Results In a comparative analysis of model perf...\n",
      "> Adding chunk: Through the dual fine-tuning of both the model ...\n",
      "> Adding chunk: Mastering PDFs: Extracting Sections, Headings, ...\n",
      "> Adding chunk: Do we need Retrieval-Augmented Generation (RAG)...\n",
      "> Adding chunk: “Content-aware” chunking . Set of methods for t...\n",
      "> Adding chunk: As a quick example, the following code snippet ...\n",
      "> Adding chunk: LlamaIndex newsletter 2023–10–24\n",
      "Hello Llama Fa...\n",
      "> Adding chunk: Tweet ,  Docs . 🗺️ Guides: Tutorial  guide on  ...\n",
      "> Adding chunk: We now accommodate custom models that align wit...\n",
      "> Adding chunk: LlamaIndex Update — 09/03/2023\n",
      "Hello LlamaIndex...\n",
      "> Adding chunk: Experience top-tier RAG by privately hosting op...\n",
      "> Adding chunk: BlogPost ,  Tweet . LlamaIndex has revamped its...\n",
      "> Adding chunk: Docs ,  Tweet . LlamaIndex introduces the  Open...\n",
      "> Adding chunk: BlogPost ,  Tweet . LlamaIndex integrates with ...\n",
      "> Adding chunk: Tweet . LITS now has additional session options...\n",
      "> Adding chunk: KDNuggests  blog post on  Build Your Own Pandas...\n",
      "> Adding chunk: A fantastic fusion of tech and medicine! SEC In...\n",
      "> Adding chunk: NewsGPT(Neotice): Summarize news articles with ...\n",
      "> Adding chunk: This data is systematically stored in the  Qdra...\n",
      "> Adding chunk: from  transformers  import  pipeline\n",
      " from  tra...\n",
      "> Adding chunk: Streaming Output with LlamaIndex and Streamlit ...\n",
      "> Adding chunk: Instead of using  st.write()  from the regular ...\n",
      "> Adding chunk: Boosting RAG: Picking the Best Embedding & Rera...\n",
      "> Adding chunk: So, if the first relevant document is the top r...\n",
      "> Adding chunk: generate only questions based on the below quer...\n",
      "> Adding chunk: # Extract keys from queries and relevant_docs t...\n",
      "> Adding chunk: embed_model = OpenAIEmbedding()\n",
      "service_context...\n",
      "> Adding chunk: Implemented by the user.\n",
      "\n",
      "        \"\"\" \n",
      "        ...\n",
      "> Adding chunk: bge-large : Experiences significant improvement...\n",
      "> Adding chunk: Nearly all embeddings benefit from reranking, s...\n",
      "> Adding chunk: LlamaIndex Update — 20/09/2023\n",
      "Hello LlamaIndex...\n",
      "> Adding chunk: Tweet . Fine-Tuning Guides: OpenAI Fine-Tuning:...\n",
      "> Adding chunk: Integrations with External Platforms Integratio...\n",
      "> Adding chunk: LlamaIndex news special edition: OpenAI develop...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023-11–07\n",
      "Hi again Llama...\n",
      "> Adding chunk: Tweet . We introduced  ParamTuner , a hyperpara...\n",
      "> Adding chunk: Ravi Theja’s   tutorial  on the Router Query En...\n",
      "> Adding chunk: LlamaIndex + Laurie Voss: an alpaca joins the l...\n",
      "> Adding chunk: If you’re new to LlamaIndex, it’s a Python and ...\n",
      "> Adding chunk: LlamaIndex turns 1!\n",
      "It’s our birthday! One year...\n",
      "> Adding chunk: It’s what gets us up in the morning and keeps u...\n",
      "> Adding chunk: Big plans With all that growth and all those fe...\n",
      "> Adding chunk: Building My Own ChatGPT Vision with PaLM, KOSMO...\n",
      "> Adding chunk: Unveiling  app.py : The Core of the Application...\n",
      "> Adding chunk: @st.cache \n",
      " def   get_image_caption ( image_dat...\n",
      "> Adding chunk: This document is then indexed to prepare it for...\n",
      "> Adding chunk: # ...code for handling user input and displayin...\n",
      "> Adding chunk: How I built the Streamlit LLM Hackathon winning...\n",
      "> Adding chunk: Setup \n",
      " \n",
      "  In case you want to refer the code t...\n",
      "> Adding chunk: FAISS is also very convenient to use. Hence, we...\n",
      "> Adding chunk: However, the response wouldn't\n",
      "  be comprehensi...\n",
      "> Adding chunk: Using this module is essential\n",
      "  because genera...\n",
      "> Adding chunk: class InnovationRnD(BaseModel):     r_and_d_act...\n",
      "> Adding chunk: session_state.index.as_query_engine(similarity_...\n",
      "> Adding chunk: write(\"## Risk Management\")             st.writ...\n",
      "> Adding chunk: You connect with me on\n",
      "   LinkedIn \n",
      "  and\n",
      "   Tw...\n",
      "> Adding chunk: Improving Retrieval Performance by Fine-tuning ...\n",
      "> Adding chunk: !mkdir -p 'data/10k/'\n",
      "!wget 'https://raw.github...\n",
      "> Adding chunk: \\\n",
      "Restrict the questions to the context informa...\n",
      "> Adding chunk: It should be noted that Hard negatives are opti...\n",
      "> Adding chunk: generate_cohere_reranker_finetuning_dataset(\n",
      "  ...\n",
      "> Adding chunk: finetune_model_no_hard_negatives = CohereRerank...\n",
      "> Adding chunk: reranker_base = CohereRerank(top_n= 5 )\n",
      "reranke...\n",
      "> Adding chunk: index_embed_model = CohereEmbedding(\n",
      "    cohere...\n",
      "> Adding chunk: results_df = pd.DataFrame()\n",
      "\n",
      "embed_name =  'Coh...\n",
      "> Adding chunk: return  self._retrieve(query_bundle)\n",
      "\n",
      "         ...\n",
      "> Adding chunk: NVIDIA Research: RAG with Long Context LLMs\n",
      "Int...\n",
      "> Adding chunk: NVIDIA’s work distinguishes itself by tapping i...\n",
      "> Adding chunk: The retrieval approach entailed segmenting each...\n",
      "> Adding chunk: Models with longer contexts (16K, 32K) outperfo...\n",
      "> Adding chunk: Best Model Performance : After enhancing with b...\n",
      "> Adding chunk: GPT4-V Experiments with General, Specific quest...\n",
      "> Adding chunk: Answer: The image you’ve provided is a bar char...\n",
      "> Adding chunk: Observation: As you can see though the categori...\n",
      "> Adding chunk: With this information, Can you compare about Ll...\n",
      "> Adding chunk: Answer: Examine the Image: The image is a bar c...\n",
      "> Adding chunk: Natural Language Understanding (Top left): All ...\n",
      "> Adding chunk: **MMLU (Top Left Graph)**: LLaMA2 shows a steep...\n",
      "> Adding chunk: The graphs are labeled with task-specific perfo...\n",
      "> Adding chunk: Identify Relevant Data: We need to focus on the...\n",
      "> Adding chunk: Image 3 — Performances of different LLMs across...\n",
      "> Adding chunk: In the SAT-en column (second from the right), t...\n",
      "> Adding chunk: Answer: To answer which model has higher perfor...\n",
      "> Adding chunk: Evaluating Multi-Modal Retrieval-Augmented Gene...\n",
      "> Adding chunk: The first two of these metrics recall and hit r...\n",
      "> Adding chunk: Hit Rate Mean Reciprocal Rank Text 0.95 0.88 Im...\n",
      "> Adding chunk: from  llama_index.evaluation.multi_modal  impor...\n",
      "> Adding chunk: We believe that separating out the retrieval ev...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–10–31\n",
      "Greetings Llam...\n",
      "> Adding chunk: Bharat Ramanathan  built  Wandbot , a live RAG ...\n",
      "> Adding chunk: Wenqi Glantz  also made a second  blog post  on...\n",
      "> Adding chunk: LongLLMLingua: Bye-bye to Middle Loss and Save ...\n",
      "> Adding chunk: Re-ranking is an intuitive concept. One intuiti...\n",
      "> Adding chunk: Compress unrelated and unimportant information ...\n",
      "> Adding chunk: The document with the ground truth is located o...\n",
      "> Adding chunk: As can be seen, compared to Retrieval-based met...\n",
      "> Adding chunk: Huiqiang Jiang, Qianhui Wu etc.\n",
      "[4] RECOMP: Imp...\n",
      "> Adding chunk: Becoming Proficient in Document Extraction\n",
      "Intr...\n",
      "> Adding chunk: This contextual understanding significantly red...\n",
      "> Adding chunk: float16,     bnb_4bit_quant_type=\"nf4\",     bnb...\n",
      "> Adding chunk: ) from llama_index.indices.query.query_transfor...\n",
      "> Adding chunk: Step 5: Lets read the  receipts \n",
      " \n",
      " from llama_...\n",
      "> Adding chunk: Medium : You\n",
      "    can read my latest articles an...\n",
      "> Adding chunk: Multi-Modal RAG\n",
      "(co-authored by Haotian Zhang, ...\n",
      "> Adding chunk: You can have chained/sequential calls that inte...\n",
      "> Adding chunk: It contains all the methods as our existing emb...\n",
      "> Adding chunk: We load the documents as a mix of text docs and...\n",
      "> Adding chunk: create-llama, a command line tool to generate L...\n",
      "> Adding chunk: There are a couple of other questions you’ll be...\n",
      "> Adding chunk: Multimodal RAG: Building ‘AInimal Go!’, a Pokém...\n",
      "> Adding chunk: Streamlit for UI Gif showing the demo in action...\n",
      "> Adding chunk: st.session_state[ 'assistant_avatar' ] = image_...\n",
      "> Adding chunk: 3. Animal Detection with ResNet18 After initial...\n",
      "> Adding chunk: Further in the script, this function is utilize...\n",
      "> Adding chunk: Remember to make {img_desc} sounds while talkin...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–11–28\n",
      "Hello to Our L...\n",
      "> Adding chunk: This pack includes Zephyr-7b as the LLM and bge...\n",
      "> Adding chunk: Tonic AI   analysis  on OpenAI Assistant API vs...\n",
      "> Adding chunk: Announcing LlamaIndex 0.9\n",
      "Our hard-working team...\n",
      "> Adding chunk: What is a  Transformation  though? It could be ...\n",
      "> Adding chunk: Here’s an example with a saving and loading a l...\n",
      "> Adding chunk: from  llama_index  import  Document\n",
      " from  llam...\n",
      "> Adding chunk: import  re\n",
      " from  llama_index  import  Document...\n",
      "> Adding chunk: We’ve done our best to minimize the impacts on ...\n",
      "> Adding chunk: There are also other installation options depen...\n",
      "> Adding chunk: See you on the Discord!\n",
      "> Adding chunk: OpenAI Cookbook: Evaluating RAG systems\n",
      "We’re e...\n",
      "> Adding chunk: Shipping your Retrieval-Augmented Generation ap...\n",
      "> Adding chunk: Your deployed app should look like this: Congra...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–11–21\n",
      "Hello Llama Fa...\n",
      "> Adding chunk: Register for free! ✨ Feature Releases and Enhan...\n",
      "> Adding chunk: Guide  on building a full-stack financial analy...\n",
      "> Adding chunk: Introducing RAGs: Your Personalized ChatGPT Exp...\n",
      "> Adding chunk: This part of the app provides an intuitive UI w...\n",
      "> Adding chunk: Say that you want to build a chatbot Define the...\n",
      "> Adding chunk: Introducing Llama Packs\n",
      "Today we’re excited to ...\n",
      "> Adding chunk: They can be downloaded either through our  llam...\n",
      "> Adding chunk: Voyage AI Pack. Every Pack has a detailed READM...\n",
      "> Adding chunk: Let’s take a look at the downloaded pack in  vo...\n",
      "> Adding chunk: Take a look at this folder for a full set of ex...\n",
      "> Adding chunk: LlamaIndex + Gemini\n",
      "(co-authored by Jerry Liu, ...\n",
      "> Adding chunk: Their  multimodal demos  demonstrate joint imag...\n",
      "> Adding chunk: It contains the following features: supports bo...\n",
      "> Adding chunk: Please see our extensive notebook guides for mo...\n",
      "> Adding chunk: Simply define the index, insert nodes, and then...\n",
      "> Adding chunk: Linking the resources again below: Gemini (text...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–11–14\n",
      "Hello Llama Fr...\n",
      "> Adding chunk: Tweet . We integrated OpenAI’s parallel functio...\n",
      "> Adding chunk: Harshad Suryawanshi ’s  tutorial  covers Buildi...\n",
      "> Adding chunk: LlamaIndex: RAG Evaluation Showdown with GPT-4 ...\n",
      "> Adding chunk: You’ll find comprehensive details on this in th...\n",
      "> Adding chunk: from  llama_index.llms  import  HuggingFaceInfe...\n",
      "> Adding chunk: ###The instruction to evaluate: Your task is to...\n",
      "> Adding chunk: Score   NO :  If  the given piece  of  informat...\n",
      "> Adding chunk: 3. After writing a feedback, write a score that...\n",
      "> Adding chunk: ### The  instruction to  evaluate :  Your  task...\n",
      "> Adding chunk: token_counter = TokenCountingHandler(\n",
      "    token...\n",
      "> Adding chunk: async   def   batch_eval_runner ( \n",
      "    evaluato...\n",
      "> Adding chunk: Query:  Based on the abstract of “Llama 2: Open...\n",
      "> Adding chunk: However, it misses the detail about Llama 2-Cha...\n",
      "> Adding chunk: Context-1:  Llama 2 : Open Foundation and Fine-...\n",
      "> Adding chunk: ∗Equal contribution, corresponding authors: {ts...\n",
      "> Adding chunk: Wemeticulouslyelaboratedonthe methodsandtechniq...\n",
      "> Adding chunk: The context clearly states that Llama 2, a coll...\n",
      "> Adding chunk: The endpoint on HF is served on AWS Nvidia A100...\n",
      "> Adding chunk: Transforming Natural Language to SQL and Insigh...\n",
      "> Adding chunk: Its integration ensures a smooth transition fro...\n",
      "> Adding chunk: class   StreamlitChatPack ( BaseLlamaPack ):\n",
      "\n",
      " ...\n",
      "> Adding chunk: I’ve used GPT3.5 here, but you can easily swap ...\n",
      "> Adding chunk: The app concludes by displaying the SQL queries...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–12–19\n",
      "What’s up, Lla...\n",
      "> Adding chunk: Tweet . We introduced day-0 integrations with t...\n",
      "> Adding chunk: Tweet AI Chatbot Starter (from the DataStax tea...\n",
      "> Adding chunk: ✍️ Tutorials: Laurie’s   Advanced Querying & Re...\n",
      "> Adding chunk: Introducing Llama Datasets 🦙📝\n",
      "(Authors: Andrei ...\n",
      "> Adding chunk: Llama Datasets on LlamaHub Overview Today’s lau...\n",
      "> Adding chunk: You can easily plug in any query engine into  a...\n",
      "> Adding chunk: reference_answer_by = CreatedBy(type=CreatedByT...\n",
      "> Adding chunk: If you want to auto-generate this given some in...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–12–05\n",
      "Hello Llama Co...\n",
      "> Adding chunk: The techniques include Hybrid Fusion, Query Rew...\n",
      "> Adding chunk: This interactive application, developed by  Har...\n",
      "> Adding chunk: Wenqi Glantz  made a  tutorial  on Llama Packs:...\n",
      "> Adding chunk: Two new llama-datasets and a Gemini vs. GPT sho...\n",
      "> Adding chunk: The way to do that with our llama-dataset abstr...\n",
      "> Adding chunk: Benchmarking flow with LabelledPairwiseEvaluato...\n",
      "> Adding chunk: The below snippet of code is how you can replic...\n",
      "> Adding chunk: As for GPT-4 versus the reference GPT-4, this i...\n",
      "> Adding chunk: Note again that these are conditional on the pr...\n",
      "> Adding chunk: Running Mixtral 8x7 locally with LlamaIndex and...\n",
      "> Adding chunk: That’s where LlamaIndex comes in. The next few ...\n",
      "> Adding chunk: This will give you a pile of documents ready to...\n",
      "> Adding chunk: Start a new python file and load in dependencie...\n",
      "> Adding chunk: We’ll need two new dependencies: pip install fl...\n",
      "> Adding chunk: And add a route that accepts a query (as form d...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–12–12\n",
      "Howdy, Llama E...\n",
      "> Adding chunk: Blog ,  Tweet . We launched  RAGs v5 , enabling...\n",
      "> Adding chunk: Tweet . We introduced AutoTranslateDoc, an open...\n",
      "> Adding chunk: This provides you with a robust chat interface ...\n",
      "> Adding chunk: Bridging the Language Gap in Programming: Intro...\n",
      "> Adding chunk: Improving Accuracy and Consistency Our commitme...\n",
      "> Adding chunk: Future Enhancements: We are actively working on...\n",
      "> Adding chunk: Scaling LlamaIndex with AWS and Hugging Face\n",
      "Ov...\n",
      "> Adding chunk: My AWS console favourites Note on how deploymen...\n",
      "> Adding chunk: Once you have a quota for GPU instances (like G...\n",
      "> Adding chunk: First, you need to create your cluster. For wha...\n",
      "> Adding chunk: You’ll want the external IP for the load balanc...\n",
      "> Adding chunk: Create a python file called  lambda_function.py...\n",
      "> Adding chunk: Select  Create function Give it a name, select ...\n",
      "> Adding chunk: To ingest data, you can run: import  requests\n",
      " ...\n",
      "> Adding chunk: Conclusion Using this setup, I was able to redu...\n",
      "> Adding chunk: Building An Intelligent Query-Response System w...\n",
      "> Adding chunk: python -m venv llamaindex-openllm\n",
      "source llamai...\n",
      "> Adding chunk: Here’s how you can use it: from  llama_index.ll...\n",
      "> Adding chunk: OpenLLM is written in Python and is available u...\n",
      "> Adding chunk: Create a folder and let’s import the GitHub REA...\n",
      "> Adding chunk: The output should be consistent with the conten...\n",
      "> Adding chunk: LlamaIndex + Waii: Combining Structured Data fr...\n",
      "> Adding chunk: Limitations arise due to the restricted context...\n",
      "> Adding chunk: The Waii Service can be deployed as a hosted Sa...\n",
      "> Adding chunk: Let’s start with creating an agent which includ...\n",
      "> Adding chunk: Understand your dataset \n",
      " \n",
      "  The first step in ...\n",
      "> Adding chunk: Specific questions that can be addressed using ...\n",
      "> Adding chunk: Books: 1,472,911 7. Home: 1,471,348 8. Jewelry:...\n",
      "> Adding chunk: - \"Gift Cards & Other\" and \"Food & Beverage\" fr...\n",
      "> Adding chunk: Introducing Query Pipelines\n",
      "Today we introduce ...\n",
      "> Adding chunk: Source: “Advanced RAG Techniques: an Illustrate...\n",
      "> Adding chunk: [In the future] Caching:  This interface also a...\n",
      "> Adding chunk: from  llama_index.postprocessor  import  Cohere...\n",
      "> Adding chunk: output_dict = p. run_multi ({ \"llm\" : { \"topic\"...\n",
      "> Adding chunk: Conclusion + Resources That’s it! As mentioned ...\n",
      "> Adding chunk: How to train a custom GPT on your data with Emb...\n",
      "> Adding chunk: The steps to do this are: Extract all the URLs ...\n",
      "> Adding chunk: Case 4: Custom ChatGPT for Notion In many moder...\n",
      "> Adding chunk: Custom trained chatbots can help your business ...\n",
      "> Adding chunk: Free Advanced RAG Certification course with Act...\n",
      "> Adding chunk: Legal:  Patent Generation and Search Engine. Ga...\n",
      "> Adding chunk: Complimentary Free Trial of Deep Lake As a part...\n",
      "> Adding chunk: AI Voice Assistant: Enhancing Accessibility in ...\n",
      "> Adding chunk: The  App.js  script incorporates features like ...\n",
      "> Adding chunk: toLowerCase ();\n",
      "         if  (transcript. inclu...\n",
      "> Adding chunk: current . stop ();\n",
      "      }\n",
      "    }  catch  (error...\n",
      "> Adding chunk: log ( \"TTS starts speaking\" );\n",
      "         setShow...\n",
      "> Adding chunk: This change ensures that when the frontend make...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024–01–16\n",
      "Hello LlamaInd...\n",
      "> Adding chunk: This method combines textual and symbolic reaso...\n",
      "> Adding chunk: 🎥 Events: Ravi Theja gave talk on Building Mult...\n",
      "> Adding chunk: Multimodal RAG pipeline with LlamaIndex and Neo...\n",
      "> Adding chunk: The results are fed into a multimodal LLM, whic...\n",
      "> Adding chunk: sections = []\n",
      "    current_section = { \"header\" ...\n",
      "> Adding chunk: all_documents = []\n",
      "all_images = []\n",
      "\n",
      " # Director...\n",
      "> Adding chunk: # Takes 10 min without GPU / 1 min with GPU on ...\n",
      "> Adding chunk: Conclusion LLMs are evolving faster than what w...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024–01–23\n",
      "Hello LlamaInd...\n",
      "> Adding chunk: Guide . ✨ Feature Releases and Enhancements: We...\n",
      "> Adding chunk: Guide  to Long-Context Embedding Models: The mo...\n",
      "> Adding chunk: Building a Slack bot that learns with LlamaInde...\n",
      "> Adding chunk: Otherwise we'll do nothing. @flask_app.route( \"...\n",
      "> Adding chunk: Click the “Permissions” link in the bottom righ...\n",
      "> Adding chunk: We’re going to use Slack’s handy Python SDK to ...\n",
      "> Adding chunk: Here's me trying it out: Success! We have a ver...\n",
      "> Adding chunk: )\n",
      "                                     return \n",
      "...\n",
      "> Adding chunk: Step 5: use LlamaIndex to store facts and answe...\n",
      "> Adding chunk: pip install qdrant-client  and bring in some ne...\n",
      "> Adding chunk: To do that we are going to stop inserting  Docu...\n",
      "> Adding chunk: A prompt template will automatically get the  c...\n",
      "> Adding chunk: We have to deploy this thing! Step 9: deploy to...\n",
      "> Adding chunk: Add a way to tell the bot to forget things (del...\n",
      "> Adding chunk: Building Scalable RAG Applications with LlamaIn...\n",
      "> Adding chunk: The chatbot is scalable and supports multi-tena...\n",
      "> Adding chunk: zcp_index.insert_doc_url(\n",
      "    url= \"https://pub...\n",
      "> Adding chunk: Zilliz Cloud Pipelines will soon support local ...\n",
      "> Adding chunk: Introducing the LlamaIndex retrieval-augmented ...\n",
      "> Adding chunk: LlamaIndex is designed  for  both beginner and ...\n",
      "> Adding chunk: Agentic RAG With LlamaIndex\n",
      "The topic of Agenti...\n",
      "> Adding chunk: Do not rely on prior knowledge \n",
      " Working Exampl...\n",
      "> Adding chunk: Utilizing LlamaIndex\n",
      "      connectors allows yo...\n",
      "> Adding chunk: Building a Fully Open Source Retriever with Nom...\n",
      "> Adding chunk: For this example, we are going to use an essay ...\n",
      "> Adding chunk: ) returns a document that describes Paul’s firs...\n",
      "> Adding chunk: So I 'm not surprised I can' t remember  any  p...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024–01–30\n",
      "Hello LlamaInd...\n",
      "> Adding chunk: Docs ,  Tweet . We have introduced JSONalyze, a...\n",
      "> Adding chunk: Tonic Validate  tutorial on Implementing integr...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024–01–02\n",
      "Hello, Llama L...\n",
      "> Adding chunk: This surpasses traditional sequential methods i...\n",
      "> Adding chunk: It integrates various tools: LlamaIndex for ind...\n",
      "> Adding chunk: Wenqi Glantz   tutorial  on 10+ Ways to Run Ope...\n",
      "> Adding chunk: Tonic Validate x LlamaIndex: Implementing integ...\n",
      "> Adding chunk: To install it, we need to make sure we have Nod...\n",
      "> Adding chunk: After this, you can run the chatbot with: pytho...\n",
      "> Adding chunk: Download the  qa_pairs.json  file from the link...\n",
      "> Adding chunk: Next, we can add the code that queries LlamaInd...\n",
      "> Adding chunk: def   test_llama_index ():\n",
      "    questions, refer...\n",
      "> Adding chunk: As is common in modern software development pra...\n",
      "> Adding chunk: In this file, we will include the following cod...\n",
      "> Adding chunk: In GitHub, go to  Settings > Secrets and variab...\n",
      "> Adding chunk: LlamaIndex: Enhancing Retrieval Performance wit...\n",
      "> Adding chunk: Queries With Misspellings:  Queries containing ...\n",
      "> Adding chunk: You can also continue following along in the  G...\n",
      "> Adding chunk: def   get_weaviate_client ( api_key, url ):\n",
      "  a...\n",
      "> Adding chunk: Setup Weaviate Client url = 'cluster URL'\n",
      "api_k...\n",
      "> Adding chunk: retrieved_nodes = self._vector_retriever.retrie...\n",
      "> Adding chunk: # Alpha values and datasets to test \n",
      "alpha_valu...\n",
      "> Adding chunk: DataFrame({ 'Dataset' : [dataset],  'Alpha' : [...\n",
      "> Adding chunk: These experiments varied in alpha values, types...\n",
      "> Adding chunk: Keyword Queries — MRR and Hit Rate are higher w...\n",
      "> Adding chunk: RAGArch: Building a No-Code RAG Pipeline Config...\n",
      "> Adding chunk: Tools and Technologies The creation of RAGArch ...\n",
      "> Adding chunk: Total documents loaded:  { len (loaded_file)} \"...\n",
      "> Adding chunk: You can choose from Google’s Gemini Pro, Cohere...\n",
      "> Adding chunk: markdown ( \"\" \"\n",
      "                    [Embedding ...\n",
      "> Adding chunk: col2 = st.columns([ 4 , 1 ])\n",
      "     with  col2:\n",
      " ...\n",
      "> Adding chunk: 'max_chars' : max_chars}\n",
      "        \n",
      "     elif  pa...\n",
      "> Adding chunk: \" )\n",
      "             return   None ,  None \n",
      "       ...\n",
      "> Adding chunk: def   select_response_synthesis_method ():\n",
      "    ...\n",
      "> Adding chunk: It initializes the pipeline with the chosen LLM...\n",
      "> Adding chunk: node_parser import SentenceSplitter, CodeSplitt...\n",
      "> Adding chunk: get( 'language' ,  'python' )} , chunk_lines= {...\n",
      "> Adding chunk: Index('test')\\n\" \n",
      "        code_snippet +=  \"vec...\n",
      "> Adding chunk: With RAGArch, both seasoned developers and AI e...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024–02–06\n",
      "Hello, LlamaIn...\n",
      "> Adding chunk: 🎥 Demo: LlamaBot:  Rohan  developed an open-sou...\n",
      "> Adding chunk: How to build LLM Agents in TypeScript with Llam...\n",
      "> Adding chunk: // Sum properties to give to the LLM \n",
      " const  s...\n",
      "> Adding chunk: Then you should see an output as: ===  Calling ...\n",
      "> Adding chunk: asQueryEngine ();\n",
      "\n",
      " // Create a QueryEngineTool...\n",
      "> Adding chunk: There is still a long way to go before they are...\n",
      "> Adding chunk: Pioneering the Future of Housing: Introducing G...\n",
      "> Adding chunk: Watch Our Demo \n",
      "\n",
      " \n",
      "\n",
      " Technologies At the heart ...\n",
      "> Adding chunk: Once you’ve setup your LlamaIndex and OpenAI AP...\n",
      "> Adding chunk: import  os\n",
      " from  pathlib  import  Path\n",
      " from  ...\n",
      "> Adding chunk: Please analyze the image, describle the layout,...\n",
      "> Adding chunk: Conclusions Our application markedly simplifies...\n",
      "> Adding chunk: LlamaIndex v0.10\n",
      "Today we’re excited to launch ...\n",
      "> Adding chunk: LlamaIndex has evolved into a broad toolkit con...\n",
      "> Adding chunk: See below for more details. llama-index-packs  ...\n",
      "> Adding chunk: There are 19 folders in here. The main integrat...\n",
      "> Adding chunk: ) Dealing with Breaking Changes This update com...\n",
      "> Adding chunk: `download` syntax A popular UX for fetching int...\n",
      "> Adding chunk: This is especially useful for callbacks. All re...\n",
      "> Adding chunk: Migration to v0.10 If you want to use LlamaInde...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–02–13\n",
      "Greetings, Lla...\n",
      "> Adding chunk: Docs . ✨ Feature Releases and Enhancements: We ...\n",
      "> Adding chunk: HelixML  tutorial  to Knowledge Memorization by...\n",
      "> Adding chunk: A Cheat Sheet and Some Recipes For Building Adv...\n",
      "> Adding chunk: Advanced RAG With the success requirements defi...\n",
      "> Adding chunk: Define objective function \n",
      " def   objective_fun...\n",
      "> Adding chunk: Execute hyperparameter search \n",
      "results = param_...\n",
      "> Adding chunk: node_id: n  for  n  in  all_nodes}\n",
      "retriever_ch...\n",
      "> Adding chunk: irrelevant information). LlamaIndex Information...\n",
      "> Adding chunk: LlamaIndex Re-Ranking For Better Generation Rec...\n",
      "> Adding chunk: # Build FLAREInstructQueryEngine \n",
      "documents = S...\n",
      "> Adding chunk: Below, we list a select few of the evaluation n...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024–01–09\n",
      "Hola, LlamaInd...\n",
      "> Adding chunk: Notebook ,  Tweet . RAGatouille LlamaPack : Int...\n",
      "> Adding chunk: Docs ,  Tweet . Ian McCrystal  has added the St...\n",
      "> Adding chunk: ✍️ Tutorials: BentoML  tutorial  on Building An...\n",
      "> Adding chunk: Introducing LlamaCloud and LlamaParse\n",
      "Today is ...\n",
      "> Adding chunk: This stack is different from any ETL stack befo...\n",
      "> Adding chunk: This is a surprisingly prevalent use case acros...\n",
      "> Adding chunk: Next Steps Our early users have already given u...\n",
      "> Adding chunk: Launch Partners and Collaborators We opened up ...\n",
      "> Adding chunk: “Now, developers can abstract complexities asso...\n",
      "> Adding chunk: Building Multi-Tenancy RAG System with LlamaInd...\n",
      "> Adding chunk: Now that we’ve discussed the concept, let’s div...\n",
      "> Adding chunk: # For user Jerry \n",
      " for  document  in  documents...\n",
      "> Adding chunk: The Task Fetching Unit dispatches the function ...\n",
      "> Adding chunk: Querying a network of knowledge with llama-inde...\n",
      "> Adding chunk: Alex has heard about these insightful documents...\n",
      "> Adding chunk: from  llama_index.networks.contributor  import ...\n",
      "> Adding chunk: A place where data suppliers package their data...\n",
      "> Adding chunk: Check out the demo to learn more! To see an act...\n",
      "> Adding chunk: Unlocking the 3rd Dimension for Generative AI (...\n",
      "> Adding chunk: This approach offers a more direct and potentia...\n",
      "> Adding chunk: (For me, I usually overestimate what I can achi...\n",
      "> Adding chunk: Our key objectives are to make neThing.xyz fast...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-03-12\n",
      "Salutations, L...\n",
      "> Adding chunk: Tweet . 🎥 Demos: Build an AI Browser Copilot : ...\n",
      "> Adding chunk: 📅 Events: We are hosting a RAG  meetup  in Pari...\n",
      "> Adding chunk: Launching the first GenAI-native document parsi...\n",
      "> Adding chunk: Do I have the wrong map? Example 3: mathematica...\n",
      "> Adding chunk: Check out this  demo notebook  where we demonst...\n",
      "> Adding chunk: PII Detector: hacking privacy in RAG\n",
      "A couple o...\n",
      "> Adding chunk: When the models generate text, there is a risk ...\n",
      "> Adding chunk: These were implemented as post processors that ...\n",
      "> Adding chunk: [ORG_521].dk/ As can be seen in this example, w...\n",
      "> Adding chunk: I could not have that. So, I added a counter an...\n",
      "> Adding chunk: My IBAN is GB90YNTU67299444055881. \n",
      "What's your...\n",
      "> Adding chunk: How It Ended Anyway, this project won the 3rd p...\n",
      "> Adding chunk: One-click Open Source RAG Observability with La...\n",
      "> Adding chunk: ))\n",
      " print (chat_engine.chat( \"How do I optimize...\n",
      "> Adding chunk: Trace more complex applications and use other L...\n",
      "> Adding chunk: LlamaIndex Accelerates Enterprise Generative AI...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-03-19\n",
      "Greetings, Lla...\n",
      "> Adding chunk: Blogpost ,  Docs ,  Tweet . Search-in-the-Chain...\n",
      "> Adding chunk: Supercharge your LlamaIndex RAG Pipeline with U...\n",
      "> Adding chunk: The evaluations demonstrated here will help you...\n",
      "> Adding chunk: Factual Accuracy : Now that we have checked if ...\n",
      "> Adding chunk: Reranking involves using a semantic search mode...\n",
      "> Adding chunk: Much of the success in the field of Artificial ...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024–02–20: introducing L...\n",
      "> Adding chunk: Tweet ,  LlamaPack . RAG Production  Guide :  A...\n",
      "> Adding chunk: Ravi Theja   tutorial  video on Building Multi-...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024–02–27\n",
      "Yo, LlamaIndex...\n",
      "> Adding chunk: Notebook ,  Tweet . ColBERT Integration:  Docum...\n",
      "> Adding chunk: BlogPost ,  Tweet . 🗺️ Guides: Guide  to simpli...\n",
      "> Adding chunk: Secure RAG with LlamaIndex and LLM Guard by Pro...\n",
      "> Adding chunk: With this example, we show how you can use LLM ...\n",
      "> Adding chunk: Try out LLM Guard by going to our  library  or ...\n",
      "> Adding chunk: Bridging the Gap in Crisis Counseling: Introduc...\n",
      "> Adding chunk: Counselor copilot takes into account contact co...\n",
      "> Adding chunk: Lastly, we used the conversation content to fil...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-03-26\n",
      "Hi there, Llam...\n",
      "> Adding chunk: Blogpost ,  Tweet . We launched LlamaParse inte...\n",
      "> Adding chunk: 📅 Events: Join us  for a Panel discussion on 'W...\n",
      "> Adding chunk: MultiModal RAG for Advanced Video Processing wi...\n",
      "> Adding chunk: The solution is divided into the following sect...\n",
      "> Adding chunk: clip = VideoFileClip(video_path)\n",
      "    clip.write...\n",
      "> Adding chunk: Building the Multi-Modal Index and Vector Store...\n",
      "> Adding chunk: from  llama_index  import  (\n",
      "    SimpleDirector...\n",
      "> Adding chunk: def   retrieve ( retriever_engine, query_str ):...\n",
      "> Adding chunk: Below is the prompt template : qa_tmpl_str = (\n",
      "...\n",
      "> Adding chunk: Convolution of Two Gaussians:  Discusses adding...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-03-05\n",
      "Greetings, Lla...\n",
      "> Adding chunk: Tweet ,  notebook ,  package ,  blog post Mixed...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-04-02\n",
      "Greetings, Lla...\n",
      "> Adding chunk: Notebook ,  Tweet We launched revamped Python d...\n",
      "> Adding chunk: Vectara’s   Panel Discussion  on 'Why RAG will ...\n",
      "> Adding chunk: Towards Long Context RAG \n",
      "Google recently relea...\n",
      "> Adding chunk: But we’re also excited about Gemini Pro, and we...\n",
      "> Adding chunk: Gemini doesn’t read all tables and charts corre...\n",
      "> Adding chunk: For these use cases, developers will no longer ...\n",
      "> Adding chunk: An solution to this that  Yao Fu  brought up is...\n",
      "> Adding chunk: One is indexing document summaries and linking ...\n",
      "> Adding chunk: But this leads to interesting retrieval strateg...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-04-09\n",
      "Hello, LlamaIn...\n",
      "> Adding chunk: 🗺️ Guides: Guide  to Building Advanced RAG with...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-04-16\n",
      "Hello, LlamaIn...\n",
      "> Adding chunk: This optimizes for reduced latency and costs, a...\n",
      "> Adding chunk: kingzzm’s   tutorial  on enhancing RAG Performa...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-04-23\n",
      "Hello LlamaInd...\n",
      "> Adding chunk: This setup includes Ray for computing, LlamaInd...\n",
      "> Adding chunk: Mariboo’s  tutorial  on Fine-tuning Embedding M...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-05-14\n",
      "Hello LlamaInd...\n",
      "> Adding chunk: Video Tutorial ,  BlogPost ,  Notebook . Arslan...\n",
      "> Adding chunk: Case study: Lyzr: Taking autonomous AI agents t...\n",
      "> Adding chunk: What do customers think? Customer reception of ...\n",
      "> Adding chunk: Building a multi-agent concierge system\n",
      "Why bui...\n",
      "> Adding chunk: Instead, it looks at what the user is currently...\n",
      "> Adding chunk: Could you please provide your username and pass...\n",
      "> Adding chunk: No current speaker, asking orchestration agent ...\n",
      "> Adding chunk: At the core of that is a very simple block that...\n",
      "> Adding chunk: If there is no current_speaker value, look at t...\n",
      "> Adding chunk: This is when the state object gets passed to ea...\n",
      "> Adding chunk: This triggers the outer loop to run the continu...\n",
      "> Adding chunk: Retrieving Privacy-Safe Documents Over A Networ...\n",
      "> Adding chunk: Part 2: of Alex, Bob and Beth. This time Bob an...\n",
      "> Adding chunk: from  llama_index.core.llama_datasets.simple  i...\n",
      "> Adding chunk: This dataset consists of 1,200 examples each co...\n",
      "> Adding chunk: import  llama_index.core.instrumentation  as  i...\n",
      "> Adding chunk: Note that we created the synthetic observations...\n",
      "> Adding chunk: nodes = [\n",
      "    TextNode(text=el.text, metadata={...\n",
      "> Adding chunk: hit rate:  a hit occurs if any of the retrieved...\n",
      "> Adding chunk: Below, we share the evaluations that result fro...\n",
      "> Adding chunk: ,\n",
      "   \"text_by\" : {\n",
      "     \"model_name\" :  \"gpt-3....\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-04-30\n",
      "Greetings, Lla...\n",
      "> Adding chunk: Tweet ✍️ Tutorials: Build a best-in-class RAG a...\n",
      "> Adding chunk: The latest updates to LlamaCloud\n",
      "To build a pro...\n",
      "> Adding chunk: This feature enables transparency, re-use, and ...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-05-07\n",
      "Hello LlamaInd...\n",
      "> Adding chunk: Tweet ,  Slides Plaban Nayak sets up a local, o...\n",
      "> Adding chunk: Arize AI and LlamaIndex Roll Out Joint Platform...\n",
      "> Adding chunk: “As leaders in our respective spaces with a com...\n",
      "> Adding chunk: Using LlamaIndex and llamafile to build a local...\n",
      "> Adding chunk: This allows the models to run on most computers...\n",
      "> Adding chunk: rename `TinyLlama-1.1B-Chat-v1.0.Q5_K_M.llamafi...\n",
      "> Adding chunk: Download the llamafile-ized model \n",
      "wget https:/...\n",
      "> Adding chunk: To get started, download our example data: mkdi...\n",
      "> Adding chunk: To start the llamafile server, open a terminal ...\n",
      "> Adding chunk: # Load local data \n",
      " from  llama_index.core  imp...\n",
      "> Adding chunk: As a next step, you could try running the examp...\n",
      "> Adding chunk: Streamlining knowledge work with LlamaIndex, Fi...\n",
      "> Adding chunk: from  llama_index.readers.web  import  SimpleWe...\n",
      "> Adding chunk: # FireworksEmbedding defaults to using model \n",
      "e...\n",
      "> Adding chunk: It’s incredibly versatile! Setting up vector se...\n",
      "> Adding chunk: ),\n",
      "    verbose= True \n",
      "    ) create-llama : from...\n",
      "> Adding chunk: Together, let’s revolutionize the way developer...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-07-16\n",
      "Hello, Llama F...\n",
      "> Adding chunk: Notebook ,  Tweet . We have integrated Redis Qu...\n",
      "> Adding chunk: Mervin Praison’s   tutorial  on using llama-age...\n",
      "> Adding chunk: Case Study: How Scaleport.ai Accelerated Develo...\n",
      "> Adding chunk: Doing that stuff with LlamaCloud and LlamaParse...\n",
      "> Adding chunk: Improving Vector Search - Reranking with Postgr...\n",
      "> Adding chunk: Install the required dependencies to get starte...\n",
      "> Adding chunk: documents = SimpleDirectoryReader( \"data\" ).loa...\n",
      "> Adding chunk: In the print era, the channel for publishing es...\n",
      "> Adding chunk: I've never known a teacher more beloved by her ...\n",
      "> Adding chunk: The school district's 1401 happened to be in th...\n",
      "> Adding chunk: The idea of actually being able to make art, to...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.15s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.17s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.61s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.20it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.04s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.52s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.59s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.53s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.34s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.11s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.75s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.78s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.11s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.12s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.06s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.17s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.24s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.18s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.02s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.24s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.63s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.91s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.97s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.24s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.13s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.10s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.67s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.56s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.74s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.61s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.84s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.73s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.60s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.01s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.46s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.27s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.17s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.09s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.21s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.30s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.54s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.10s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.83s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.71s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.22s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.16s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.16s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.37s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.21s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.04s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.67s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.33s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.01s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.24s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.15s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.19s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.03s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.58s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.75s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.33s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:12<00:00,  2.48s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.30s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.40s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.34s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.77s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.17s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.19s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.12s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.69s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.18s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.58s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.60s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.32s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.06s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.03s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.01s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.12s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.41s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.65s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.69s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.68s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.65s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.54s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.07s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.22s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.08s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.58s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.24s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.07s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.53s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.65s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.37s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.18s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.47s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.78s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.69s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.47s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.34s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.22s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.14s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.82s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.57s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.55s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.59s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.17s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.42s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.75s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.81s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.31s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.66s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.80s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.29s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.14s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.25s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.56s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.74s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.38s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.58s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.54s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.81s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.17s/it]\n",
      "\u001b[32m2024-07-23 13:52:04.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mIndexing 159 into VectorStoreIndex took 1,187s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "db_collection_count = db_collection.indexed_vectors_count\n",
    "\n",
    "if db_collection_count > 0 and RECREATE_INDEX == False:\n",
    "    logger.info(f\"Loading index from existing DB...\")\n",
    "    with open(NODES_PERSIST_FP, 'rb') as f:\n",
    "        nodes = pickle.load(f)\n",
    "else:\n",
    "    logger.info(f\"Creating new DB index...\")\n",
    "    # Generate nodes\n",
    "    # https://docs.llamaindex.ai/en/stable/module_guides/indexing/vector_store_index/\n",
    "    \n",
    "    from llama_index.core.extractors import TitleExtractor\n",
    "    from llama_index.core.ingestion import IngestionPipeline, IngestionCache\n",
    "    \n",
    "    # create the pipeline with transformations\n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[\n",
    "            SentenceSplitter(**CHUNKER_CONFIG),\n",
    "            TitleExtractor(),\n",
    "            embed_model,\n",
    "        ],\n",
    "        vector_store = vector_store\n",
    "    )\n",
    "\n",
    "    num_workers = os.cpu_count() - 1\n",
    "    logger.info(f\"Running Ingestion Pipeline with {num_workers=}\")\n",
    "    nodes = await pipeline.arun(documents=documents, num_workers=num_workers)\n",
    "    with open(NODES_PERSIST_FP, 'wb') as f:\n",
    "        pickle.dump(nodes, f)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store, storage_context=storage_context)\n",
    "t1 = time.perf_counter()\n",
    "logger.info(f\"Indexing {len(documents)} into VectorStoreIndex took {t1 - t0:,.0f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ae9a042-75d5-4b9a-8dec-42f75c86c9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 13:52:21.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mIndexed 808 nodes into Vector Store\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Indexed {len(nodes)} nodes into Vector Store\")\n",
    "if LOG_TO_MLFLOW:\n",
    "    mlflow.log_param(\"len_nodes\", len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f72b3d52-7be9-49e1-bf4e-4cd586635d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5a5fb8a-636a-463c-a938-1864cff81e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECREATE_INDEX = False\n",
    "\n",
    "COLLECTION = 'togetherai'\n",
    "NOTEBOOK_CACHE_DP = 'data/001/togetherai'\n",
    "NODES_PERSIST_FP = f'{NOTEBOOK_CACHE_DP}/nodes.pkl'\n",
    "os.makedirs(NOTEBOOK_CACHE_DP, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4a1d0d1-142d-4e7a-b626-ef154ba08e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 12:09:50.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mUse existing ChromaDB collection\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "db = chromadb.PersistentClient(path=f\"{NOTEBOOK_CACHE_DP}/chroma_db\")\n",
    "collection_exists = COLLECTION in [c.name for c in db.list_collections()]\n",
    "if RECREATE_INDEX or not collection_exists:\n",
    "    logger.info(f\"Creating new ChromaDB collection...\")\n",
    "    if collection_exists:\n",
    "        logger.info(f\"Deleting existing ChromaDB collection...\")\n",
    "        db.delete_collection(COLLECTION)\n",
    "    if os.path.exists(NODES_PERSIST_FP):\n",
    "        logger.info(f\"Deleting persisted nodes object at {NODES_PERSIST_FP}...\")\n",
    "        os.remove(NODES_PERSIST_FP)\n",
    "else:\n",
    "    logger.info(f\"Use existing ChromaDB collection\")\n",
    "chroma_collection = db.get_or_create_collection(COLLECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ecdec51-2720-4628-a43f-caaa98310630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "baa0a955-fbdf-4029-8e41-2efdea6ef58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKER = \"SentenceSplitter\"\n",
    "CHUNKER_CONFIG = {\n",
    "    \"chunk_size\": 512,\n",
    "    \"chunk_overlap\": 10\n",
    "}\n",
    "if LOG_TO_MLFLOW:\n",
    "    mlflow.log_param(\"CHUNKER\", CHUNKER)\n",
    "    for k, v in CHUNKER_CONFIG.items():\n",
    "        mlflow.log_param(f\"CHUNKER__{k}\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0f36679-603e-40d6-862b-5d9313b3c1ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 12:09:51.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mLoading index from existing ChromaDB...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if chroma_collection.count() > 0 and RECREATE_INDEX == False:\n",
    "    logger.info(f\"Loading index from existing ChromaDB...\")\n",
    "    with open(NODES_PERSIST_FP, 'rb') as f:\n",
    "        nodes = pickle.load(f)\n",
    "else:\n",
    "    logger.info(f\"Creating new ChromaDB index...\")\n",
    "    # Generate nodes\n",
    "    # https://docs.llamaindex.ai/en/stable/module_guides/indexing/vector_store_index/\n",
    "    \n",
    "    from llama_index.core.extractors import TitleExtractor\n",
    "    from llama_index.core.ingestion import IngestionPipeline, IngestionCache\n",
    "    \n",
    "    # create the pipeline with transformations\n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[\n",
    "            SentenceSplitter(**CHUNKER_CONFIG),\n",
    "            TitleExtractor(),\n",
    "            embedding,\n",
    "        ],\n",
    "        vector_store = vector_store\n",
    "    )\n",
    "    \n",
    "    # Need to use await and arun here to run the pipeline else error\n",
    "    # Ref: https://docs.llamaindex.ai/en/stable/examples/ingestion/async_ingestion_pipeline/\n",
    "    # Ref: https://github.com/run-llama/llama_index/issues/13904#issuecomment-2145561710\n",
    "    nodes = await pipeline.arun(documents=documents)\n",
    "    with open(NODES_PERSIST_FP, 'wb') as f:\n",
    "        pickle.dump(nodes, f)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a338d-469e-4461-9511-553dd6c1f766",
   "metadata": {},
   "source": [
    "#### Inspect nodes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20f68dde-bd70-49b2-a62b-40a527fc44ea",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# embeddings are excluded by default for performance, if need then explicitly ask for it in `include`\n",
    "# chroma_collection.get(include=['embeddings'])\n",
    "chroma_collection.get()['documents']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5914bc1e-e93b-40d9-8849-53903bff533d",
   "metadata": {},
   "source": [
    "# Query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "817b9319-67e2-4423-a7b8-e45f22c9a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af7f28e5-f273-492c-b1de-e1b0f3956342",
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRIEVAL_TOP_K = 2\n",
    "# Need to be able to control this cutoff until specify it\n",
    "RETRIEVAL_SIMILARITY_CUTOFF = None\n",
    "# RETRIEVAL_SIMILARITY_CUTOFF = 0.3\n",
    "\n",
    "if LOG_TO_MLFLOW:\n",
    "    mlflow.log_param(\"RETRIEVAL_TOP_K\", RETRIEVAL_TOP_K)\n",
    "    if RETRIEVAL_SIMILARITY_CUTOFF:\n",
    "        mlflow.log_param(\"RETRIEVAL_SIMILARITY_CUTOFF\", RETRIEVAL_SIMILARITY_CUTOFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d05f895c-b472-432c-911d-2f6744c00aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=RETRIEVAL_TOP_K,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "node_postprocessors = []\n",
    "\n",
    "if RETRIEVAL_SIMILARITY_CUTOFF is not None:\n",
    "    node_postprocessors.append(SimilarityPostprocessor(similarity_cutoff=RETRIEVAL_SIMILARITY_CUTOFF))\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=node_postprocessors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd56d64e-ddc6-4267-9641-bd90d64131a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 2 nodes:\n",
      "> [Node f0812544-41a5-4374-9c28-4a89704c920f] [Similarity score:             0.708697] Automate online tasks with MultiOn and LlamaIndex\n",
      "Introduction MultiOn is an AI agents platform d...\n",
      "> [Node dbc2d800-7fe5-4d49-81cf-a6f5f6d5b1ce] [Similarity score:             0.691203] The email was authenticated and passed SPF and DKIM checks.\n",
      "\n",
      "In response to the last email, I wou...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 13:53:04.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mMultiOn is an AI agents platform designed to facilitate the autonomous completion of tasks in any web environment. It empowers developers to build AI agents that can manage online activities from start to finish, handling everything from simple data retrieval to complex interactions.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"What is MultiOn?\"\n",
    "response = query_engine.query(question)\n",
    "logger.info(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ed9ba4-4573-4e66-8d59-ad55b1ed6aae",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9bdb95-f255-4f97-abc8-dda696070ed3",
   "metadata": {},
   "source": [
    "## Retrieval Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43008702-394b-4b6d-96a1-587b82d01249",
   "metadata": {},
   "source": [
    "### Building synthetic evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f78b7ddd-885b-469c-aa8d-052702dd7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NODES_PERSIST_FP, 'rb') as f:\n",
    "    nodes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b6b2b43-8bd7-4d6a-85fa-5dcb759677aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import generate_question_context_pairs, EmbeddingQAFinetuneDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ab9c5be-73e5-471e-9936-7904a6c7d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECREATE_RETRIEVAL_EVAL_DATASET = True\n",
    "RETRIEVAL_EVAL_DATASET_FP = f\"{NOTEBOOK_CACHE_DP}/llamaindex_blog_retrieval_eval_dataset.json\"\n",
    "RETRIEVAL_NUM_SAMPLE_NODES = 10\n",
    "RETRIEVAL_NUM_SAMPLE_NODES = min(len(nodes), RETRIEVAL_NUM_SAMPLE_NODES)\n",
    "RETRIEVAL_NUM_QUESTIONS_PER_CHUNK = 2\n",
    "if LOG_TO_MLFLOW:\n",
    "    mlflow.log_param(\"RETRIEVAL_NUM_QUESTIONS_PER_CHUNK\", RETRIEVAL_NUM_QUESTIONS_PER_CHUNK)\n",
    "    mlflow.log_param(\"RETRIEVAL_NUM_SAMPLE_NODES\", RETRIEVAL_NUM_SAMPLE_NODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cf4da0a-5ae8-49b9-892b-5a18d0782490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 13:53:26.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mSampling 10 nodes for retrieval evaluation...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if RECREATE_RETRIEVAL_EVAL_DATASET or not os.path.exists(RETRIEVAL_EVAL_DATASET_FP):\n",
    "    if RETRIEVAL_NUM_SAMPLE_NODES:\n",
    "        logger.info(f\"Sampling {RETRIEVAL_NUM_SAMPLE_NODES} nodes for retrieval evaluation...\")\n",
    "        np.random.seed(41)\n",
    "        retrieval_eval_nodes = np.random.choice(nodes, RETRIEVAL_NUM_SAMPLE_NODES)\n",
    "    else:\n",
    "        logger.info(f\"Using all nodes for retrieval evaluation\")\n",
    "        retrieval_eval_nodes = nodes\n",
    "else:\n",
    "    logger.info(f\"Loading retrieval_eval_nodes from {RETRIEVAL_EVAL_DATASET_FP}...\")\n",
    "    with open(RETRIEVAL_EVAL_DATASET_FP, 'r') as f:\n",
    "        retrieval_eval_nodes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7c1995d-9b60-4720-b58b-759bebdb2364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 13:53:28.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mCreating new synthetic retrieval eval dataset...\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "if RECREATE_RETRIEVAL_EVAL_DATASET or not os.path.exists(RETRIEVAL_EVAL_DATASET_FP):\n",
    "    logger.info(f\"Creating new synthetic retrieval eval dataset...\")\n",
    "    retrieval_eval_dataset = generate_question_context_pairs(\n",
    "        retrieval_eval_nodes, llm=llm, num_questions_per_chunk=RETRIEVAL_NUM_QUESTIONS_PER_CHUNK\n",
    "    )\n",
    "    retrieval_eval_dataset.save_json(RETRIEVAL_EVAL_DATASET_FP)\n",
    "else:\n",
    "    logger.info(f\"Loading existing synthetic retrieval eval dataset at {RETRIEVAL_EVAL_DATASET_FP}...\")\n",
    "    retrieval_eval_dataset = EmbeddingQAFinetuneDataset.from_json(RETRIEVAL_EVAL_DATASET_FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d9beaa-6a73-44c1-9f63-6d4c704a68d5",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c31f7229-f30e-4fd3-8bd9-186e9ada6923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import RetrieverEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b77bd622-ef88-44d3-8e5a-80fd10b9d768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 2 nodes:\n",
      "> [Node ed16c24c-937b-4bbb-80d7-dd33ea873087] [Similarity score:             0.699729] ) returns a document that describes Paul’s first programs: Node ID: 380fbb0e-6fc1-41de-a4f6-3f22c...\n",
      "> [Node e358122f-b411-4c26-9694-f8dc08c13b2c] [Similarity score:             0.697677] GPT4-V Experiments with General, Specific questions and Chain Of Thought prompting(COT) technique...\n",
      "> Top 2 nodes:\n",
      "> [Node 486b3118-3b2d-455d-bcea-8dc8e0db26d2] [Similarity score:             0.749254] The retrieval approach entailed segmenting each document into 300-word sections, encoding both qu...\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.735408] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> Top 2 nodes:\n",
      "> [Node 3b5ad0bd-36ff-41f3-8197-81d880eeeb19] [Similarity score:             0.835285] Next, we can add the code that queries LlamaIndex: def   get_responses ( questions ):\n",
      "    llm_ans...\n",
      "> [Node 91ffc125-c6be-490d-b626-3f84b64069f7] [Similarity score:             0.826941] Slides . Simon  conducted a workshop on Building, Evaluating, and Optimizing your RAG App for Pro...\n",
      "> Top 2 nodes:\n",
      "> [Node 486b3118-3b2d-455d-bcea-8dc8e0db26d2] [Similarity score:             0.783261] The retrieval approach entailed segmenting each document into 300-word sections, encoding both qu...\n",
      "> [Node e149477d-6dc2-4238-9b63-18878e66cc45] [Similarity score:             0.759313] One is indexing document summaries and linking them to documents, and the other is indexing small...\n",
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.757286] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.754412] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node ed16c24c-937b-4bbb-80d7-dd33ea873087] [Similarity score:             0.711259] ) returns a document that describes Paul’s first programs: Node ID: 380fbb0e-6fc1-41de-a4f6-3f22c...\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.705386] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> Top 2 nodes:\n",
      "> [Node 3b5ad0bd-36ff-41f3-8197-81d880eeeb19] [Similarity score:             0.667379] Next, we can add the code that queries LlamaIndex: def   get_responses ( questions ):\n",
      "    llm_ans...\n",
      "> [Node 7bcf1e17-7e56-49f0-8b79-aa0427488928] [Similarity score:             0.659577] The school district's 1401 happened to be in the basement of our junior high school, and my frien...\n",
      "> Top 2 nodes:\n",
      "> [Node 486b3118-3b2d-455d-bcea-8dc8e0db26d2] [Similarity score:             0.783261] The retrieval approach entailed segmenting each document into 300-word sections, encoding both qu...\n",
      "> [Node e149477d-6dc2-4238-9b63-18878e66cc45] [Similarity score:             0.759313] One is indexing document summaries and linking them to documents, and the other is indexing small...\n",
      "> Top 2 nodes:\n",
      "> [Node ed16c24c-937b-4bbb-80d7-dd33ea873087] [Similarity score:             0.711259] ) returns a document that describes Paul’s first programs: Node ID: 380fbb0e-6fc1-41de-a4f6-3f22c...\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.705386] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.731841] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.723881] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node ed16c24c-937b-4bbb-80d7-dd33ea873087] [Similarity score:             0.715059] ) returns a document that describes Paul’s first programs: Node ID: 380fbb0e-6fc1-41de-a4f6-3f22c...\n",
      "> [Node f01c2a9e-ed09-4852-9136-0a2e0a054aa1] [Similarity score:             0.699916] Where Anthropic’s 100k model doesn’t do well: Cost:  This one is obvious. Every query we ran proc...\n",
      "> Top 2 nodes:\n",
      "> [Node 486b3118-3b2d-455d-bcea-8dc8e0db26d2] [Similarity score:             0.734357] The retrieval approach entailed segmenting each document into 300-word sections, encoding both qu...\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.719107] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> Top 2 nodes:\n",
      "> [Node 8cf60c44-e9e5-4448-a8c6-216130f7e88e] [Similarity score:             0.778063] It repeats these steps in an iterative loop until the task is complete. There are other interacti...\n",
      "> [Node 14b2e017-dd01-4e5a-94a2-28114849aa8d] [Similarity score:             0.772008] GPT-3/GPT-4 ReAct Agent Setup # initializing zero-shot ReAct agent \n",
      "\n",
      "uber_config_sept = IndexTool...\n",
      "> Top 2 nodes:\n",
      "> [Node 486b3118-3b2d-455d-bcea-8dc8e0db26d2] [Similarity score:             0.783261] The retrieval approach entailed segmenting each document into 300-word sections, encoding both qu...\n",
      "> [Node e149477d-6dc2-4238-9b63-18878e66cc45] [Similarity score:             0.759313] One is indexing document summaries and linking them to documents, and the other is indexing small...\n",
      "> Top 2 nodes:\n",
      "> [Node e358122f-b411-4c26-9694-f8dc08c13b2c] [Similarity score:             0.626734] GPT4-V Experiments with General, Specific questions and Chain Of Thought prompting(COT) technique...\n",
      "> [Node b9085781-a6dd-4b53-8d5f-192767c7d9c8] [Similarity score:             0.621548] However, using entire code bases for\n",
      "  explanations can overwhelm language models like LLMs, caus...\n",
      "> Top 2 nodes:\n",
      "> [Node 99a1f627-fc78-49d4-a5d1-bd5fc2234e44] [Similarity score:             0.793766] These (question, chunk) pairs are then used as positive examples as training signals for the mode...\n",
      "> [Node dbba146b-8249-4221-a2b6-0e5475bd9e17] [Similarity score:             0.788442] min )\n",
      "\n",
      "\n",
      "feedbacks = [f_lang_match, f_qa_relevance, f_qs_relevance]\n",
      "\n",
      "l = TruLlama(app=query_engine...\n",
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.756688] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.752196] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node 6d9caeb3-1250-4b2c-946d-d25c2ceed141] [Similarity score:             0.76629] Introducing RAGs: Your Personalized ChatGPT Experience Over Your Data\n",
      "Today we introduce  RAGs , ...\n",
      "> [Node 924ed153-bb6e-4044-9431-205e36c96274] [Similarity score:             0.751785] Say that you want to build a chatbot Define the dataset (here it’s a web page, can also be a loca...\n",
      "> Top 2 nodes:\n",
      "> [Node 7964afd5-2e4d-4821-9580-c83b68cf0c01] [Similarity score:             0.807861] This stack is different from any ETL stack before it, because unlike traditional software, every ...\n",
      "> [Node 5e93d815-9777-48e1-83a6-194d4554687a] [Similarity score:             0.80432] The Rise of Centralized Knowledge Management We have designed LlamaCloud to cater to the need of ...\n",
      "> Top 2 nodes:\n",
      "> [Node 486b3118-3b2d-455d-bcea-8dc8e0db26d2] [Similarity score:             0.749254] The retrieval approach entailed segmenting each document into 300-word sections, encoding both qu...\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.735408] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n"
     ]
    }
   ],
   "source": [
    "RETRIEVAL_METRICS = [\"hit_rate\", \"mrr\", \"precision\", \"recall\", \"ap\", \"ndcg\"]\n",
    "\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    RETRIEVAL_METRICS, retriever=retriever\n",
    ")\n",
    "\n",
    "retrieval_eval_results = await retriever_evaluator.aevaluate_dataset(retrieval_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4dfa852-27b8-4caf-b017-f3148c348887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(name, eval_results, metrics=['hit_rate', 'mrr'], include_cohere_rerank=False):\n",
    "    \"\"\"Display results from evaluate.\"\"\"\n",
    "\n",
    "    metric_dicts = []\n",
    "    for eval_result in eval_results:\n",
    "        metric_dict = eval_result.metric_vals_dict\n",
    "        metric_dicts.append(metric_dict)\n",
    "\n",
    "    full_df = pd.DataFrame(metric_dicts)\n",
    "\n",
    "    columns = {\n",
    "        \"retrievers\": [name],\n",
    "        **{k: [full_df[k].mean()] for k in metrics},\n",
    "    }\n",
    "\n",
    "    if include_cohere_rerank:\n",
    "        crr_relevancy = full_df[\"cohere_rerank_relevancy\"].mean()\n",
    "        columns.update({\"cohere_rerank_relevancy\": [crr_relevancy]})\n",
    "\n",
    "    metric_df = pd.DataFrame(columns)\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0236036f-d6f7-42b1-9707-785e8fd61e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>ap</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top_2_retrieval_eval</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.061315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             retrievers  hit_rate  mrr  precision  recall   ap      ndcg\n",
       "0  top_2_retrieval_eval       0.1  0.1       0.05     0.1  0.1  0.061315"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_prefix = f\"top_{RETRIEVAL_TOP_K}_retrieval_eval\"\n",
    "retrieval_eval_results_df = display_results(metric_prefix, retrieval_eval_results, metrics=RETRIEVAL_METRICS)\n",
    "retrieval_eval_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5fa1e246-ac8c-4403-98f8-70c21123a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_TO_MLFLOW:\n",
    "    for metric, metric_value in retrieval_eval_results_df.to_dict(orient='records')[0].items():\n",
    "        if metric in RETRIEVAL_METRICS:\n",
    "            mlflow.log_metric(f\"{metric_prefix}_{metric}\", metric_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e513ce-3f13-4cd1-bd2e-c37f4834f39e",
   "metadata": {},
   "source": [
    "### Manually curated dataset\n",
    "Ref: https://docs.llamaindex.ai/en/stable/module_guides/evaluating/usage_pattern_retrieval/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c90a243-f246-4802-8d95-f584e2d87be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MANUAL_EVAL_QA = [\n",
    "(\"What are key features of llama-agents?\",\n",
    "\"\"\"\n",
    "Key features of llama-agents are:\n",
    "1. Distributed Service Oriented Architecture: every agent in LlamaIndex can be its own independently running microservice, orchestrated by a fully customizable LLM-powered control plane that routes and distributes tasks.\n",
    "2. Communication via standardized API interfaces: interface between agents using a central control plane orchestrator. Pass messages between agents using a message queue.\n",
    "3. Define agentic and explicit orchestration flows: developers have the flexibility to directly define the sequence of interactions between agents, or leave it up to an “agentic orchestrator” that decides which agents are relevant to the task.\n",
    "4. Ease of deployment: launch, scale and monitor each agent and your control plane independently.\n",
    "5. Scalability and resource management: use our built-in observability tools to monitor the quality and performance of the system and each individual agent service\n",
    "\"\"\"\n",
    "),\n",
    "(\"What are the two critical areas of RAG system performance that are assessed in the 'Evaluating RAG with LlamaIndex' section of the OpenAI Cookbook?\",\n",
    "\"\"\"\n",
    "Retrieval System and Response Generation.\n",
    "\"\"\"\n",
    "),\n",
    "(\"What are the two main metrics used to evaluate the performance of the different rerankers in the RAG system?\",\n",
    "\"\"\"\n",
    "Hit rate and Mean Reciprocal Rank (MRR)\n",
    "\n",
    "Hit Rate: Hit rate calculates the fraction of queries where the correct answer is found within the top-k retrieved documents. In simpler terms, it’s about how often our system gets it right within the top few guesses.\n",
    "\n",
    "Mean Reciprocal Rank (MRR): For each query, MRR evaluates the system’s accuracy by looking at the rank of the highest-placed relevant document. Specifically, it’s the average of the reciprocals of these ranks across all the queries. So, if the first relevant document is the top result, the reciprocal rank is 1; if it’s second, the reciprocal rank is 1/2, and so on.\n",
    "\"\"\"\n",
    ")\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9499affa-46c9-409b-8712-59b403a95020",
   "metadata": {},
   "source": [
    "# TODO: Implement manual retrieval checks\n",
    "retriever_evaluator.evaluate(\n",
    "    query=\"query\", expected_ids=[\"node_id1\", \"node_id2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc8df9-d1eb-459b-bd34-222e27637b2f",
   "metadata": {},
   "source": [
    "## Response Evaluation\n",
    "Ref: https://docs.llamaindex.ai/en/stable/examples/llama_dataset/downloading_llama_datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2bcf3938-0f92-4fa0-97dc-483151fa64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_labelled_rag_dataset(response_eval_dataset, response_eval_prediction_dataset, dataset_name=\"synthetic\", batch_size=8, judge_model='gpt-3.5-turbo', cache_dp='.'):\n",
    "    # Instantiate the judges\n",
    "    judges = {\n",
    "        \"correctness\": CorrectnessEvaluator(\n",
    "            llm=OpenAI(temperature=0, model=judge_model),\n",
    "        ),\n",
    "        \"relevancy\": RelevancyEvaluator(\n",
    "            llm=OpenAI(temperature=0, model=judge_model),\n",
    "        ),\n",
    "        \"faithfulness\": FaithfulnessEvaluator(\n",
    "            llm=OpenAI(temperature=0, model=judge_model),\n",
    "        ),\n",
    "        \"semantic_similarity\": SemanticSimilarityEvaluator(),\n",
    "    }\n",
    "\n",
    "    # Initialize evaluations dictionary\n",
    "    evals = {\n",
    "        \"correctness\": [],\n",
    "        \"relevancy\": [],\n",
    "        \"faithfulness\": [],\n",
    "        \"contexts\": [],\n",
    "    }\n",
    "\n",
    "    # Evaluate each prediction\n",
    "    for example, prediction in tqdm(\n",
    "        zip(response_eval_dataset.examples, response_eval_prediction_dataset.predictions)\n",
    "    ):\n",
    "        correctness_result = judges[\"correctness\"].evaluate(\n",
    "            query=example.query,\n",
    "            response=prediction.response,\n",
    "            reference=example.reference_answer,\n",
    "        )\n",
    "\n",
    "        relevancy_result = judges[\"relevancy\"].evaluate(\n",
    "            query=example.query,\n",
    "            response=prediction.response,\n",
    "            contexts=prediction.contexts,\n",
    "        )\n",
    "\n",
    "        faithfulness_result = judges[\"faithfulness\"].evaluate(\n",
    "            query=example.query,\n",
    "            response=prediction.response,\n",
    "            contexts=prediction.contexts,\n",
    "        )\n",
    "\n",
    "        evals[\"correctness\"].append(correctness_result)\n",
    "        evals[\"relevancy\"].append(relevancy_result)\n",
    "        evals[\"faithfulness\"].append(faithfulness_result)\n",
    "        evals[\"contexts\"].append(prediction.contexts)\n",
    "\n",
    "    # Save evaluations to JSON\n",
    "    evaluations_objects = {\n",
    "        \"correctness\": [e.dict() for e in evals[\"correctness\"]],\n",
    "        \"faithfulness\": [e.dict() for e in evals[\"faithfulness\"]],\n",
    "        \"relevancy\": [e.dict() for e in evals[\"relevancy\"]],\n",
    "        \"contexts\": evals['contexts'],\n",
    "    }\n",
    "\n",
    "    with open(f\"{cache_dp}/{dataset_name}_evaluations.json\", \"w\") as json_file:\n",
    "        json.dump(evaluations_objects, json_file)\n",
    "\n",
    "    # Generate evaluation results DataFrames\n",
    "    deep_eval_correctness_df, mean_correctness_df = get_eval_results_df(\n",
    "        [\"base_rag\"] * len(evals[\"correctness\"]),\n",
    "        evals[\"correctness\"],\n",
    "        metric=\"correctness\",\n",
    "    )\n",
    "    deep_eval_relevancy_df, mean_relevancy_df = get_eval_results_df(\n",
    "        [\"base_rag\"] * len(evals[\"relevancy\"]),\n",
    "        evals[\"relevancy\"],\n",
    "        metric=\"relevancy\",\n",
    "    )\n",
    "    deep_eval_faithfulness_df, mean_faithfulness_df = get_eval_results_df(\n",
    "        [\"base_rag\"] * len(evals[\"faithfulness\"]),\n",
    "        evals[\"faithfulness\"],\n",
    "        metric=\"faithfulness\",\n",
    "    )\n",
    "\n",
    "    mean_scores_df = pd.concat(\n",
    "        [\n",
    "            mean_correctness_df.reset_index(),\n",
    "            mean_relevancy_df.reset_index(),\n",
    "            mean_faithfulness_df.reset_index(),\n",
    "        ],\n",
    "        axis=0,\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    mean_scores_df = mean_scores_df.set_index(\"index\")\n",
    "    mean_scores_df.index = mean_scores_df.index.set_names([\"metrics\"])\n",
    "\n",
    "    deep_eval_df = pd.concat([\n",
    "        deep_eval_correctness_df[['query', 'answer']],\n",
    "        deep_eval_relevancy_df[['scores']].rename(columns={'scores': 'relevancy_score'}),\n",
    "        deep_eval_correctness_df[['scores']].rename(columns={'scores': 'correctness_score'}),\n",
    "        deep_eval_faithfulness_df[['scores']].rename(columns={'scores': 'faithfulness_score'}),\n",
    "        pd.Series(evals['contexts'], name='contexts')\n",
    "    ], axis=1)\n",
    "\n",
    "    return mean_scores_df, deep_eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9375eec0-f1d5-44c2-8cdd-3a26746c2c8a",
   "metadata": {},
   "source": [
    "### Generate synthetic Llama Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66e51daa-8fa4-4ff1-af60-2cf77cc142b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n",
    "from llama_index.core.llama_dataset import LabeledRagDataset\n",
    "from llama_index.core.evaluation import (\n",
    "    CorrectnessEvaluator,\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    "    SemanticSimilarityEvaluator,\n",
    ")\n",
    "from llama_index.core.evaluation.notebook_utils import get_eval_results_df\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a1729a4-d78b-493d-a134-be20149e664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECREATE_SYNTHETIC_EVAL_DATASET = True\n",
    "RESPONSE_EVAL_DATASET_FP = f\"{NOTEBOOK_CACHE_DP}/llamaindex_blog_response_eval_dataset.json\"\n",
    "RESPONSE_EVAL_LLM_MODEL = 'gpt-3.5-turbo'\n",
    "RESPONSE_EVAL_LLM_MODEL_CONFIG = {\n",
    "    \"temperature\": 0.3\n",
    "}\n",
    "SYNTHETIC_RESPONSE_NUM_QUESTIONS_PER_CHUNK = 2\n",
    "RESPONSE_NUM_SAMPLE_DOCUMENTS = 10\n",
    "RESPONSE_NUM_SAMPLE_DOCUMENTS = min(len(documents), RESPONSE_NUM_SAMPLE_DOCUMENTS)\n",
    "\n",
    "if LOG_TO_MLFLOW:\n",
    "    mlflow.log_param(\"SYNTHETIC_RESPONSE_NUM_QUESTIONS_PER_CHUNK\", SYNTHETIC_RESPONSE_NUM_QUESTIONS_PER_CHUNK)\n",
    "    mlflow.log_param(\"RESPONSE_EVAL_LLM_MODEL\", RESPONSE_EVAL_LLM_MODEL)\n",
    "    mlflow.log_param(\"RESPONSE_NUM_SAMPLE_DOCUMENTS\", RESPONSE_NUM_SAMPLE_DOCUMENTS)\n",
    "    for k, v in RESPONSE_EVAL_LLM_MODEL_CONFIG.items():\n",
    "        mlflow.log_param(f\"RESPONSE_EVAL_LLM_MODEL_CONFIG__{k}\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d177516-86bc-4639-a185-65895add5c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 13:54:08.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mSampling 10 documents for response evaluation...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if RESPONSE_NUM_SAMPLE_DOCUMENTS:\n",
    "    logger.info(f\"Sampling {RESPONSE_NUM_SAMPLE_DOCUMENTS} documents for response evaluation...\")\n",
    "    np.random.seed(41)\n",
    "    response_eval_documents = np.random.choice(documents, RESPONSE_NUM_SAMPLE_DOCUMENTS)\n",
    "else:\n",
    "    logger.info(f\"Using all documents for retrieval evaluation\")\n",
    "    response_eval_documents = documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8251b70-e28e-4b6a-aec7-b0d0fcf61020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-07-23 13:54:10.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mCreating synthetic response eval dataset...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13664dd5c422470e9feffe636d0e2f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Adding chunk: LlamaIndex Newsletter 2024-03-05\n",
      "Greetings, Lla...\n",
      "> Adding chunk: OpenAI Cookbook: Evaluating RAG systems\n",
      "We’re e...\n",
      "> Adding chunk: LlamaIndex turns 1!\n",
      "It’s our birthday! One year...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–12–19\n",
      "What’s up, Lla...\n",
      "> Adding chunk: 👀 Community Demos : MemoryCache: Mozilla’s new ...\n",
      "> Adding chunk: The latest updates to LlamaCloud\n",
      "To build a pro...\n",
      "> Adding chunk: Build and Evaluate LLM Apps with LlamaIndex and...\n",
      "> Adding chunk: Finally, the third feedback function checks how...\n",
      "> Adding chunk: Agentic RAG With LlamaIndex\n",
      "The topic of Agenti...\n",
      "> Adding chunk: These connectors can work with\n",
      "  APIs, PDFs, SQ...\n",
      "> Adding chunk: LlamaIndex Accelerates Enterprise Generative AI...\n",
      "> Adding chunk: Introducing Llama Packs\n",
      "Today we’re excited to ...\n",
      "> Adding chunk: Special thanks to Logan Markewich and Andrei Fa...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–11–14\n",
      "Hello Llama Fr...\n",
      "> Adding chunk: Finally, we released a guide to craft a GPT Bui...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-03-05\n",
      "Greetings, Lla...\n",
      "> Adding chunk: OpenAI Cookbook: Evaluating RAG systems\n",
      "We’re e...\n",
      "> Adding chunk: LlamaIndex turns 1!\n",
      "It’s our birthday! One year...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–12–19\n",
      "What’s up, Lla...\n",
      "> Adding chunk: 👀 Community Demos : MemoryCache: Mozilla’s new ...\n",
      "> Adding chunk: The latest updates to LlamaCloud\n",
      "To build a pro...\n",
      "> Adding chunk: Build and Evaluate LLM Apps with LlamaIndex and...\n",
      "> Adding chunk: Finally, the third feedback function checks how...\n",
      "> Adding chunk: Agentic RAG With LlamaIndex\n",
      "The topic of Agenti...\n",
      "> Adding chunk: These connectors can work with\n",
      "  APIs, PDFs, SQ...\n",
      "> Adding chunk: LlamaIndex Accelerates Enterprise Generative AI...\n",
      "> Adding chunk: Introducing Llama Packs\n",
      "Today we’re excited to ...\n",
      "> Adding chunk: Special thanks to Logan Markewich and Andrei Fa...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–11–14\n",
      "Hello Llama Fr...\n",
      "> Adding chunk: Finally, we released a guide to craft a GPT Bui...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                          | 6/15 [00:07<00:10,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.08747687122671666 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You have been rate limited. Your rate limit is 60 queries per minute. Please navigate to https://api.together.xyz/settings/billing to upgrade to a paid plan.', 'type': 'credit_limit', 'param': None, 'code': None}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:19<00:00,  1.32s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.19s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.26s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.24s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.71s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.01s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.09s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.49s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.27s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.72s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.19s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "if RECREATE_SYNTHETIC_EVAL_DATASET or not os.path.exists(RESPONSE_EVAL_DATASET_FP):\n",
    "    logger.info(f\"Creating synthetic response eval dataset...\")\n",
    "    # set context for llm provider\n",
    "    response_eval_llm = OpenAI(model=RESPONSE_EVAL_LLM_MODEL, **RESPONSE_EVAL_LLM_MODEL_CONFIG)\n",
    "\n",
    "    # instantiate a DatasetGenerator\n",
    "    response_dataset_generator = RagDatasetGenerator.from_documents(\n",
    "        response_eval_documents,\n",
    "        llm=llm,\n",
    "        num_questions_per_chunk=SYNTHETIC_RESPONSE_NUM_QUESTIONS_PER_CHUNK,  # set the number of questions per nodes\n",
    "        show_progress=True,\n",
    "    )\n",
    "\n",
    "    synthetic_response_eval_dataset = response_dataset_generator.generate_dataset_from_nodes()\n",
    "\n",
    "    synthetic_response_eval_dataset.save_json(RESPONSE_EVAL_DATASET_FP)\n",
    "else:\n",
    "    logger.info(f\"Loading existing synthetic response eval dataset at {RESPONSE_EVAL_DATASET_FP}...\")\n",
    "    synthetic_response_eval_dataset = LabeledRagDataset.from_json(RESPONSE_EVAL_DATASET_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940feda2-1aad-427c-895f-2d4cdf43918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_response_eval_prediction_dataset = await synthetic_response_eval_dataset.amake_predictions_with(\n",
    "    predictor=query_engine, batch_size=8, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab082f5e-59a4-4401-9ced-0394bf4ab869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:   0%|                                                                                                                                                                                                               | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 2 nodes:\n",
      "> [Node e009b8ae-616f-47c3-9cf9-20fa1c683ac3] [Similarity score:             0.701982] OpenAI Cookbook: Evaluating RAG systems\n",
      "We’re excited to unveil our  OpenAI Cookbook , a guide to...\n",
      "> [Node ed16c24c-937b-4bbb-80d7-dd33ea873087] [Similarity score:             0.697224] ) returns a document that describes Paul’s first programs: Node ID: 380fbb0e-6fc1-41de-a4f6-3f22c...\n",
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.757286] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.754412] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node 99874c4e-123d-4d24-b677-f4d581b37bd7] [Similarity score:             0.789413] LlamaIndex turns 1!\n",
      "It’s our birthday! One year ago, Jerry pushed his  first commit  to GPT Index...\n",
      "> [Node 0b40dc8d-ea6a-4d0e-a58d-b554104659e0] [Similarity score:             0.751507] The endpoint on HF is served on AWS Nvidia A100G · 1x GPU · 80 GB which costs $6.5/h. (We extend ...\n",
      "> Top 2 nodes:\n",
      "> [Node 486b3118-3b2d-455d-bcea-8dc8e0db26d2] [Similarity score:             0.783261] The retrieval approach entailed segmenting each document into 300-word sections, encoding both qu...\n",
      "> [Node e149477d-6dc2-4238-9b63-18878e66cc45] [Similarity score:             0.759313] One is indexing document summaries and linking them to documents, and the other is indexing small...\n",
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.757286] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.754412] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.757286] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.754412] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node 89285fc8-241c-41b1-b377-1d49ceccbae1] [Similarity score:             0.85063] Tweet . We introduced day-0 integrations with the MistralAI LLMs (mistral-tiny, mistral-small, mi...\n",
      "> [Node 0d1ce744-a52e-4aac-b0ec-052b318fd09a] [Similarity score:             0.836969] Ross A.’s  tutorial  on retrieval evaluations for RAG delves into essential metrics like precisio...\n",
      "> Top 2 nodes:\n",
      "> [Node 618ad8e0-394a-435e-90b3-188ec0f36be2] [Similarity score:             0.838997] LlamaIndex newsletter 2023–10–24\n",
      "Hello Llama Fans 🦙! Welcome back to our newsletter covering new ...\n",
      "> [Node 54dc7222-7171-469d-b84b-382ccaf73bf3] [Similarity score:             0.837145] Notebook ,  Tweet . RAGatouille LlamaPack : Introduction of an easy-to-use pack for ColBERT retri...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  50%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                   | 4/8 [00:05<00:04,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8273668115595825 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You have been rate limited. Your rate limit is 60 queries per minute. Please navigate to https://api.together.xyz/settings/billing to upgrade to a paid plan.', 'type': 'credit_limit', 'param': None, 'code': None}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.6818801269681636 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You have been rate limited. Your rate limit is 60 queries per minute. Please navigate to https://api.together.xyz/settings/billing to upgrade to a paid plan.', 'type': 'credit_limit', 'param': None, 'code': None}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:11<00:00,  1.43s/it]\n",
      "Batch processing of predictions:   0%|                                                                                                                                                                                                               | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.668279] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.664631] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.756688] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.752196] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node 486b3118-3b2d-455d-bcea-8dc8e0db26d2] [Similarity score:             0.783261] The retrieval approach entailed segmenting each document into 300-word sections, encoding both qu...\n",
      "> [Node e149477d-6dc2-4238-9b63-18878e66cc45] [Similarity score:             0.759313] One is indexing document summaries and linking them to documents, and the other is indexing small...\n",
      "> Top 2 nodes:\n",
      "> [Node 3480df1a-0e04-4045-a787-45123719d7e5] [Similarity score:             0.759411] Wrap A LlamaIndex App with TruLens With TruLens, you can wrap LlamaIndex query engines with a Tru...\n",
      "> [Node dbba146b-8249-4221-a2b6-0e5475bd9e17] [Similarity score:             0.739854] min )\n",
      "\n",
      "\n",
      "feedbacks = [f_lang_match, f_qa_relevance, f_qs_relevance]\n",
      "\n",
      "l = TruLlama(app=query_engine...\n",
      "> Top 2 nodes:\n",
      "> [Node 99874c4e-123d-4d24-b677-f4d581b37bd7] [Similarity score:             0.76815] LlamaIndex turns 1!\n",
      "It’s our birthday! One year ago, Jerry pushed his  first commit  to GPT Index...\n",
      "> [Node 512059ff-4499-40e6-aee6-27aec88756bc] [Similarity score:             0.767752] LlamaIndex Newsletter 2024-03-26\n",
      "Hi there, LlamaIndex followers! 🦙 Welcome to another thrilling w...\n",
      "> Top 2 nodes:\n",
      "> [Node 40199aa8-9828-445e-847e-c187d990f99e] [Similarity score:             0.745815] If you’re new to LlamaIndex, it’s a Python and JavaScript framework that lets you quickly put tog...\n",
      "> [Node d399ae45-6a78-471d-aca2-8e68f08ecc0b] [Similarity score:             0.728537] Build and Evaluate LLM Apps with LlamaIndex and TruLens\n",
      "Authors:  Anupam Datta, Shayak Sen, Jerry...\n",
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.756688] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.752196] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node 810ad5e5-7513-4136-a496-aec19b6fd7e4] [Similarity score:             0.776433] Want to discuss unlimited commercial use?  Contact us  and let's chat! Note: we support private d...\n",
      "> [Node 5e93d815-9777-48e1-83a6-194d4554687a] [Similarity score:             0.759384] The Rise of Centralized Knowledge Management We have designed LlamaCloud to cater to the need of ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  50%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                   | 4/8 [00:07<00:07,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.10209788798295549 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You have been rate limited. Your rate limit is 60 queries per minute. Please navigate to https://api.together.xyz/settings/billing to upgrade to a paid plan.', 'type': 'credit_limit', 'param': None, 'code': None}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.7265954352427538 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You have been rate limited. Your rate limit is 60 queries per minute. Please navigate to https://api.together.xyz/settings/billing to upgrade to a paid plan.', 'type': 'credit_limit', 'param': None, 'code': None}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:12<00:00,  1.54s/it]\n",
      "Batch processing of predictions:   0%|                                                                                                                                                                                                               | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 2 nodes:\n",
      "> [Node c0f25679-dadc-4957-bf94-6e728db1b6e7] [Similarity score:             0.814899] source  import  MyCustomSource  # plug in your own source here \n",
      "AirbyteCDKReader = download_loade...\n",
      "> [Node 6ae590fb-9f0f-419d-9ce0-1011a0b3c859] [Similarity score:             0.812255] With this release, it’s easier than ever to run any Python-based source in LlamaIndex directly wi...\n",
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.757286] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.754412] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node 20fb7280-8799-4c3d-a9dd-abdf004781e5] [Similarity score:             0.795988] Unlocking the 3rd Dimension for Generative AI (Part 1)\n",
      "It would be an understatement to say that ...\n",
      "> [Node 8bbe75ab-315d-4608-97c1-0764ffd3efe4] [Similarity score:             0.784001] This approach offers a more direct and potentially more powerful method for generating complex de...\n",
      "> Top 2 nodes:\n",
      "> [Node fa4d2de7-b6aa-4a80-b679-e792f357768e] [Similarity score:             0.826858] Utilizing LlamaIndex\n",
      "      connectors allows you to seamlessly integrate your data into the\n",
      "     ...\n",
      "> [Node 390ed7c9-6024-4f86-bcca-5eba197a02d3] [Similarity score:             0.811783] Agentic RAG With LlamaIndex\n",
      "The topic of Agentic RAG explores how agents can be incorporated into...\n",
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.756688] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.752196] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.756688] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.752196] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node 486b3118-3b2d-455d-bcea-8dc8e0db26d2] [Similarity score:             0.783261] The retrieval approach entailed segmenting each document into 300-word sections, encoding both qu...\n",
      "> [Node e149477d-6dc2-4238-9b63-18878e66cc45] [Similarity score:             0.759313] One is indexing document summaries and linking them to documents, and the other is indexing small...\n",
      "> Top 2 nodes:\n",
      "> [Node ed16c24c-937b-4bbb-80d7-dd33ea873087] [Similarity score:             0.711259] ) returns a document that describes Paul’s first programs: Node ID: 380fbb0e-6fc1-41de-a4f6-3f22c...\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.705386] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  38%|██████████████████████████████████████████████████████████████████████████▋                                                                                                                            | 3/8 [00:04<00:08,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.9333980479954174 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You have been rate limited. Your rate limit is 60 queries per minute. Please navigate to https://api.together.xyz/settings/billing to upgrade to a paid plan.', 'type': 'credit_limit', 'param': None, 'code': None}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.03660077212470314 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You have been rate limited. Your rate limit is 60 queries per minute. Please navigate to https://api.together.xyz/settings/billing to upgrade to a paid plan.', 'type': 'credit_limit', 'param': None, 'code': None}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:11<00:00,  1.46s/it]\n",
      "Batch processing of predictions:   0%|                                                                                                                                                                                                               | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 2 nodes:\n",
      "> [Node 486b3118-3b2d-455d-bcea-8dc8e0db26d2] [Similarity score:             0.783261] The retrieval approach entailed segmenting each document into 300-word sections, encoding both qu...\n",
      "> [Node e149477d-6dc2-4238-9b63-18878e66cc45] [Similarity score:             0.759313] One is indexing document summaries and linking them to documents, and the other is indexing small...\n",
      "> Top 2 nodes:\n",
      "> [Node 7f51966e-f508-4e4d-9103-b9ae9d81d6c3] [Similarity score:             0.804341] We also offer an extensive array of integrations with other storage providers and downstream appl...\n",
      "> [Node e70db3b1-e06a-4d17-b88d-6da062fa67ca] [Similarity score:             0.794489] Building the data framework for LLMs\n",
      "Today is an exciting day for LlamaIndex, and a big milestone...\n",
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.756688] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.752196] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node aaa56eee-5b1d-485a-b5f0-9905948c448a] [Similarity score:             0.756688] Generate Answers/Source Nodes (Context) Using List Index, we generate answers and source nodes fo...\n",
      "> [Node eb2e69f6-6d0d-4810-bda8-b272aa270dc9] [Similarity score:             0.752196] Building and Evaluating a QA System with LlamaIndex\n",
      "Introduction LlamaIndex (GPT Index)  offers a...\n",
      "> Top 2 nodes:\n",
      "> [Node 839ad04f-5520-4423-ae2d-cf7911106a8a] [Similarity score:             0.793203] Introducing Llama Packs\n",
      "Today we’re excited to introduce  Llama Packs 🦙📦—  a community-driven hub...\n",
      "> [Node 771cea2f-164f-43dc-9483-97c64608a538] [Similarity score:             0.785051] They can be downloaded either through our  llama_index  Python library or the CLI in  one line of...\n",
      "> Top 2 nodes:\n",
      "> [Node 99874c4e-123d-4d24-b677-f4d581b37bd7] [Similarity score:             0.785477] LlamaIndex turns 1!\n",
      "It’s our birthday! One year ago, Jerry pushed his  first commit  to GPT Index...\n",
      "> [Node 6495a402-9686-43f5-baf9-6a4c6f1513bf] [Similarity score:             0.776818] LlamaIndex Newsletter 2024-05-14\n",
      "Hello LlamaIndex Family! 🦙 Welcome to another thrilling weekly u...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:09<00:00,  1.56s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95910d4e661a4b4db14eb2c678cc0f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: LlamaIndex newsletter 2023–10–24\n",
      "Hello Llama Fa...\n",
      "> Adding chunk: Notebook ,  Tweet . RAGatouille LlamaPack : Int...\n",
      "> Adding chunk: LlamaIndex newsletter 2023–10–24\n",
      "Hello Llama Fa...\n",
      "> Adding chunk: Notebook ,  Tweet . RAGatouille LlamaPack : Int...\n",
      "> Adding chunk: The retrieval approach entailed segmenting each...\n",
      "> Adding chunk: One is indexing document summaries and linking ...\n",
      "> Adding chunk: The retrieval approach entailed segmenting each...\n",
      "> Adding chunk: One is indexing document summaries and linking ...\n",
      "> Adding chunk: OpenAI Cookbook: Evaluating RAG systems\n",
      "We’re e...\n",
      "> Adding chunk: ) returns a document that describes Paul’s firs...\n",
      "> Adding chunk: OpenAI Cookbook: Evaluating RAG systems\n",
      "We’re e...\n",
      "> Adding chunk: ) returns a document that describes Paul’s firs...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: LlamaIndex turns 1!\n",
      "It’s our birthday! One year...\n",
      "> Adding chunk: The endpoint on HF is served on AWS Nvidia A100...\n",
      "> Adding chunk: LlamaIndex turns 1!\n",
      "It’s our birthday! One year...\n",
      "> Adding chunk: The endpoint on HF is served on AWS Nvidia A100...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Tweet . We introduced day-0 integrations with t...\n",
      "> Adding chunk: Ross A.’s  tutorial  on retrieval evaluations f...\n",
      "> Adding chunk: Tweet . We introduced day-0 integrations with t...\n",
      "> Adding chunk: Ross A.’s  tutorial  on retrieval evaluations f...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: LlamaIndex turns 1!\n",
      "It’s our birthday! One year...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-03-26\n",
      "Hi there, Llam...\n",
      "> Adding chunk: LlamaIndex turns 1!\n",
      "It’s our birthday! One year...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-03-26\n",
      "Hi there, Llam...\n",
      "> Adding chunk: The retrieval approach entailed segmenting each...\n",
      "> Adding chunk: One is indexing document summaries and linking ...\n",
      "> Adding chunk: The retrieval approach entailed segmenting each...\n",
      "> Adding chunk: One is indexing document summaries and linking ...\n",
      "> Adding chunk: Want to discuss unlimited commercial use?  Cont...\n",
      "> Adding chunk: The Rise of Centralized Knowledge Management We...\n",
      "> Adding chunk: Want to discuss unlimited commercial use?  Cont...\n",
      "> Adding chunk: The Rise of Centralized Knowledge Management We...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: If you’re new to LlamaIndex, it’s a Python and ...\n",
      "> Adding chunk: Build and Evaluate LLM Apps with LlamaIndex and...\n",
      "> Adding chunk: If you’re new to LlamaIndex, it’s a Python and ...\n",
      "> Adding chunk: Build and Evaluate LLM Apps with LlamaIndex and...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Wrap A LlamaIndex App with TruLens With TruLens...\n",
      "> Adding chunk: min )\n",
      "\n",
      "\n",
      "feedbacks = [f_lang_match, f_qa_relevan...\n",
      "> Adding chunk: Wrap A LlamaIndex App with TruLens With TruLens...\n",
      "> Adding chunk: min )\n",
      "\n",
      "\n",
      "feedbacks = [f_lang_match, f_qa_relevan...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Utilizing LlamaIndex\n",
      "      connectors allows yo...\n",
      "> Adding chunk: Agentic RAG With LlamaIndex\n",
      "The topic of Agenti...\n",
      "> Adding chunk: Utilizing LlamaIndex\n",
      "      connectors allows yo...\n",
      "> Adding chunk: Agentic RAG With LlamaIndex\n",
      "The topic of Agenti...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: source  import  MyCustomSource  # plug in your ...\n",
      "> Adding chunk: With this release, it’s easier than ever to run...\n",
      "> Adding chunk: source  import  MyCustomSource  # plug in your ...\n",
      "> Adding chunk: With this release, it’s easier than ever to run...\n",
      "> Adding chunk: The retrieval approach entailed segmenting each...\n",
      "> Adding chunk: One is indexing document summaries and linking ...\n",
      "> Adding chunk: The retrieval approach entailed segmenting each...\n",
      "> Adding chunk: One is indexing document summaries and linking ...\n",
      "> Adding chunk: Unlocking the 3rd Dimension for Generative AI (...\n",
      "> Adding chunk: This approach offers a more direct and potentia...\n",
      "> Adding chunk: Unlocking the 3rd Dimension for Generative AI (...\n",
      "> Adding chunk: This approach offers a more direct and potentia...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: ) returns a document that describes Paul’s firs...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: ) returns a document that describes Paul’s firs...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Introducing Llama Packs\n",
      "Today we’re excited to ...\n",
      "> Adding chunk: They can be downloaded either through our  llam...\n",
      "> Adding chunk: Introducing Llama Packs\n",
      "Today we’re excited to ...\n",
      "> Adding chunk: They can be downloaded either through our  llam...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: Generate Answers/Source Nodes (Context) Using L...\n",
      "> Adding chunk: Building and Evaluating a QA System with LlamaI...\n",
      "> Adding chunk: We also offer an extensive array of integration...\n",
      "> Adding chunk: Building the data framework for LLMs\n",
      "Today is a...\n",
      "> Adding chunk: We also offer an extensive array of integration...\n",
      "> Adding chunk: Building the data framework for LLMs\n",
      "Today is a...\n",
      "> Adding chunk: The retrieval approach entailed segmenting each...\n",
      "> Adding chunk: One is indexing document summaries and linking ...\n",
      "> Adding chunk: The retrieval approach entailed segmenting each...\n",
      "> Adding chunk: One is indexing document summaries and linking ...\n",
      "> Adding chunk: LlamaIndex turns 1!\n",
      "It’s our birthday! One year...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-05-14\n",
      "Hello LlamaInd...\n",
      "> Adding chunk: LlamaIndex turns 1!\n",
      "It’s our birthday! One year...\n",
      "> Adding chunk: LlamaIndex Newsletter 2024-05-14\n",
      "Hello LlamaInd...\n"
     ]
    }
   ],
   "source": [
    "synthetic_mean_scores_df, synthetic_deep_eval_df = evaluate_labelled_rag_dataset(\n",
    "    synthetic_response_eval_dataset,\n",
    "    synthetic_response_eval_prediction_dataset,\n",
    "    dataset_name=\"synthetic\",\n",
    "    judge_model=RESPONSE_EVAL_LLM_MODEL,\n",
    "    cache_dp=NOTEBOOK_CACHE_DP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59356440-eef4-4670-b28f-43d23f1aa803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rag</th>\n",
       "      <th>base_rag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_correctness_score</th>\n",
       "      <td>2.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_relevancy_score</th>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_faithfulness_score</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rag                      base_rag\n",
       "metrics                          \n",
       "mean_correctness_score   2.616667\n",
       "mean_relevancy_score     0.766667\n",
       "mean_faithfulness_score  0.666667"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_mean_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84ed66a8-b590-4195-8416-75b660c13490",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>relevancy_score</th>\n",
       "      <th>correctness_score</th>\n",
       "      <th>faithfulness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on the context information, I've generat...</td>\n",
       "      <td>I'd be happy to help! Based on the context, I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>**Question 1:** What is the new feature releas...</td>\n",
       "      <td>There is no new feature released in LlamaIndex...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here are two questions based on the context in...</td>\n",
       "      <td>Here are the answers to the two questions base...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>**Question 1:** What is the primary goal of th...</td>\n",
       "      <td>To provide the community with an essential res...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on the context information, I've generat...</td>\n",
       "      <td>I'd be happy to help!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>**Question 1:** What is the primary limitation...</td>\n",
       "      <td>The primary limitation of GPT-3, according to ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Based on the context information, I've generat...</td>\n",
       "      <td>I'd be happy to help!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>**Question 1:** What is the name of the new da...</td>\n",
       "      <td>The new dataset launched by LlamaIndex in coll...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Based on the context information, I've generat...</td>\n",
       "      <td>I'd be happy to help!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>**Question 1:** What is the name of the experi...</td>\n",
       "      <td>There is no information in the provided contex...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Here are two questions based on the context in...</td>\n",
       "      <td>Here are the answers to the two questions base...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>**Question 1:** What is the primary purpose of...</td>\n",
       "      <td>The primary purpose of LlamaCloud is to cater ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Based on the context information, I'll generat...</td>\n",
       "      <td>Here are two questions based on the context in...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What is the primary purpose of the LlamaIndex ...</td>\n",
       "      <td>The primary purpose of the LlamaIndex and TruL...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Based on the context information, I've generat...</td>\n",
       "      <td>I'd be happy to help you with that!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>**Question 1:** What is the purpose of the fee...</td>\n",
       "      <td>The purpose of the feedback function `f_qs_rel...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Based on the context information, I've generat...</td>\n",
       "      <td>I'd be happy to help!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>**Question 1:** What is the primary purpose of...</td>\n",
       "      <td>The primary purpose of the Agentic RAG approac...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Based on the context information, I've generat...</td>\n",
       "      <td>I'd be happy to help! Based on the context, I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>**Question 1:** What type of data sources are ...</td>\n",
       "      <td>Python-based sources.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Here are two questions based on the context in...</td>\n",
       "      <td>Here are the answers to the two questions base...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>**Question 1:** What is the primary challenge ...</td>\n",
       "      <td>The primary challenge that enterprises face wh...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Based on the context information, I've generat...</td>\n",
       "      <td>I'd be happy to help!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>**Question 1:**</td>\n",
       "      <td>What did Paul work on before college?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Based on the context information, I've generat...</td>\n",
       "      <td>I'd be happy to help you with that!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>**Question 1:** What is the primary purpose of...</td>\n",
       "      <td>The primary purpose of the `get_modules()` fun...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Based on the context information, I've generat...</td>\n",
       "      <td>I'd be happy to help you with that!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>**Question 1:** What is the name of the projec...</td>\n",
       "      <td>The project that merges LLM fine-tuning with k...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Here are two questions based on the context in...</td>\n",
       "      <td>Here are the answers to the two questions base...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>**Question 1:** What is the main purpose of th...</td>\n",
       "      <td>The main purpose of the GPT-4o support release...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0   Based on the context information, I've generat...   \n",
       "1   **Question 1:** What is the new feature releas...   \n",
       "2   Here are two questions based on the context in...   \n",
       "3   **Question 1:** What is the primary goal of th...   \n",
       "4   Based on the context information, I've generat...   \n",
       "5   **Question 1:** What is the primary limitation...   \n",
       "6   Based on the context information, I've generat...   \n",
       "7   **Question 1:** What is the name of the new da...   \n",
       "8   Based on the context information, I've generat...   \n",
       "9   **Question 1:** What is the name of the experi...   \n",
       "10  Here are two questions based on the context in...   \n",
       "11  **Question 1:** What is the primary purpose of...   \n",
       "12  Based on the context information, I'll generat...   \n",
       "13  What is the primary purpose of the LlamaIndex ...   \n",
       "14  Based on the context information, I've generat...   \n",
       "15  **Question 1:** What is the purpose of the fee...   \n",
       "16  Based on the context information, I've generat...   \n",
       "17  **Question 1:** What is the primary purpose of...   \n",
       "18  Based on the context information, I've generat...   \n",
       "19  **Question 1:** What type of data sources are ...   \n",
       "20  Here are two questions based on the context in...   \n",
       "21  **Question 1:** What is the primary challenge ...   \n",
       "22  Based on the context information, I've generat...   \n",
       "23                                    **Question 1:**   \n",
       "24  Based on the context information, I've generat...   \n",
       "25  **Question 1:** What is the primary purpose of...   \n",
       "26  Based on the context information, I've generat...   \n",
       "27  **Question 1:** What is the name of the projec...   \n",
       "28  Here are two questions based on the context in...   \n",
       "29  **Question 1:** What is the main purpose of th...   \n",
       "\n",
       "                                               answer  relevancy_score  \\\n",
       "0   I'd be happy to help! Based on the context, I ...              1.0   \n",
       "1   There is no new feature released in LlamaIndex...              0.0   \n",
       "2   Here are the answers to the two questions base...              1.0   \n",
       "3   To provide the community with an essential res...              0.0   \n",
       "4                               I'd be happy to help!              1.0   \n",
       "5   The primary limitation of GPT-3, according to ...              1.0   \n",
       "6                               I'd be happy to help!              1.0   \n",
       "7   The new dataset launched by LlamaIndex in coll...              0.0   \n",
       "8                               I'd be happy to help!              1.0   \n",
       "9   There is no information in the provided contex...              0.0   \n",
       "10  Here are the answers to the two questions base...              1.0   \n",
       "11  The primary purpose of LlamaCloud is to cater ...              1.0   \n",
       "12  Here are two questions based on the context in...              1.0   \n",
       "13  The primary purpose of the LlamaIndex and TruL...              1.0   \n",
       "14                I'd be happy to help you with that!              1.0   \n",
       "15  The purpose of the feedback function `f_qs_rel...              1.0   \n",
       "16                              I'd be happy to help!              1.0   \n",
       "17  The primary purpose of the Agentic RAG approac...              1.0   \n",
       "18  I'd be happy to help! Based on the context, I ...              1.0   \n",
       "19                              Python-based sources.              0.0   \n",
       "20  Here are the answers to the two questions base...              1.0   \n",
       "21  The primary challenge that enterprises face wh...              1.0   \n",
       "22                              I'd be happy to help!              1.0   \n",
       "23              What did Paul work on before college?              1.0   \n",
       "24                I'd be happy to help you with that!              1.0   \n",
       "25  The primary purpose of the `get_modules()` fun...              0.0   \n",
       "26                I'd be happy to help you with that!              1.0   \n",
       "27  The project that merges LLM fine-tuning with k...              0.0   \n",
       "28  Here are the answers to the two questions base...              1.0   \n",
       "29  The main purpose of the GPT-4o support release...              1.0   \n",
       "\n",
       "    correctness_score  faithfulness_score  \n",
       "0                 3.5                 1.0  \n",
       "1                 2.0                 1.0  \n",
       "2                 3.0                 1.0  \n",
       "3                 3.5                 1.0  \n",
       "4                 3.0                 0.0  \n",
       "5                 4.0                 1.0  \n",
       "6                 1.0                 0.0  \n",
       "7                 4.5                 1.0  \n",
       "8                 1.0                 0.0  \n",
       "9                 1.0                 1.0  \n",
       "10                3.0                 1.0  \n",
       "11                4.5                 1.0  \n",
       "12                4.0                 1.0  \n",
       "13                4.5                 1.0  \n",
       "14                3.0                 0.0  \n",
       "15                3.5                 1.0  \n",
       "16                2.0                 0.0  \n",
       "17                4.0                 1.0  \n",
       "18                4.0                 1.0  \n",
       "19                2.0                 1.0  \n",
       "20                1.0                 1.0  \n",
       "21                2.5                 1.0  \n",
       "22                1.0                 0.0  \n",
       "23                1.0                 1.0  \n",
       "24                1.0                 0.0  \n",
       "25                2.0                 1.0  \n",
       "26                2.0                 0.0  \n",
       "27                1.0                 0.0  \n",
       "28                3.5                 0.0  \n",
       "29                2.5                 1.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_deep_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a143069-ea8a-4474-ba4a-c9f9d24dab9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if LOG_TO_MLFLOW:\n",
    "    for k, v in synthetic_mean_scores_df.T.to_dict(orient='records')[0].items():\n",
    "        mlflow.log_metric(f\"synthetic_response_eval__{k}\", v)\n",
    "    synthetic_deep_eval_df.to_html(f\"{NOTEBOOK_CACHE_DP}/synthetic_deep_eval_df.html\")\n",
    "    mlflow.log_artifact(f\"{NOTEBOOK_CACHE_DP}/synthetic_deep_eval_df.html\", \"synthetic_deep_eval_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0abbb7-0382-4bc6-b1be-1ac4f6245dc9",
   "metadata": {},
   "source": [
    "### Manually curated\n",
    "Ref: https://docs.llamaindex.ai/en/stable/examples/llama_dataset/ragdataset_submission_template/#1c-creating-a-labelledragdataset-from-scratch-with-manually-constructed-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e9113fa-4915-4c59-9039-d461b98c1e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset import LabelledRagDataset, LabelledRagDataExample, CreatedBy, CreatedByType\n",
    "\n",
    "examples = []\n",
    "\n",
    "for question, expected_anwser in MANUAL_EVAL_QA:\n",
    "    example = LabelledRagDataExample(\n",
    "        query=question,\n",
    "        query_by=CreatedBy(type=CreatedByType.HUMAN),\n",
    "        reference_answer=expected_anwser,\n",
    "        reference_answer_by=CreatedBy(type=CreatedByType.HUMAN),\n",
    "        reference_contexts=[],\n",
    "    )\n",
    "    examples.append(example)\n",
    "\n",
    "curated_response_eval_dataset = LabelledRagDataset(examples=examples)\n",
    "\n",
    "# save this dataset as it is required for the submission\n",
    "curated_response_eval_dataset.save_json(f\"{NOTEBOOK_CACHE_DP}/curated_response_eval_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2876bc3c-251b-4686-9321-6a7a0c081019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:   0%|                                                                                                                                                                                                               | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 2 nodes:\n",
      "> [Node e009b8ae-616f-47c3-9cf9-20fa1c683ac3] [Similarity score:             0.855356] OpenAI Cookbook: Evaluating RAG systems\n",
      "We’re excited to unveil our  OpenAI Cookbook , a guide to...\n",
      "> [Node 0020f723-6a45-4396-9543-f414375e8936] [Similarity score:             0.781137] LlamaIndex Newsletter 2023–12–05\n",
      "Hello Llama Community 🦙, We are excited to collaborate with Deep...\n",
      "> Top 2 nodes:\n",
      "> [Node 685a355d-9332-41a9-96bd-a4903ec86777] [Similarity score:             0.824755] Implemented by the user.\n",
      "\n",
      "        \"\"\" \n",
      "         return  self._retrieve(query_bundle)\n",
      "\n",
      "     async ...\n",
      "> [Node d175dd37-b2cb-4772-9709-4cc90227bac0] [Similarity score:             0.81401] # Extract keys from queries and relevant_docs that need to be removed \n",
      "    queries_relevant_docs_...\n",
      "> Top 2 nodes:\n",
      "> [Node 78ead847-3d01-4db3-8483-59a88f95b1d7] [Similarity score:             0.797389] First we’ll bring in our dependencies and set up our control plane, which contains our LLM-powere...\n",
      "> [Node 9929ccb4-3d3b-4e9d-80ac-dc86ff8df3c1] [Similarity score:             0.793224] Introducing llama-agents: A Powerful Framework for Building Production Multi-Agent AI Systems\n",
      "We'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "curated_response_eval_prediction_dataset = await curated_response_eval_dataset.amake_predictions_with(\n",
    "    predictor=query_engine, batch_size=8, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7ac08e37-3c76-4318-988f-1d2a4acf9223",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3968fb54d9004770b2e38fc08c11c875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Adding chunk: First we’ll bring in our dependencies and set u...\n",
      "> Adding chunk: Introducing llama-agents: A Powerful Framework ...\n",
      "> Adding chunk: First we’ll bring in our dependencies and set u...\n",
      "> Adding chunk: Introducing llama-agents: A Powerful Framework ...\n",
      "> Adding chunk: OpenAI Cookbook: Evaluating RAG systems\n",
      "We’re e...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–12–05\n",
      "Hello Llama Co...\n",
      "> Adding chunk: OpenAI Cookbook: Evaluating RAG systems\n",
      "We’re e...\n",
      "> Adding chunk: LlamaIndex Newsletter 2023–12–05\n",
      "Hello Llama Co...\n",
      "> Adding chunk: Implemented by the user.\n",
      "\n",
      "        \"\"\" \n",
      "        ...\n",
      "> Adding chunk: # Extract keys from queries and relevant_docs t...\n",
      "> Adding chunk: Implemented by the user.\n",
      "\n",
      "        \"\"\" \n",
      "        ...\n",
      "> Adding chunk: # Extract keys from queries and relevant_docs t...\n"
     ]
    }
   ],
   "source": [
    "curated_mean_scores_df, curated_deep_eval_df = evaluate_labelled_rag_dataset(\n",
    "    curated_response_eval_dataset,\n",
    "    curated_response_eval_prediction_dataset,\n",
    "    dataset_name=\"curated\",\n",
    "    judge_model=RESPONSE_EVAL_LLM_MODEL,\n",
    "    cache_dp=NOTEBOOK_CACHE_DP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "88d2625c-2837-42cc-8c6d-250001158d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rag</th>\n",
       "      <th>base_rag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_correctness_score</th>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_relevancy_score</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_faithfulness_score</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rag                      base_rag\n",
       "metrics                          \n",
       "mean_correctness_score        4.5\n",
       "mean_relevancy_score          1.0\n",
       "mean_faithfulness_score       1.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curated_mean_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4eb4524e-977c-4716-8c02-0676b2d48ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>relevancy_score</th>\n",
       "      <th>correctness_score</th>\n",
       "      <th>faithfulness_score</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are key features of llama-agents?</td>\n",
       "      <td>Distributed Service-Oriented Architecture, Communication via standardized API interfaces, Pass messages between agents using a message queue, Define agentic and explicit orchestration flows, Ease of deployment, Scalability and resource management.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[First we’ll bring in our dependencies and set up our control plane, which contains our LLM-powered orchestrator import  dotenv\\ndotenv.load_dotenv()  # our .env file defines OPENAI_API_KEY \\n from  llama_agents  import  (\\n    AgentService,\\n    ControlPlaneServer,\\n    SimpleMessageQueue,\\n    AgentOrchestrator,\\n)\\n from  llama_index.core.agent  import  FunctionCallingAgentWorker\\n from  llama_index.core.tools  import  FunctionTool\\n from  llama_index.llms.openai  import  OpenAI\\n import  logging\\n\\n # turn on logging so we can see the system working \\nlogging.getLogger( \"llama_agents\" ).setLevel(logging.INFO)\\n\\n # Set up the message queue and control plane \\nmessage_queue = SimpleMessageQueue()\\ncontrol_plane = ControlPlaneServer(\\n    message_queue=message_queue,\\n    orchestrator=AgentOrchestrator(llm=OpenAI()),\\n) Next we create our tools using LlamaIndex’s existing abstractions, provide those tools to an agent, and turn that agent into an independent microservice: # create a tool \\n def   get_the_secret_fact () -&gt;  str :\\n     \"\"\"Returns the secret fact.\"\"\" \\n     return   \"The secret fact is: A baby llama is called a 'Cria'.\" \\n\\ntool = FunctionTool.from_defaults(fn=get_the_secret_fact)\\n\\n # Define an agent \\nworker = FunctionCallingAgentWorker.from_tools([tool], llm=OpenAI())\\nagent = worker.as_agent()\\n\\n # Create an agent service \\nagent_service = AgentService(\\n    agent=agent,\\n    message_queue=message_queue,\\n    description= \"General purpose assistant\" ,\\n    service_name= \"assistant\" ,\\n) Finally we launch the service and the control plane. Note that here we’re using a helper function to run a single query through the system and then exit; next we’ll show how to deploy this to production. # Set up the launcher for local testing \\n from  llama_agents  import  LocalLauncher\\n\\nlauncher = LocalLauncher(\\n    [agent_service],\\n    control_plane,\\n    message_queue,\\n)\\n\\n # Run a single query through the system \\nresult = launcher.launch_single( \"What's the secret fact?\", Introducing llama-agents: A Powerful Framework for Building Production Multi-Agent AI Systems\\nWe're excited to announce the alpha release of  llama-agents , a new open-source framework designed to simplify the process of building, iterating, and deploying multi-agent AI systems and turn your agents into production microservices. Whether you're working on complex question-answering systems, collaborative AI assistants, or distributed AI workflows, llama-agents provides the tools and structure you need to bring your ideas to life. Key Features of llama-agents Distributed Service Oriented Architecture:  every agent in LlamaIndex can be its own independently running microservice, orchestrated by a fully customizable LLM-powered control plane that routes and distributes tasks. Communication via standardized API interfaces:  interface between agents using a central control plane orchestrator. Pass messages between agents using a message queue. Define agentic and explicit orchestration flows:  developers have the flexibility to directly define the sequence of interactions between agents, or leave it up to an “agentic orchestrator” that decides which agents are relevant to the task. Ease of deployment:  launch, scale and monitor each agent and your control plane independently. Scalability and resource management:  use our built-in observability tools to monitor the quality and performance of the system and each individual agent service Let's dive into how you can start using llama-agents to build your own multi-agent systems. Getting Started with llama-agents First, install the framework using pip: pip install llama-agents llama-index-agent-openai Basic System Setup Here's a simple example of how to set up a basic multi-agent system using llama-agents.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the two critical areas of RAG system performance that are assessed in the 'Evaluating RAG with LlamaIndex' section of the OpenAI Cookbook?</td>\n",
       "      <td>The two critical areas of RAG system performance that are assessed in the 'Evaluating RAG with LlamaIndex' section of the OpenAI Cookbook are the Retrieval System and Response Generation.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OpenAI Cookbook: Evaluating RAG systems\\nWe’re excited to unveil our  OpenAI Cookbook , a guide to evaluating Retrieval-Augmented Generation (RAG) systems using LlamaIndex. We hope you’ll find it useful in enhancing the effectiveness of your RAG systems, and we’re thrilled to share it with you. The OpenAI Cookbook has three sections: Understanding Retrieval-Augmented Generation (RAG):  provides a detailed overview of RAG systems, including the various stages involved in building the RAG system. Building RAG with LlamaIndex:  Here, we dive into the practical aspects, demonstrating how to construct a RAG system using LlamaIndex, specifically applied to Paul Graham’s essay, utilizing the  VectorStoreIndex . Evaluating RAG with LlamaIndex:  The final section focuses on assessing the RAG system’s performance in two critical areas:  the Retrieval System  and  Response Generation. We use our unique synthetic dataset generation method,  generate_question_context_pairs  to conduct thorough evaluations in these areas. Our goal with this  cookbook  is to provide the community with an essential resource for effectively evaluating and enhancing RAG systems developed using LlamaIndex. Join us in exploring the depths of RAG system evaluation and discover how to leverage the full potential of your RAG implementations with LlamaIndex. Keep building with LlamaIndex!🦙, LlamaIndex Newsletter 2023–12–05\\nHello Llama Community 🦙, We are excited to collaborate with DeepLearningAI and TruEraAI to launch an extensive course on advanced Retrieval-Augmented Generation (RAG) and its evaluations. The course includes Sentence Window Retrieval, Auto-merging Retrieval, and Evaluations with TruLensML, providing practical tools for enhanced learning and application. To make the most of this learning opportunity, we invite you to  take the course . We appreciate your support and are always excited to see your projects and videos. Feel free to share them at  news@llamaindex.ai . Also, remember to subscribe to our newsletter on our  website  for the latest updates and to connect with our vibrant community. 🤩  First, the highlights: Launch of Seven Advanced Retrieval LlamaPacks : Simplifies building advanced RAG systems to nearly a single line of code, offering techniques like Hybrid Fusion and Auto-merging Retriever.  Tweet . Introduction of the OpenAI Cookbook : A comprehensive guide for evaluating RAG systems with LlamaIndex, covering system understanding, building, and performance evaluation.  Blog ,  Notebook Speed Enhancement in Structured Metadata Extraction : Achieved 2x to 10x faster processing in extracting structured metadata from text, boosting RAG performance.  Docs ,  Tweet . We launched versions 3 of  RAGs , our project that lets you use natural language to generate a RAG bot customized to your needs. This version incorporates web search, so your bot can incorporate answers fresh from the web.  Tweet . Core  guide   for Full-Stack LLM App Development : Simplifies complex app development with tools like ‘create-llama’ for full-stack apps, ‘SEC Insights’ for multi-document processing, and ‘LlamaIndex Chat’ for chatbot customization. ✨ Feature Releases and Enhancements: We’ve launched seven advanced retrieval LlamaPacks, serving as templates to easily build advanced RAG systems. These packs simplify the process to almost a single line of code, moving away from the traditional notebook approach.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the two main metrics used to evaluate the performance of the different rerankers in the RAG system?</td>\n",
       "      <td>The two main metrics used to evaluate the performance of the different rerankers in the RAG system are Hit Rate and Mean Reciprocal Rank (MRR).</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Implemented by the user.\\n\\n        \"\"\" \\n         return  self._retrieve(query_bundle)\\n\\n     async   def   aretrieve ( self, str_or_query_bundle: QueryType ) -&amp;gt;  List [NodeWithScore]:\\n         if   isinstance (str_or_query_bundle,  str ):\\n            str_or_query_bundle = QueryBundle(str_or_query_bundle)\\n         return   await  self._aretrieve(str_or_query_bundle)\\n\\ncustom_retriever = CustomRetriever(vector_retriever) Evaluation: To evaluate our retriever, we computed the Mean Reciprocal Rank (MRR) and Hit Rate metrics: retriever_evaluator = RetrieverEvaluator.from_metric_names(\\n    [ \"mrr\" ,  \"hit_rate\" ], retriever=custom_retriever\\n)\\neval_results =  await  retriever_evaluator.aevaluate_dataset(qa_dataset) Results: We put various embedding models and rerankers to the test. Here are the models we considered: Embedding Models : OpenAI Embedding Voyage Embedding CohereAI Embedding  (v2.0/ v3.0) Jina Embeddings  (small/ base) BAAI/bge-large-en Google PaLM Embedding Rerankers : CohereAI bge-reranker-base bge-reranker-large It’s worth mentioning that these results provide a solid insight into performance for this particular dataset and task. However, actual outcomes may differ based on data characteristics, dataset size, and other variables like chunk_size, similarity_top_k, and so on. The table below showcases the evaluation results based on the metrics of Hit Rate and Mean Reciprocal Rank (MRR): Analysis: Performance by Embedding: OpenAI : Showcases top-tier performance, especially with the  CohereRerank  (0.926966 hit rate, 0.86573 MRR) and  bge-reranker-large  (0.910112 hit rate, 0.855805 MRR), indicating strong compatibility with reranking tools., # Extract keys from queries and relevant_docs that need to be removed \\n    queries_relevant_docs_keys_to_remove = {\\n        k  for  k, v  in  qa_dataset.queries.items()\\n         if   'Here are 2'   in  v  or   'Here are two'   in  v\\n    }\\n\\n     # Filter queries and relevant_docs using dictionary comprehensions \\n    filtered_queries = {\\n        k: v  for  k, v  in  qa_dataset.queries.items()\\n         if  k  not   in  queries_relevant_docs_keys_to_remove\\n    }\\n    filtered_relevant_docs = {\\n        k: v  for  k, v  in  qa_dataset.relevant_docs.items()\\n         if  k  not   in  queries_relevant_docs_keys_to_remove\\n    }\\n\\n     # Create a new instance of EmbeddingQAFinetuneDataset with the filtered data \\n     return  EmbeddingQAFinetuneDataset(\\n        queries=filtered_queries,\\n        corpus=qa_dataset.corpus,\\n        relevant_docs=filtered_relevant_docs\\n    )\\n\\n # filter out pairs with phrases `Here are 2 questions based on provided context` \\nqa_dataset = filter_qa_dataset(qa_dataset) Custom Retriever: To identify the optimal retriever, we employ a combination of an embedding model and a reranker. Initially, we establish a base  VectorIndexRetriever . Upon retrieving the nodes, we then introduce a reranker to further refine the results. It’s worth noting that for this particular experiment, we’ve set similarity_top_k to 10 and picked top-5 with reranker. However, feel free to adjust this parameter based on the needs of your specific experiment. We are showing the code here with  OpenAIEmbedding , please refer to the  notebook  for code with other embeddings.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 query  \\\n",
       "0                                                                                                               What are key features of llama-agents?   \n",
       "1  What are the two critical areas of RAG system performance that are assessed in the 'Evaluating RAG with LlamaIndex' section of the OpenAI Cookbook?   \n",
       "2                                         What are the two main metrics used to evaluate the performance of the different rerankers in the RAG system?   \n",
       "\n",
       "                                                                                                                                                                                                                                                    answer  \\\n",
       "0  Distributed Service-Oriented Architecture, Communication via standardized API interfaces, Pass messages between agents using a message queue, Define agentic and explicit orchestration flows, Ease of deployment, Scalability and resource management.   \n",
       "1                                                              The two critical areas of RAG system performance that are assessed in the 'Evaluating RAG with LlamaIndex' section of the OpenAI Cookbook are the Retrieval System and Response Generation.   \n",
       "2                                                                                                          The two main metrics used to evaluate the performance of the different rerankers in the RAG system are Hit Rate and Mean Reciprocal Rank (MRR).   \n",
       "\n",
       "   relevancy_score  correctness_score  faithfulness_score  \\\n",
       "0              1.0                NaN                 1.0   \n",
       "1              1.0                4.5                 1.0   \n",
       "2              1.0                4.5                 1.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  contexts  \n",
       "0  [First we’ll bring in our dependencies and set up our control plane, which contains our LLM-powered orchestrator import  dotenv\\ndotenv.load_dotenv()  # our .env file defines OPENAI_API_KEY \\n from  llama_agents  import  (\\n    AgentService,\\n    ControlPlaneServer,\\n    SimpleMessageQueue,\\n    AgentOrchestrator,\\n)\\n from  llama_index.core.agent  import  FunctionCallingAgentWorker\\n from  llama_index.core.tools  import  FunctionTool\\n from  llama_index.llms.openai  import  OpenAI\\n import  logging\\n\\n # turn on logging so we can see the system working \\nlogging.getLogger( \"llama_agents\" ).setLevel(logging.INFO)\\n\\n # Set up the message queue and control plane \\nmessage_queue = SimpleMessageQueue()\\ncontrol_plane = ControlPlaneServer(\\n    message_queue=message_queue,\\n    orchestrator=AgentOrchestrator(llm=OpenAI()),\\n) Next we create our tools using LlamaIndex’s existing abstractions, provide those tools to an agent, and turn that agent into an independent microservice: # create a tool \\n def   get_the_secret_fact () ->  str :\\n     \"\"\"Returns the secret fact.\"\"\" \\n     return   \"The secret fact is: A baby llama is called a 'Cria'.\" \\n\\ntool = FunctionTool.from_defaults(fn=get_the_secret_fact)\\n\\n # Define an agent \\nworker = FunctionCallingAgentWorker.from_tools([tool], llm=OpenAI())\\nagent = worker.as_agent()\\n\\n # Create an agent service \\nagent_service = AgentService(\\n    agent=agent,\\n    message_queue=message_queue,\\n    description= \"General purpose assistant\" ,\\n    service_name= \"assistant\" ,\\n) Finally we launch the service and the control plane. Note that here we’re using a helper function to run a single query through the system and then exit; next we’ll show how to deploy this to production. # Set up the launcher for local testing \\n from  llama_agents  import  LocalLauncher\\n\\nlauncher = LocalLauncher(\\n    [agent_service],\\n    control_plane,\\n    message_queue,\\n)\\n\\n # Run a single query through the system \\nresult = launcher.launch_single( \"What's the secret fact?\", Introducing llama-agents: A Powerful Framework for Building Production Multi-Agent AI Systems\\nWe're excited to announce the alpha release of  llama-agents , a new open-source framework designed to simplify the process of building, iterating, and deploying multi-agent AI systems and turn your agents into production microservices. Whether you're working on complex question-answering systems, collaborative AI assistants, or distributed AI workflows, llama-agents provides the tools and structure you need to bring your ideas to life. Key Features of llama-agents Distributed Service Oriented Architecture:  every agent in LlamaIndex can be its own independently running microservice, orchestrated by a fully customizable LLM-powered control plane that routes and distributes tasks. Communication via standardized API interfaces:  interface between agents using a central control plane orchestrator. Pass messages between agents using a message queue. Define agentic and explicit orchestration flows:  developers have the flexibility to directly define the sequence of interactions between agents, or leave it up to an “agentic orchestrator” that decides which agents are relevant to the task. Ease of deployment:  launch, scale and monitor each agent and your control plane independently. Scalability and resource management:  use our built-in observability tools to monitor the quality and performance of the system and each individual agent service Let's dive into how you can start using llama-agents to build your own multi-agent systems. Getting Started with llama-agents First, install the framework using pip: pip install llama-agents llama-index-agent-openai Basic System Setup Here's a simple example of how to set up a basic multi-agent system using llama-agents.]  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                [OpenAI Cookbook: Evaluating RAG systems\\nWe’re excited to unveil our  OpenAI Cookbook , a guide to evaluating Retrieval-Augmented Generation (RAG) systems using LlamaIndex. We hope you’ll find it useful in enhancing the effectiveness of your RAG systems, and we’re thrilled to share it with you. The OpenAI Cookbook has three sections: Understanding Retrieval-Augmented Generation (RAG):  provides a detailed overview of RAG systems, including the various stages involved in building the RAG system. Building RAG with LlamaIndex:  Here, we dive into the practical aspects, demonstrating how to construct a RAG system using LlamaIndex, specifically applied to Paul Graham’s essay, utilizing the  VectorStoreIndex . Evaluating RAG with LlamaIndex:  The final section focuses on assessing the RAG system’s performance in two critical areas:  the Retrieval System  and  Response Generation. We use our unique synthetic dataset generation method,  generate_question_context_pairs  to conduct thorough evaluations in these areas. Our goal with this  cookbook  is to provide the community with an essential resource for effectively evaluating and enhancing RAG systems developed using LlamaIndex. Join us in exploring the depths of RAG system evaluation and discover how to leverage the full potential of your RAG implementations with LlamaIndex. Keep building with LlamaIndex!🦙, LlamaIndex Newsletter 2023–12–05\\nHello Llama Community 🦙, We are excited to collaborate with DeepLearningAI and TruEraAI to launch an extensive course on advanced Retrieval-Augmented Generation (RAG) and its evaluations. The course includes Sentence Window Retrieval, Auto-merging Retrieval, and Evaluations with TruLensML, providing practical tools for enhanced learning and application. To make the most of this learning opportunity, we invite you to  take the course . We appreciate your support and are always excited to see your projects and videos. Feel free to share them at  news@llamaindex.ai . Also, remember to subscribe to our newsletter on our  website  for the latest updates and to connect with our vibrant community. 🤩  First, the highlights: Launch of Seven Advanced Retrieval LlamaPacks : Simplifies building advanced RAG systems to nearly a single line of code, offering techniques like Hybrid Fusion and Auto-merging Retriever.  Tweet . Introduction of the OpenAI Cookbook : A comprehensive guide for evaluating RAG systems with LlamaIndex, covering system understanding, building, and performance evaluation.  Blog ,  Notebook Speed Enhancement in Structured Metadata Extraction : Achieved 2x to 10x faster processing in extracting structured metadata from text, boosting RAG performance.  Docs ,  Tweet . We launched versions 3 of  RAGs , our project that lets you use natural language to generate a RAG bot customized to your needs. This version incorporates web search, so your bot can incorporate answers fresh from the web.  Tweet . Core  guide   for Full-Stack LLM App Development : Simplifies complex app development with tools like ‘create-llama’ for full-stack apps, ‘SEC Insights’ for multi-document processing, and ‘LlamaIndex Chat’ for chatbot customization. ✨ Feature Releases and Enhancements: We’ve launched seven advanced retrieval LlamaPacks, serving as templates to easily build advanced RAG systems. These packs simplify the process to almost a single line of code, moving away from the traditional notebook approach.]  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [Implemented by the user.\\n\\n        \"\"\" \\n         return  self._retrieve(query_bundle)\\n\\n     async   def   aretrieve ( self, str_or_query_bundle: QueryType ) -&gt;  List [NodeWithScore]:\\n         if   isinstance (str_or_query_bundle,  str ):\\n            str_or_query_bundle = QueryBundle(str_or_query_bundle)\\n         return   await  self._aretrieve(str_or_query_bundle)\\n\\ncustom_retriever = CustomRetriever(vector_retriever) Evaluation: To evaluate our retriever, we computed the Mean Reciprocal Rank (MRR) and Hit Rate metrics: retriever_evaluator = RetrieverEvaluator.from_metric_names(\\n    [ \"mrr\" ,  \"hit_rate\" ], retriever=custom_retriever\\n)\\neval_results =  await  retriever_evaluator.aevaluate_dataset(qa_dataset) Results: We put various embedding models and rerankers to the test. Here are the models we considered: Embedding Models : OpenAI Embedding Voyage Embedding CohereAI Embedding  (v2.0/ v3.0) Jina Embeddings  (small/ base) BAAI/bge-large-en Google PaLM Embedding Rerankers : CohereAI bge-reranker-base bge-reranker-large It’s worth mentioning that these results provide a solid insight into performance for this particular dataset and task. However, actual outcomes may differ based on data characteristics, dataset size, and other variables like chunk_size, similarity_top_k, and so on. The table below showcases the evaluation results based on the metrics of Hit Rate and Mean Reciprocal Rank (MRR): Analysis: Performance by Embedding: OpenAI : Showcases top-tier performance, especially with the  CohereRerank  (0.926966 hit rate, 0.86573 MRR) and  bge-reranker-large  (0.910112 hit rate, 0.855805 MRR), indicating strong compatibility with reranking tools., # Extract keys from queries and relevant_docs that need to be removed \\n    queries_relevant_docs_keys_to_remove = {\\n        k  for  k, v  in  qa_dataset.queries.items()\\n         if   'Here are 2'   in  v  or   'Here are two'   in  v\\n    }\\n\\n     # Filter queries and relevant_docs using dictionary comprehensions \\n    filtered_queries = {\\n        k: v  for  k, v  in  qa_dataset.queries.items()\\n         if  k  not   in  queries_relevant_docs_keys_to_remove\\n    }\\n    filtered_relevant_docs = {\\n        k: v  for  k, v  in  qa_dataset.relevant_docs.items()\\n         if  k  not   in  queries_relevant_docs_keys_to_remove\\n    }\\n\\n     # Create a new instance of EmbeddingQAFinetuneDataset with the filtered data \\n     return  EmbeddingQAFinetuneDataset(\\n        queries=filtered_queries,\\n        corpus=qa_dataset.corpus,\\n        relevant_docs=filtered_relevant_docs\\n    )\\n\\n # filter out pairs with phrases `Here are 2 questions based on provided context` \\nqa_dataset = filter_qa_dataset(qa_dataset) Custom Retriever: To identify the optimal retriever, we employ a combination of an embedding model and a reranker. Initially, we establish a base  VectorIndexRetriever . Upon retrieving the nodes, we then introduce a reranker to further refine the results. It’s worth noting that for this particular experiment, we’ve set similarity_top_k to 10 and picked top-5 with reranker. However, feel free to adjust this parameter based on the needs of your specific experiment. We are showing the code here with  OpenAIEmbedding , please refer to the  notebook  for code with other embeddings.]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(curated_deep_eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "113a264d-1cea-4e41-82ac-22135f12f729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implemented by the user.\n",
      "\n",
      "        \"\"\" \n",
      "         return  self._retrieve(query_bundle)\n",
      "\n",
      "     async   def   aretrieve ( self, str_or_query_bundle: QueryType ) -&gt;  List [NodeWithScore]:\n",
      "         if   isinstance (str_or_query_bundle,  str ):\n",
      "            str_or_query_bundle = QueryBundle(str_or_query_bundle)\n",
      "         return   await  self._aretrieve(str_or_query_bundle)\n",
      "\n",
      "custom_retriever = CustomRetriever(vector_retriever) Evaluation: To evaluate our retriever, we computed the Mean Reciprocal Rank (MRR) and Hit Rate metrics: retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
      "    [ \"mrr\" ,  \"hit_rate\" ], retriever=custom_retriever\n",
      ")\n",
      "eval_results =  await  retriever_evaluator.aevaluate_dataset(qa_dataset) Results: We put various embedding models and rerankers to the test. Here are the models we considered: Embedding Models : OpenAI Embedding Voyage Embedding CohereAI Embedding  (v2.0/ v3.0) Jina Embeddings  (small/ base) BAAI/bge-large-en Google PaLM Embedding Rerankers : CohereAI bge-reranker-base bge-reranker-large It’s worth mentioning that these results provide a solid insight into performance for this particular dataset and task. However, actual outcomes may differ based on data characteristics, dataset size, and other variables like chunk_size, similarity_top_k, and so on. The table below showcases the evaluation results based on the metrics of Hit Rate and Mean Reciprocal Rank (MRR): Analysis: Performance by Embedding: OpenAI : Showcases top-tier performance, especially with the  CohereRerank  (0.926966 hit rate, 0.86573 MRR) and  bge-reranker-large  (0.910112 hit rate, 0.855805 MRR), indicating strong compatibility with reranking tools.\n",
      "----------\n",
      "# Extract keys from queries and relevant_docs that need to be removed \n",
      "    queries_relevant_docs_keys_to_remove = {\n",
      "        k  for  k, v  in  qa_dataset.queries.items()\n",
      "         if   'Here are 2'   in  v  or   'Here are two'   in  v\n",
      "    }\n",
      "\n",
      "     # Filter queries and relevant_docs using dictionary comprehensions \n",
      "    filtered_queries = {\n",
      "        k: v  for  k, v  in  qa_dataset.queries.items()\n",
      "         if  k  not   in  queries_relevant_docs_keys_to_remove\n",
      "    }\n",
      "    filtered_relevant_docs = {\n",
      "        k: v  for  k, v  in  qa_dataset.relevant_docs.items()\n",
      "         if  k  not   in  queries_relevant_docs_keys_to_remove\n",
      "    }\n",
      "\n",
      "     # Create a new instance of EmbeddingQAFinetuneDataset with the filtered data \n",
      "     return  EmbeddingQAFinetuneDataset(\n",
      "        queries=filtered_queries,\n",
      "        corpus=qa_dataset.corpus,\n",
      "        relevant_docs=filtered_relevant_docs\n",
      "    )\n",
      "\n",
      " # filter out pairs with phrases `Here are 2 questions based on provided context` \n",
      "qa_dataset = filter_qa_dataset(qa_dataset) Custom Retriever: To identify the optimal retriever, we employ a combination of an embedding model and a reranker. Initially, we establish a base  VectorIndexRetriever . Upon retrieving the nodes, we then introduce a reranker to further refine the results. It’s worth noting that for this particular experiment, we’ve set similarity_top_k to 10 and picked top-5 with reranker. However, feel free to adjust this parameter based on the needs of your specific experiment. We are showing the code here with  OpenAIEmbedding , please refer to the  notebook  for code with other embeddings.\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for context in curated_deep_eval_df.iloc[2]['contexts']:\n",
    "    print(context)\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "024c20ec-bf28-43bf-912b-d02c5aed9d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_TO_MLFLOW:\n",
    "    for k, v in curated_mean_scores_df.T.to_dict(orient='records')[0].items():\n",
    "        mlflow.log_metric(f\"curated_response_eval__{k}\", v)\n",
    "    curated_deep_eval_df.to_html(f\"{NOTEBOOK_CACHE_DP}/curated_deep_eval_df.html\")\n",
    "    mlflow.log_artifact(f\"{NOTEBOOK_CACHE_DP}/curated_deep_eval_df.html\", \"curated_deep_eval_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2247e7ca-f7d1-4620-96de-7bc9977fb0a2",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "47f12fc1-4062-4829-9236-82c27df86c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_TO_MLFLOW:\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7959512-c62a-4e08-a5e7-3e7681b2096f",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f261db95-ff04-4372-8e5e-d261b8b0f9a3",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3d69798-d4bb-4461-88a2-f07d7c0a6099",
   "metadata": {},
   "source": [
    "def displayify_df(df):\n",
    "    \"\"\"For pretty displaying DataFrame in a notebook.\"\"\"\n",
    "    display_df = df.style.set_properties(\n",
    "        **{\n",
    "            \"inline-size\": \"300px\",\n",
    "            \"overflow-wrap\": \"break-word\",\n",
    "        }\n",
    "    )\n",
    "    display(display_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1338b451-66d8-4b1c-9786-85e046683d60",
   "metadata": {},
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3243b624-20ee-4b0c-9e84-1f99a814e995",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "response_eval_prediction_dataset = await response_eval_dataset.amake_predictions_with(\n",
    "    predictor=query_engine, batch_size=BATCH_SIZE, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa48d537-5cad-47ed-88a3-392c435c3e9e",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e7eb720-48a1-45f7-aee5-bcb315c4d6fd",
   "metadata": {},
   "source": [
    "Ref: https://docs.llamaindex.ai/en/stable/examples/llama_dataset/downloading_llama_datasets/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbfee4dc-d2d7-4c04-ac61-273279da59c8",
   "metadata": {},
   "source": [
    "judge_model = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "675a37c7-e9cc-48ba-8158-4cd28f57b07a",
   "metadata": {},
   "source": [
    "# instantiate the judge\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.evaluation import (\n",
    "    CorrectnessEvaluator,\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    "    SemanticSimilarityEvaluator,\n",
    ")\n",
    "\n",
    "judges = {}\n",
    "\n",
    "# Correctness outputs a score between 1 and 5, where 1 is the worst and 5 is the best, along with a reasoning for the score. Passing is defined as a score greater than or equal to the given threshold.\n",
    "# Ref: https://docs.llamaindex.ai/en/stable/api_reference/evaluation/correctness/\n",
    "judges[\"correctness\"] = CorrectnessEvaluator(\n",
    "    llm=OpenAI(temperature=0, model=judge_model),\n",
    ")\n",
    "\n",
    "judges[\"relevancy\"] = RelevancyEvaluator(\n",
    "    llm=OpenAI(temperature=0, model=judge_model),\n",
    ")\n",
    "\n",
    "judges[\"faithfulness\"] = FaithfulnessEvaluator(\n",
    "    llm=OpenAI(temperature=0, model=judge_model),\n",
    ")\n",
    "\n",
    "judges[\"semantic_similarity\"] = SemanticSimilarityEvaluator()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87659d89-1cad-4bfc-bccf-f4b2f73bb076",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "evals = {\n",
    "    \"correctness\": [],\n",
    "    \"relevancy\": [],\n",
    "    \"faithfulness\": [],\n",
    "}\n",
    "\n",
    "for example, prediction in tqdm(\n",
    "    zip(response_eval_dataset.examples, response_eval_prediction_dataset.predictions)\n",
    "):\n",
    "    correctness_result = judges[\"correctness\"].evaluate(\n",
    "        query=example.query,\n",
    "        response=prediction.response,\n",
    "        reference=example.reference_answer,\n",
    "    )\n",
    "\n",
    "    relevancy_result = judges[\"relevancy\"].evaluate(\n",
    "        query=example.query,\n",
    "        response=prediction.response,\n",
    "        contexts=prediction.contexts,\n",
    "    )\n",
    "\n",
    "    faithfulness_result = judges[\"faithfulness\"].evaluate(\n",
    "        query=example.query,\n",
    "        response=prediction.response,\n",
    "        contexts=prediction.contexts,\n",
    "    )\n",
    "\n",
    "    evals[\"correctness\"].append(correctness_result)\n",
    "    evals[\"relevancy\"].append(relevancy_result)\n",
    "    evals[\"faithfulness\"].append(faithfulness_result)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1203338f-c3e4-4862-ac57-4c248a138db2",
   "metadata": {},
   "source": [
    "#### Persist evaluation results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61fd4039-3ac2-4dd0-b0b9-0bc5c4573793",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "# saving evaluations\n",
    "evaluations_objects = {\n",
    "    \"correctness\": [e.dict() for e in evals[\"correctness\"]],\n",
    "    \"faithfulness\": [e.dict() for e in evals[\"faithfulness\"]],\n",
    "    \"relevancy\": [e.dict() for e in evals[\"relevancy\"]],\n",
    "}\n",
    "\n",
    "with open(f\"{notebook_cache_dp}/evaluations.json\", \"w\") as json_file:\n",
    "    json.dump(evaluations_objects, json_file)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a46e4889-7fe2-4220-9191-ae95cb4a7318",
   "metadata": {},
   "source": [
    "#### View eval results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47150615-931e-4190-8a33-3620d34c5d71",
   "metadata": {},
   "source": [
    "##### Overall results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef3d73ab-1245-45cf-87b2-856da742e463",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from llama_index.core.evaluation.notebook_utils import get_eval_results_df\n",
    "\n",
    "deep_eval_correctness_df, mean_correctness_df = get_eval_results_df(\n",
    "    [\"base_rag\"] * len(evals[\"correctness\"]),\n",
    "    evals[\"correctness\"],\n",
    "    metric=\"correctness\",\n",
    ")\n",
    "deep_eval_relevancy_df, mean_relevancy_df = get_eval_results_df(\n",
    "    [\"base_rag\"] * len(evals[\"relevancy\"]),\n",
    "    evals[\"relevancy\"],\n",
    "    metric=\"relevancy\",\n",
    ")\n",
    "deep_eval_faithfulness_df, mean_faithfulness_df = get_eval_results_df(\n",
    "    [\"base_rag\"] * len(evals[\"faithfulness\"]),\n",
    "    evals[\"faithfulness\"],\n",
    "    metric=\"faithfulness\",\n",
    ")\n",
    "\n",
    "mean_scores_df = pd.concat(\n",
    "    [\n",
    "        mean_correctness_df.reset_index(),\n",
    "        mean_relevancy_df.reset_index(),\n",
    "        mean_faithfulness_df.reset_index(),\n",
    "    ],\n",
    "    axis=0,\n",
    "    ignore_index=True,\n",
    ")\n",
    "mean_scores_df = mean_scores_df.set_index(\"index\")\n",
    "mean_scores_df.index = mean_scores_df.index.set_names([\"metrics\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "760ad247-1d13-4c30-95b7-2ab8a2c7cd19",
   "metadata": {},
   "source": [
    "mean_scores_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d617bacd-c71f-45bb-be9d-fff0c4d28fca",
   "metadata": {},
   "source": [
    "##### By questions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea2cd128-6cd6-4b60-a219-69fa4af80e0d",
   "metadata": {},
   "source": [
    "deep_eval_df = pd.concat([\n",
    "    deep_eval_correctness_df[['query', 'answer']],\n",
    "    deep_eval_relevancy_df[['scores']].rename(columns={'scores': 'relevancy_score'}),\n",
    "    deep_eval_correctness_df[['scores']].rename(columns={'scores': 'correctness_score'}),\n",
    "    deep_eval_faithfulness_df[['scores']].rename(columns={'scores': 'faithfulness_score'}),\n",
    "], axis=1)\n",
    "\n",
    "(\n",
    "    deep_eval_df\n",
    ")\n",
    "\n",
    "# (\n",
    "#     deep_eval_df\n",
    "#     .style\n",
    "#     .background_gradient(subset=[col for col in deep_eval_df.columns if col.endswith('score')])\n",
    "# )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "050df1f5-b4fc-48ce-b45b-322be1c234b5",
   "metadata": {},
   "source": [
    "## Manually curated dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
